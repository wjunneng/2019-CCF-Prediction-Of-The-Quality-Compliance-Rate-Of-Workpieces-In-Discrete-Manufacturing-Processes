{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train = '/home/wjunneng/Ubuntu/2019-CCF-Prediction-Of-The-Quality-Compliance-Rate-Of-Workpieces-In-Discrete-Manufacturing-Processes/data/cache/X_train_smote.h5'\n",
    "y_train = '/home/wjunneng/Ubuntu/2019-CCF-Prediction-Of-The-Quality-Compliance-Rate-Of-Workpieces-In-Discrete-Manufacturing-Processes/data/cache/y_train_smote.h5'\n",
    "X_test = '/home/wjunneng/Ubuntu/2019-CCF-Prediction-Of-The-Quality-Compliance-Rate-Of-Workpieces-In-Discrete-Manufacturing-Processes/data/cache/X_test.h5'\n",
    "\n",
    "X_train = pd.read_hdf(path_or_buf=X_train, mode='r', key='X_train')\n",
    "y_train = pd.read_hdf(path_or_buf=y_train, mode='r', key='y_train')\n",
    "X_test = pd.read_hdf(path_or_buf=X_test, mode='r', key='X_test')\n",
    "\n",
    "columns = ['Parameter1', 'Parameter2', 'Parameter3', 'Parameter4', 'Parameter5', 'Parameter6',\n",
    "                          'Parameter7', 'Parameter8', 'Parameter9', 'Parameter10']\n",
    "\n",
    "categorical_columns = ['Parameter5', 'Parameter6',\n",
    "                          'Parameter7', 'Parameter8', 'Parameter9', 'Parameter10']\n",
    "\n",
    "X_train = X_train[columns]\n",
    "X_test = X_test[columns]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "   Parameter1  Parameter2  Parameter3  Parameter4  Parameter5  Parameter6  \\\n0   -1.006836   -0.530762    1.590820    1.132812    0.000421    0.000612   \n1   -0.130493   -1.026367   -1.021484    1.210938    0.000909    0.002398   \n2   -0.908203    1.412109   -0.968750   -0.900391    0.000909    0.001972   \n3    0.951660   -0.988770   -1.043945   -0.331055    0.000909    0.002398   \n4   -0.995605   -1.034180   -1.059570    1.620117    0.000909    0.002398   \n\n   Parameter7  Parameter8  Parameter9  Parameter10  \n0      2286.0    0.035407    0.593081     1.010742  \n1      2286.0    0.035407    0.593081     1.010742  \n2      2286.0    0.035407    0.593081     1.010742  \n3      2286.0    0.035407    0.593081     1.010742  \n4      2286.0    0.035407    0.593081     1.010742  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Parameter1</th>\n      <th>Parameter2</th>\n      <th>Parameter3</th>\n      <th>Parameter4</th>\n      <th>Parameter5</th>\n      <th>Parameter6</th>\n      <th>Parameter7</th>\n      <th>Parameter8</th>\n      <th>Parameter9</th>\n      <th>Parameter10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.006836</td>\n      <td>-0.530762</td>\n      <td>1.590820</td>\n      <td>1.132812</td>\n      <td>0.000421</td>\n      <td>0.000612</td>\n      <td>2286.0</td>\n      <td>0.035407</td>\n      <td>0.593081</td>\n      <td>1.010742</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.130493</td>\n      <td>-1.026367</td>\n      <td>-1.021484</td>\n      <td>1.210938</td>\n      <td>0.000909</td>\n      <td>0.002398</td>\n      <td>2286.0</td>\n      <td>0.035407</td>\n      <td>0.593081</td>\n      <td>1.010742</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.908203</td>\n      <td>1.412109</td>\n      <td>-0.968750</td>\n      <td>-0.900391</td>\n      <td>0.000909</td>\n      <td>0.001972</td>\n      <td>2286.0</td>\n      <td>0.035407</td>\n      <td>0.593081</td>\n      <td>1.010742</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.951660</td>\n      <td>-0.988770</td>\n      <td>-1.043945</td>\n      <td>-0.331055</td>\n      <td>0.000909</td>\n      <td>0.002398</td>\n      <td>2286.0</td>\n      <td>0.035407</td>\n      <td>0.593081</td>\n      <td>1.010742</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.995605</td>\n      <td>-1.034180</td>\n      <td>-1.059570</td>\n      <td>1.620117</td>\n      <td>0.000909</td>\n      <td>0.002398</td>\n      <td>2286.0</td>\n      <td>0.035407</td>\n      <td>0.593081</td>\n      <td>1.010742</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 120
    }
   ],
   "source": [
    "X_train.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "   Parameter1  Parameter2  Parameter3  Parameter4  Parameter5  Parameter6  \\\n0   -1.006836   -0.530762    1.590820    1.132812    0.000421    0.000612   \n1   -0.130493   -1.026367   -1.021484    1.210938    0.000909    0.002398   \n2   -0.908203    1.412109   -0.968750   -0.900391    0.000909    0.001972   \n3    0.951660   -0.988770   -1.043945   -0.331055    0.000909    0.002398   \n4   -0.995605   -1.034180   -1.059570    1.620117    0.000909    0.002398   \n\n   Parameter7  Parameter8  Parameter9  Parameter10  \n0      2286.0    0.035407    0.593081     1.010742  \n1      2286.0    0.035407    0.593081     1.010742  \n2      2286.0    0.035407    0.593081     1.010742  \n3      2286.0    0.035407    0.593081     1.010742  \n4      2286.0    0.035407    0.593081     1.010742  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Parameter1</th>\n      <th>Parameter2</th>\n      <th>Parameter3</th>\n      <th>Parameter4</th>\n      <th>Parameter5</th>\n      <th>Parameter6</th>\n      <th>Parameter7</th>\n      <th>Parameter8</th>\n      <th>Parameter9</th>\n      <th>Parameter10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.006836</td>\n      <td>-0.530762</td>\n      <td>1.590820</td>\n      <td>1.132812</td>\n      <td>0.000421</td>\n      <td>0.000612</td>\n      <td>2286.0</td>\n      <td>0.035407</td>\n      <td>0.593081</td>\n      <td>1.010742</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.130493</td>\n      <td>-1.026367</td>\n      <td>-1.021484</td>\n      <td>1.210938</td>\n      <td>0.000909</td>\n      <td>0.002398</td>\n      <td>2286.0</td>\n      <td>0.035407</td>\n      <td>0.593081</td>\n      <td>1.010742</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.908203</td>\n      <td>1.412109</td>\n      <td>-0.968750</td>\n      <td>-0.900391</td>\n      <td>0.000909</td>\n      <td>0.001972</td>\n      <td>2286.0</td>\n      <td>0.035407</td>\n      <td>0.593081</td>\n      <td>1.010742</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.951660</td>\n      <td>-0.988770</td>\n      <td>-1.043945</td>\n      <td>-0.331055</td>\n      <td>0.000909</td>\n      <td>0.002398</td>\n      <td>2286.0</td>\n      <td>0.035407</td>\n      <td>0.593081</td>\n      <td>1.010742</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.995605</td>\n      <td>-1.034180</td>\n      <td>-1.059570</td>\n      <td>1.620117</td>\n      <td>0.000909</td>\n      <td>0.002398</td>\n      <td>2286.0</td>\n      <td>0.035407</td>\n      <td>0.593081</td>\n      <td>1.010742</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 121
    }
   ],
   "source": [
    "X_train.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "0    2\n1    3\n2    3\n3    3\n4    3\ndtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 122
    }
   ],
   "source": [
    "y_train.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[1]\tcv_agg's auc: 0.513567 + 0.0154579\n[2]\tcv_agg's auc: 0.516969 + 0.0161124\n[3]\tcv_agg's auc: 0.519606 + 0.01231\n[4]\tcv_agg's auc: 0.517641 + 0.0109929\n[5]\tcv_agg's auc: 0.516329 + 0.0105724\n[6]\tcv_agg's auc: 0.512623 + 0.0129872\n[7]\tcv_agg's auc: 0.511112 + 0.0116579\n[8]\tcv_agg's auc: 0.512458 + 0.00776031\n[9]\tcv_agg's auc: 0.510481 + 0.00717166\n[10]\tcv_agg's auc: 0.511954 + 0.00799246\n",
      "[11]\tcv_agg's auc: 0.512623 + 0.0076673\n[12]\tcv_agg's auc: 0.512033 + 0.00651754\n[13]\tcv_agg's auc: 0.513016 + 0.00759083\n[14]\tcv_agg's auc: 0.514885 + 0.00965241\n[15]\tcv_agg's auc: 0.515002 + 0.0099335\n[16]\tcv_agg's auc: 0.514192 + 0.0108676\n[17]\tcv_agg's auc: 0.514421 + 0.0111697\n[18]\tcv_agg's auc: 0.514412 + 0.0115082\n[19]\tcv_agg's auc: 0.513005 + 0.0107982\n[20]\tcv_agg's auc: 0.513469 + 0.00986755\n[21]\tcv_agg's auc: 0.513408 + 0.010231\n[22]\tcv_agg's auc: 0.511039 + 0.0104796\n[23]\tcv_agg's auc: 0.510808 + 0.0117271\n[24]\tcv_agg's auc: 0.510882 + 0.0112081\n",
      "[25]\tcv_agg's auc: 0.511072 + 0.0118836\n[26]\tcv_agg's auc: 0.511608 + 0.0116782\n[27]\tcv_agg's auc: 0.511507 + 0.0107176\n[28]\tcv_agg's auc: 0.510937 + 0.0107378\n[29]\tcv_agg's auc: 0.510797 + 0.0114954\n[30]\tcv_agg's auc: 0.5096 + 0.0120513\n[31]\tcv_agg's auc: 0.510022 + 0.0118125\n[32]\tcv_agg's auc: 0.510046 + 0.0113749\n[33]\tcv_agg's auc: 0.510113 + 0.0102705\n[34]\tcv_agg's auc: 0.509777 + 0.0107622\n[35]\tcv_agg's auc: 0.509121 + 0.0116027\n[36]\tcv_agg's auc: 0.50811 + 0.0114848\n[37]\tcv_agg's auc: 0.507997 + 0.0107372\n[38]\tcv_agg's auc: 0.508135 + 0.0113738\n[39]\tcv_agg's auc: 0.508666 + 0.0108471\n[40]\tcv_agg's auc: 0.508423 + 0.0107315\n[41]\tcv_agg's auc: 0.507978 + 0.0114446\n[42]\tcv_agg's auc: 0.508269 + 0.0112296\n[43]\tcv_agg's auc: 0.508182 + 0.0116706\n[44]\tcv_agg's auc: 0.508277 + 0.0119375\n[45]\tcv_agg's auc: 0.508673 + 0.0126347\n[46]\tcv_agg's auc: 0.508801 + 0.0130401\n[47]\tcv_agg's auc: 0.509032 + 0.0128689\n[48]\tcv_agg's auc: 0.508781 + 0.0121744\n",
      "[49]\tcv_agg's auc: 0.509334 + 0.0124661\n[50]\tcv_agg's auc: 0.509556 + 0.0127646\n[51]\tcv_agg's auc: 0.509819 + 0.0133588\n[52]\tcv_agg's auc: 0.50931 + 0.0133727\n[53]\tcv_agg's auc: 0.509695 + 0.014652\n[54]\tcv_agg's auc: 0.509575 + 0.0149396\n[55]\tcv_agg's auc: 0.50978 + 0.0153797\n[56]\tcv_agg's auc: 0.510602 + 0.0156284\n[57]\tcv_agg's auc: 0.510853 + 0.0154036\n[58]\tcv_agg's auc: 0.511347 + 0.0151497\n[59]\tcv_agg's auc: 0.510082 + 0.0142783\n[60]\tcv_agg's auc: 0.509657 + 0.0145322\n[61]\tcv_agg's auc: 0.509219 + 0.0139804\n[62]\tcv_agg's auc: 0.509228 + 0.0142981\n[63]\tcv_agg's auc: 0.509557 + 0.0145623\n[64]\tcv_agg's auc: 0.510244 + 0.0149461\n[65]\tcv_agg's auc: 0.510014 + 0.0152226\n[66]\tcv_agg's auc: 0.51079 + 0.0150995\n[67]\tcv_agg's auc: 0.51088 + 0.0145674\n[68]\tcv_agg's auc: 0.510641 + 0.0144702\n[69]\tcv_agg's auc: 0.510586 + 0.0145044\n[70]\tcv_agg's auc: 0.510944 + 0.0147438\n[71]\tcv_agg's auc: 0.510185 + 0.0154928\n[72]\tcv_agg's auc: 0.50997 + 0.0154262\n[73]\tcv_agg's auc: 0.510143 + 0.0150609\n[74]\tcv_agg's auc: 0.51056 + 0.0153646\n[75]\tcv_agg's auc: 0.51036 + 0.0149234\n[76]\tcv_agg's auc: 0.50997 + 0.0148568\n[77]\tcv_agg's auc: 0.509853 + 0.0145316\n[78]\tcv_agg's auc: 0.50971 + 0.014521\n[79]\tcv_agg's auc: 0.509914 + 0.0146213\n[80]\tcv_agg's auc: 0.510245 + 0.0144847\n[81]\tcv_agg's auc: 0.510577 + 0.0147174\n[82]\tcv_agg's auc: 0.510148 + 0.0155982\n[83]\tcv_agg's auc: 0.510534 + 0.0157702\n[84]\tcv_agg's auc: 0.510168 + 0.0156163\n[85]\tcv_agg's auc: 0.510312 + 0.0159352\n",
      "[86]\tcv_agg's auc: 0.510124 + 0.0159887\n[87]\tcv_agg's auc: 0.510705 + 0.0167552\n[88]\tcv_agg's auc: 0.510096 + 0.0166445\n[89]\tcv_agg's auc: 0.510358 + 0.0171577\n[90]\tcv_agg's auc: 0.510004 + 0.0167343\n[91]\tcv_agg's auc: 0.509987 + 0.0168791\n[92]\tcv_agg's auc: 0.510337 + 0.017135\n[93]\tcv_agg's auc: 0.510786 + 0.0173183\n[94]\tcv_agg's auc: 0.510041 + 0.0173631\n[95]\tcv_agg's auc: 0.509807 + 0.0170584\n[96]\tcv_agg's auc: 0.509504 + 0.017523\n[97]\tcv_agg's auc: 0.509649 + 0.0174474\n[98]\tcv_agg's auc: 0.509858 + 0.0173938\n",
      "[99]\tcv_agg's auc: 0.50918 + 0.0182973\n[100]\tcv_agg's auc: 0.509006 + 0.0185267\n[101]\tcv_agg's auc: 0.50904 + 0.0186431\n[102]\tcv_agg's auc: 0.50882 + 0.0184558\n[103]\tcv_agg's auc: 0.508649 + 0.0179534\n[104]\tcv_agg's auc: 0.508623 + 0.0180856\n[105]\tcv_agg's auc: 0.508914 + 0.0177263\n[106]\tcv_agg's auc: 0.509169 + 0.0178899\n[107]\tcv_agg's auc: 0.508809 + 0.0179007\n[108]\tcv_agg's auc: 0.508381 + 0.0180282\n[109]\tcv_agg's auc: 0.50888 + 0.0180781\n[110]\tcv_agg's auc: 0.508625 + 0.0181274\n",
      "[111]\tcv_agg's auc: 0.50854 + 0.0179365\n[112]\tcv_agg's auc: 0.508755 + 0.0181468\n[113]\tcv_agg's auc: 0.508761 + 0.018145\n[114]\tcv_agg's auc: 0.509136 + 0.0177367\n[115]\tcv_agg's auc: 0.509186 + 0.0179312\n[116]\tcv_agg's auc: 0.508686 + 0.0183413\n[117]\tcv_agg's auc: 0.508519 + 0.0190118\n[118]\tcv_agg's auc: 0.508438 + 0.0193016\n[119]\tcv_agg's auc: 0.508539 + 0.0192296\n[120]\tcv_agg's auc: 0.508529 + 0.0192212\n[121]\tcv_agg's auc: 0.508725 + 0.0191152\n[122]\tcv_agg's auc: 0.509042 + 0.0192449\n[123]\tcv_agg's auc: 0.508926 + 0.0190882\n[124]\tcv_agg's auc: 0.508845 + 0.0194326\n[125]\tcv_agg's auc: 0.509078 + 0.0196797\n[126]\tcv_agg's auc: 0.509262 + 0.0197432\n[127]\tcv_agg's auc: 0.509432 + 0.0198904\n[128]\tcv_agg's auc: 0.509512 + 0.0204947\n[129]\tcv_agg's auc: 0.509675 + 0.0203089\n[130]\tcv_agg's auc: 0.509798 + 0.0204798\n[131]\tcv_agg's auc: 0.509529 + 0.0205712\n[132]\tcv_agg's auc: 0.509551 + 0.0205866\n[133]\tcv_agg's auc: 0.509797 + 0.0203872\n[134]\tcv_agg's auc: 0.509536 + 0.0203568\n",
      "[135]\tcv_agg's auc: 0.509823 + 0.0202475\n[136]\tcv_agg's auc: 0.509858 + 0.020049\n[137]\tcv_agg's auc: 0.509922 + 0.0196964\n[138]\tcv_agg's auc: 0.510627 + 0.0202418\n[139]\tcv_agg's auc: 0.51051 + 0.02077\n[140]\tcv_agg's auc: 0.510547 + 0.0208621\n[141]\tcv_agg's auc: 0.510551 + 0.0205089\n[142]\tcv_agg's auc: 0.510707 + 0.0205012\n[143]\tcv_agg's auc: 0.510374 + 0.020162\n[144]\tcv_agg's auc: 0.510472 + 0.0198329\n[145]\tcv_agg's auc: 0.509954 + 0.0203356\n[146]\tcv_agg's auc: 0.509583 + 0.0203742\n[147]\tcv_agg's auc: 0.509464 + 0.0208209\n[148]\tcv_agg's auc: 0.509104 + 0.0211654\n[149]\tcv_agg's auc: 0.509304 + 0.0206526\n[150]\tcv_agg's auc: 0.509695 + 0.0211747\n[151]\tcv_agg's auc: 0.509477 + 0.0212759\n[152]\tcv_agg's auc: 0.509168 + 0.0214498\n[153]\tcv_agg's auc: 0.509487 + 0.0213996\n[154]\tcv_agg's auc: 0.509574 + 0.0212451\n[155]\tcv_agg's auc: 0.509732 + 0.0212624\n[156]\tcv_agg's auc: 0.509863 + 0.0215061\n[157]\tcv_agg's auc: 0.51006 + 0.0215923\n[158]\tcv_agg's auc: 0.510005 + 0.0217212\n[159]\tcv_agg's auc: 0.510038 + 0.0219232\n[160]\tcv_agg's auc: 0.510166 + 0.0222413\n[161]\tcv_agg's auc: 0.509833 + 0.022116\n[162]\tcv_agg's auc: 0.510135 + 0.0223178\n[163]\tcv_agg's auc: 0.510244 + 0.0223089\n[164]\tcv_agg's auc: 0.510291 + 0.0219496\n[165]\tcv_agg's auc: 0.510395 + 0.0218215\n[166]\tcv_agg's auc: 0.510163 + 0.0215957\n[167]\tcv_agg's auc: 0.51029 + 0.0217426\n[168]\tcv_agg's auc: 0.509771 + 0.0215042\n[169]\tcv_agg's auc: 0.50998 + 0.0215992\n[170]\tcv_agg's auc: 0.510598 + 0.0219881\n[171]\tcv_agg's auc: 0.510814 + 0.0221401\n[172]\tcv_agg's auc: 0.510773 + 0.0223481\n[173]\tcv_agg's auc: 0.510999 + 0.02208\n[174]\tcv_agg's auc: 0.510632 + 0.0222584\n[175]\tcv_agg's auc: 0.510542 + 0.0225593\n",
      "[176]\tcv_agg's auc: 0.510352 + 0.0224251\n[177]\tcv_agg's auc: 0.510138 + 0.0222216\n[178]\tcv_agg's auc: 0.509994 + 0.0221747\n[179]\tcv_agg's auc: 0.509985 + 0.0222379\n[180]\tcv_agg's auc: 0.50997 + 0.022432\n[181]\tcv_agg's auc: 0.509949 + 0.0225002\n[182]\tcv_agg's auc: 0.509953 + 0.0224887\n[183]\tcv_agg's auc: 0.51001 + 0.0224724\n[184]\tcv_agg's auc: 0.510008 + 0.0225722\n[185]\tcv_agg's auc: 0.510261 + 0.0226945\n",
      "[186]\tcv_agg's auc: 0.510308 + 0.0229514\n[187]\tcv_agg's auc: 0.510593 + 0.0234457\n[188]\tcv_agg's auc: 0.510724 + 0.0231282\n[189]\tcv_agg's auc: 0.510424 + 0.0233011\n[190]\tcv_agg's auc: 0.510436 + 0.0229919\n[191]\tcv_agg's auc: 0.510165 + 0.0229779\n[192]\tcv_agg's auc: 0.50991 + 0.0230587\n[193]\tcv_agg's auc: 0.509506 + 0.0234082\n[194]\tcv_agg's auc: 0.509099 + 0.0231869\n[195]\tcv_agg's auc: 0.508993 + 0.0233997\n[196]\tcv_agg's auc: 0.50888 + 0.0235113\n[197]\tcv_agg's auc: 0.508799 + 0.0238545\n[198]\tcv_agg's auc: 0.5088 + 0.0236241\n[199]\tcv_agg's auc: 0.508763 + 0.0236835\n[200]\tcv_agg's auc: 0.508834 + 0.0236617\n[201]\tcv_agg's auc: 0.50865 + 0.023925\n[202]\tcv_agg's auc: 0.508526 + 0.0244279\n[203]\tcv_agg's auc: 0.508591 + 0.0244392\n交叉验证中最优的AUC为 0.51961，对应的标准差为0.01231.\n模型最优的迭代次数为3.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/wjunneng/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\nNew categorical_feature is ['Parameter10', 'Parameter5', 'Parameter6', 'Parameter7', 'Parameter8', 'Parameter9']\n  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train['Quality_label'] = y_train\n",
    "X_valid['Quality_label'] = y_valid\n",
    "X_train['Is_Test'] = 0\n",
    "X_valid['Is_Test'] = 1\n",
    "\n",
    "# 将 Train 和 Test 合成一个数据集。Quality_label是数据本来的Y，所以剔除。\n",
    "df_adv = pd.concat([X_train, X_valid])\n",
    "\n",
    "adv_data = lgb.Dataset(data=df_adv.drop('Is_Test', axis=1), label=df_adv.loc[:, 'Is_Test'])\n",
    "\n",
    "# 定义模型参数\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'colsample_bytree': 1,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'min_child_samples': 100,\n",
    "    'min_child_weight': 1,\n",
    "    'min_split_gain': 0.0,\n",
    "    'num_leaves': 20,\n",
    "    'objective': 'binary',\n",
    "    'random_state': 50,\n",
    "    'subsample': 1.0,\n",
    "    'subsample_freq': 0,\n",
    "    'metric': 'auc',\n",
    "    'num_threads': 8\n",
    "}\n",
    "\n",
    "# 交叉验证\n",
    "adv_cv_results = lgb.cv(\n",
    "    params,\n",
    "    adv_data,\n",
    "    num_boost_round=10000,\n",
    "    nfold=5,\n",
    "    categorical_feature=categorical_columns,\n",
    "    early_stopping_rounds=200,\n",
    "    verbose_eval=True,\n",
    "    seed=42)\n",
    "\n",
    "print('交叉验证中最优的AUC为 {:.5f}，对应的标准差为{:.5f}.'.format(\n",
    "    adv_cv_results['auc-mean'][-1], adv_cv_results['auc-stdv'][-1]))\n",
    "\n",
    "print('模型最优的迭代次数为{}.'.format(len(adv_cv_results['auc-mean'])))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "params['n_estimators'] = len(adv_cv_results['auc-mean'])\n",
    "\n",
    "model_adv = lgb.LGBMClassifier(**params)\n",
    "model_adv.fit(df_adv.drop('Is_Test', axis=1), df_adv.loc[:, 'Is_Test'])\n",
    "\n",
    "preds_adv = model_adv.predict_proba(df_adv.drop('Is_Test', axis=1))[:, 1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "(7698,)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 125
    }
   ],
   "source": [
    "preds_adv.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "None\n",
      "[1]\tcv_agg's multi_logloss: 1.28295 + 0.000539608\n[2]\tcv_agg's multi_logloss: 1.28043 + 0.00055615\n[3]\tcv_agg's multi_logloss: 1.27806 + 0.000633\n[4]\tcv_agg's multi_logloss: 1.27577 + 0.000653991\n[5]\tcv_agg's multi_logloss: 1.27357 + 0.000704831\n[6]\tcv_agg's multi_logloss: 1.27126 + 0.00076547\n[7]\tcv_agg's multi_logloss: 1.26882 + 0.000806752\n[8]\tcv_agg's multi_logloss: 1.2666 + 0.000899607\n[9]\tcv_agg's multi_logloss: 1.26429 + 0.00100225\n[10]\tcv_agg's multi_logloss: 1.2622 + 0.00105727\n",
      "[11]\tcv_agg's multi_logloss: 1.25999 + 0.00111027\n[12]\tcv_agg's multi_logloss: 1.25805 + 0.00120688\n",
      "[13]\tcv_agg's multi_logloss: 1.25585 + 0.00129493\n[14]\tcv_agg's multi_logloss: 1.25372 + 0.00148718\n[15]\tcv_agg's multi_logloss: 1.25164 + 0.00160326\n[16]\tcv_agg's multi_logloss: 1.24979 + 0.00169063\n[17]\tcv_agg's multi_logloss: 1.24787 + 0.00171518\n[18]\tcv_agg's multi_logloss: 1.24592 + 0.00175626\n[19]\tcv_agg's multi_logloss: 1.24416 + 0.00173776\n[20]\tcv_agg's multi_logloss: 1.2422 + 0.0017871\n[21]\tcv_agg's multi_logloss: 1.24039 + 0.0017678\n[22]\tcv_agg's multi_logloss: 1.23885 + 0.00178808\n",
      "[23]\tcv_agg's multi_logloss: 1.23703 + 0.00181626\n[24]\tcv_agg's multi_logloss: 1.23522 + 0.00182583\n[25]\tcv_agg's multi_logloss: 1.23337 + 0.00187208\n",
      "[26]\tcv_agg's multi_logloss: 1.23155 + 0.00194787\n[27]\tcv_agg's multi_logloss: 1.22971 + 0.00195039\n[28]\tcv_agg's multi_logloss: 1.2279 + 0.00197164\n[29]\tcv_agg's multi_logloss: 1.22607 + 0.00197921\n[30]\tcv_agg's multi_logloss: 1.22434 + 0.00204587\n[31]\tcv_agg's multi_logloss: 1.22279 + 0.00207843\n[32]\tcv_agg's multi_logloss: 1.22113 + 0.00213184\n[33]\tcv_agg's multi_logloss: 1.21954 + 0.00216772\n[34]\tcv_agg's multi_logloss: 1.21796 + 0.00218775\n[35]\tcv_agg's multi_logloss: 1.21645 + 0.00224953\n",
      "[36]\tcv_agg's multi_logloss: 1.21493 + 0.00241831\n[37]\tcv_agg's multi_logloss: 1.21339 + 0.00250649\n[38]\tcv_agg's multi_logloss: 1.21182 + 0.00255664\n",
      "[39]\tcv_agg's multi_logloss: 1.21029 + 0.00266532\n[40]\tcv_agg's multi_logloss: 1.20893 + 0.00278914\n[41]\tcv_agg's multi_logloss: 1.20762 + 0.00286308\n[42]\tcv_agg's multi_logloss: 1.20628 + 0.00290881\n[43]\tcv_agg's multi_logloss: 1.20488 + 0.00289365\n[44]\tcv_agg's multi_logloss: 1.20348 + 0.00295188\n[45]\tcv_agg's multi_logloss: 1.20211 + 0.00299404\n[46]\tcv_agg's multi_logloss: 1.20071 + 0.00303175\n[47]\tcv_agg's multi_logloss: 1.19939 + 0.00298411\n[48]\tcv_agg's multi_logloss: 1.198 + 0.0030326\n",
      "[49]\tcv_agg's multi_logloss: 1.1967 + 0.00309293\n[50]\tcv_agg's multi_logloss: 1.19529 + 0.00317396\n[51]\tcv_agg's multi_logloss: 1.19398 + 0.00323556\n",
      "[52]\tcv_agg's multi_logloss: 1.19275 + 0.00330086\n[53]\tcv_agg's multi_logloss: 1.19159 + 0.00334534\n[54]\tcv_agg's multi_logloss: 1.19032 + 0.00340397\n[55]\tcv_agg's multi_logloss: 1.18928 + 0.00346098\n[56]\tcv_agg's multi_logloss: 1.1882 + 0.00358247\n[57]\tcv_agg's multi_logloss: 1.18705 + 0.00367764\n[58]\tcv_agg's multi_logloss: 1.18584 + 0.00374169\n[59]\tcv_agg's multi_logloss: 1.18465 + 0.00381992\n[60]\tcv_agg's multi_logloss: 1.18354 + 0.00394395\n[61]\tcv_agg's multi_logloss: 1.1824 + 0.0040119\n",
      "[62]\tcv_agg's multi_logloss: 1.18134 + 0.00405841\n[63]\tcv_agg's multi_logloss: 1.18031 + 0.00412694\n[64]\tcv_agg's multi_logloss: 1.1791 + 0.00424126\n",
      "[65]\tcv_agg's multi_logloss: 1.17795 + 0.00436066\n[66]\tcv_agg's multi_logloss: 1.17685 + 0.00443311\n[67]\tcv_agg's multi_logloss: 1.17585 + 0.0044403\n[68]\tcv_agg's multi_logloss: 1.17485 + 0.00452777\n[69]\tcv_agg's multi_logloss: 1.17387 + 0.0045817\n[70]\tcv_agg's multi_logloss: 1.17287 + 0.00465448\n[71]\tcv_agg's multi_logloss: 1.17181 + 0.00469132\n[72]\tcv_agg's multi_logloss: 1.17082 + 0.00475749\n[73]\tcv_agg's multi_logloss: 1.16992 + 0.00481098\n[74]\tcv_agg's multi_logloss: 1.16895 + 0.00484238\n",
      "[75]\tcv_agg's multi_logloss: 1.16794 + 0.00487835\n[76]\tcv_agg's multi_logloss: 1.16697 + 0.00488162\n[77]\tcv_agg's multi_logloss: 1.16597 + 0.00500669\n",
      "[78]\tcv_agg's multi_logloss: 1.1649 + 0.00508353\n[79]\tcv_agg's multi_logloss: 1.16393 + 0.0052178\n[80]\tcv_agg's multi_logloss: 1.1629 + 0.00531477\n[81]\tcv_agg's multi_logloss: 1.16195 + 0.00535658\n[82]\tcv_agg's multi_logloss: 1.16099 + 0.00536629\n[83]\tcv_agg's multi_logloss: 1.16006 + 0.00542227\n[84]\tcv_agg's multi_logloss: 1.15918 + 0.00541835\n[85]\tcv_agg's multi_logloss: 1.15826 + 0.00546316\n[86]\tcv_agg's multi_logloss: 1.15744 + 0.00549884\n[87]\tcv_agg's multi_logloss: 1.15658 + 0.00556701\n",
      "[88]\tcv_agg's multi_logloss: 1.1558 + 0.0055222\n[89]\tcv_agg's multi_logloss: 1.15499 + 0.00549197\n[90]\tcv_agg's multi_logloss: 1.15418 + 0.00548598\n",
      "[91]\tcv_agg's multi_logloss: 1.15344 + 0.00555926\n[92]\tcv_agg's multi_logloss: 1.15267 + 0.00559607\n[93]\tcv_agg's multi_logloss: 1.15189 + 0.00564339\n[94]\tcv_agg's multi_logloss: 1.15113 + 0.00567319\n[95]\tcv_agg's multi_logloss: 1.15032 + 0.00571694\n[96]\tcv_agg's multi_logloss: 1.14957 + 0.00580263\n[97]\tcv_agg's multi_logloss: 1.1488 + 0.00584079\n[98]\tcv_agg's multi_logloss: 1.14806 + 0.00590795\n[99]\tcv_agg's multi_logloss: 1.14732 + 0.00595802\n[100]\tcv_agg's multi_logloss: 1.14662 + 0.00602639\n",
      "[101]\tcv_agg's multi_logloss: 1.14596 + 0.0060123\n[102]\tcv_agg's multi_logloss: 1.14532 + 0.00599803\n",
      "[103]\tcv_agg's multi_logloss: 1.14459 + 0.00607068\n[104]\tcv_agg's multi_logloss: 1.14395 + 0.00610962\n[105]\tcv_agg's multi_logloss: 1.14333 + 0.00617207\n[106]\tcv_agg's multi_logloss: 1.14266 + 0.00627721\n[107]\tcv_agg's multi_logloss: 1.14201 + 0.00642636\n[108]\tcv_agg's multi_logloss: 1.14136 + 0.00647244\n[109]\tcv_agg's multi_logloss: 1.14076 + 0.00647687\n[110]\tcv_agg's multi_logloss: 1.14013 + 0.00653024\n[111]\tcv_agg's multi_logloss: 1.13957 + 0.00660074\n[112]\tcv_agg's multi_logloss: 1.13899 + 0.00669342\n",
      "[113]\tcv_agg's multi_logloss: 1.13837 + 0.0067362\n[114]\tcv_agg's multi_logloss: 1.13782 + 0.0068074\n",
      "[115]\tcv_agg's multi_logloss: 1.13717 + 0.00691087\n[116]\tcv_agg's multi_logloss: 1.13655 + 0.00699871\n[117]\tcv_agg's multi_logloss: 1.13604 + 0.00703566\n[118]\tcv_agg's multi_logloss: 1.13555 + 0.00707318\n[119]\tcv_agg's multi_logloss: 1.13501 + 0.00709082\n[120]\tcv_agg's multi_logloss: 1.13439 + 0.00715225\n[121]\tcv_agg's multi_logloss: 1.13386 + 0.0072088\n[122]\tcv_agg's multi_logloss: 1.13329 + 0.00726504\n[123]\tcv_agg's multi_logloss: 1.1328 + 0.0073257\n[124]\tcv_agg's multi_logloss: 1.13228 + 0.00742535\n",
      "[125]\tcv_agg's multi_logloss: 1.13178 + 0.00749326\n[126]\tcv_agg's multi_logloss: 1.13124 + 0.00758923\n",
      "[127]\tcv_agg's multi_logloss: 1.13073 + 0.00768941\n[128]\tcv_agg's multi_logloss: 1.13013 + 0.00776469\n[129]\tcv_agg's multi_logloss: 1.12967 + 0.0078473\n[130]\tcv_agg's multi_logloss: 1.1292 + 0.0079069\n[131]\tcv_agg's multi_logloss: 1.12868 + 0.00800157\n[132]\tcv_agg's multi_logloss: 1.1282 + 0.00810537\n[133]\tcv_agg's multi_logloss: 1.12776 + 0.00819065\n[134]\tcv_agg's multi_logloss: 1.12723 + 0.00825339\n[135]\tcv_agg's multi_logloss: 1.12676 + 0.00834872\n[136]\tcv_agg's multi_logloss: 1.12632 + 0.00838291\n[137]\tcv_agg's multi_logloss: 1.12583 + 0.008444\n",
      "[138]\tcv_agg's multi_logloss: 1.12543 + 0.00850394\n[139]\tcv_agg's multi_logloss: 1.12491 + 0.00858467\n",
      "[140]\tcv_agg's multi_logloss: 1.12448 + 0.00866769\n[141]\tcv_agg's multi_logloss: 1.12397 + 0.0087264\n[142]\tcv_agg's multi_logloss: 1.12353 + 0.00881845\n[143]\tcv_agg's multi_logloss: 1.12311 + 0.00887374\n[144]\tcv_agg's multi_logloss: 1.12265 + 0.00898217\n[145]\tcv_agg's multi_logloss: 1.12215 + 0.00909721\n[146]\tcv_agg's multi_logloss: 1.12178 + 0.00911024\n[147]\tcv_agg's multi_logloss: 1.12133 + 0.00916859\n[148]\tcv_agg's multi_logloss: 1.12094 + 0.00923686\n[149]\tcv_agg's multi_logloss: 1.12051 + 0.0093007\n[150]\tcv_agg's multi_logloss: 1.12011 + 0.0093862\n",
      "[151]\tcv_agg's multi_logloss: 1.11974 + 0.00945759\n[152]\tcv_agg's multi_logloss: 1.11945 + 0.00950489\n",
      "[153]\tcv_agg's multi_logloss: 1.11912 + 0.00957545\n[154]\tcv_agg's multi_logloss: 1.11882 + 0.00967734\n[155]\tcv_agg's multi_logloss: 1.11841 + 0.00973057\n[156]\tcv_agg's multi_logloss: 1.11802 + 0.00979487\n[157]\tcv_agg's multi_logloss: 1.11762 + 0.00990392\n[158]\tcv_agg's multi_logloss: 1.11726 + 0.00992525\n[159]\tcv_agg's multi_logloss: 1.11689 + 0.010027\n[160]\tcv_agg's multi_logloss: 1.11655 + 0.0101394\n[161]\tcv_agg's multi_logloss: 1.11618 + 0.0102056\n[162]\tcv_agg's multi_logloss: 1.11592 + 0.010328\n[163]\tcv_agg's multi_logloss: 1.11557 + 0.0103853\n",
      "[164]\tcv_agg's multi_logloss: 1.11519 + 0.0104815\n[165]\tcv_agg's multi_logloss: 1.11482 + 0.0106016\n",
      "[166]\tcv_agg's multi_logloss: 1.11446 + 0.0105776\n[167]\tcv_agg's multi_logloss: 1.11406 + 0.0106249\n[168]\tcv_agg's multi_logloss: 1.11369 + 0.0106567\n[169]\tcv_agg's multi_logloss: 1.11338 + 0.0106651\n[170]\tcv_agg's multi_logloss: 1.11308 + 0.0106802\n[171]\tcv_agg's multi_logloss: 1.11278 + 0.0107365\n[172]\tcv_agg's multi_logloss: 1.11246 + 0.0107625\n[173]\tcv_agg's multi_logloss: 1.11215 + 0.0107973\n[174]\tcv_agg's multi_logloss: 1.11182 + 0.0109098\n[175]\tcv_agg's multi_logloss: 1.11147 + 0.0109466\n[176]\tcv_agg's multi_logloss: 1.11115 + 0.01098\n",
      "[177]\tcv_agg's multi_logloss: 1.11082 + 0.0110189\n[178]\tcv_agg's multi_logloss: 1.11051 + 0.011096\n",
      "[179]\tcv_agg's multi_logloss: 1.1102 + 0.0110868\n[180]\tcv_agg's multi_logloss: 1.10993 + 0.0111383\n[181]\tcv_agg's multi_logloss: 1.10959 + 0.0111591\n[182]\tcv_agg's multi_logloss: 1.10928 + 0.0111864\n[183]\tcv_agg's multi_logloss: 1.10902 + 0.0112298\n[184]\tcv_agg's multi_logloss: 1.10872 + 0.0112722\n[185]\tcv_agg's multi_logloss: 1.10849 + 0.0113381\n[186]\tcv_agg's multi_logloss: 1.10822 + 0.0113787\n[187]\tcv_agg's multi_logloss: 1.10794 + 0.0114313\n[188]\tcv_agg's multi_logloss: 1.10762 + 0.0114672\n[189]\tcv_agg's multi_logloss: 1.10737 + 0.0114699\n",
      "[190]\tcv_agg's multi_logloss: 1.10713 + 0.011472\n[191]\tcv_agg's multi_logloss: 1.10688 + 0.0115151\n",
      "[192]\tcv_agg's multi_logloss: 1.10666 + 0.0114999\n[193]\tcv_agg's multi_logloss: 1.10644 + 0.0114737\n[194]\tcv_agg's multi_logloss: 1.1062 + 0.0114828\n[195]\tcv_agg's multi_logloss: 1.10593 + 0.0114934\n[196]\tcv_agg's multi_logloss: 1.10564 + 0.0115456\n[197]\tcv_agg's multi_logloss: 1.10537 + 0.0115438\n[198]\tcv_agg's multi_logloss: 1.10515 + 0.0116172\n[199]\tcv_agg's multi_logloss: 1.10491 + 0.0116805\n[200]\tcv_agg's multi_logloss: 1.10462 + 0.0116832\n[201]\tcv_agg's multi_logloss: 1.10445 + 0.0117283\n[202]\tcv_agg's multi_logloss: 1.10423 + 0.0117836\n",
      "[203]\tcv_agg's multi_logloss: 1.10398 + 0.0118099\n[204]\tcv_agg's multi_logloss: 1.10369 + 0.0118803\n",
      "[205]\tcv_agg's multi_logloss: 1.1035 + 0.0119321\n[206]\tcv_agg's multi_logloss: 1.10331 + 0.0119679\n[207]\tcv_agg's multi_logloss: 1.10308 + 0.0120047\n[208]\tcv_agg's multi_logloss: 1.1028 + 0.012008\n[209]\tcv_agg's multi_logloss: 1.10256 + 0.0120282\n[210]\tcv_agg's multi_logloss: 1.10229 + 0.0120894\n[211]\tcv_agg's multi_logloss: 1.10207 + 0.0121454\n[212]\tcv_agg's multi_logloss: 1.10185 + 0.0122194\n[213]\tcv_agg's multi_logloss: 1.10161 + 0.012273\n[214]\tcv_agg's multi_logloss: 1.10135 + 0.0123525\n",
      "[215]\tcv_agg's multi_logloss: 1.10115 + 0.0124407\n[216]\tcv_agg's multi_logloss: 1.10093 + 0.0124693\n",
      "[217]\tcv_agg's multi_logloss: 1.10067 + 0.0125154\n[218]\tcv_agg's multi_logloss: 1.10042 + 0.0125675\n[219]\tcv_agg's multi_logloss: 1.10022 + 0.01256\n[220]\tcv_agg's multi_logloss: 1.10004 + 0.0125733\n[221]\tcv_agg's multi_logloss: 1.09985 + 0.0126392\n[222]\tcv_agg's multi_logloss: 1.09966 + 0.0126706\n[223]\tcv_agg's multi_logloss: 1.09947 + 0.0126994\n[224]\tcv_agg's multi_logloss: 1.09928 + 0.0127787\n[225]\tcv_agg's multi_logloss: 1.0991 + 0.0128548\n[226]\tcv_agg's multi_logloss: 1.09894 + 0.0128375\n[227]\tcv_agg's multi_logloss: 1.09879 + 0.0128694\n",
      "[228]\tcv_agg's multi_logloss: 1.09858 + 0.012832\n[229]\tcv_agg's multi_logloss: 1.09836 + 0.0128196\n",
      "[230]\tcv_agg's multi_logloss: 1.0982 + 0.0128472\n[231]\tcv_agg's multi_logloss: 1.098 + 0.0128924\n[232]\tcv_agg's multi_logloss: 1.09784 + 0.0130004\n[233]\tcv_agg's multi_logloss: 1.09772 + 0.0130385\n[234]\tcv_agg's multi_logloss: 1.09751 + 0.0131102\n[235]\tcv_agg's multi_logloss: 1.09735 + 0.0131843\n[236]\tcv_agg's multi_logloss: 1.09719 + 0.0131783\n[237]\tcv_agg's multi_logloss: 1.09708 + 0.0132084\n[238]\tcv_agg's multi_logloss: 1.09693 + 0.013219\n[239]\tcv_agg's multi_logloss: 1.09674 + 0.0132623\n[240]\tcv_agg's multi_logloss: 1.09656 + 0.0133341\n",
      "[241]\tcv_agg's multi_logloss: 1.09638 + 0.013339\n[242]\tcv_agg's multi_logloss: 1.0962 + 0.0134041\n",
      "[243]\tcv_agg's multi_logloss: 1.09599 + 0.0134482\n[244]\tcv_agg's multi_logloss: 1.09576 + 0.0134533\n[245]\tcv_agg's multi_logloss: 1.09558 + 0.0135176\n[246]\tcv_agg's multi_logloss: 1.09542 + 0.0135962\n[247]\tcv_agg's multi_logloss: 1.09527 + 0.013621\n[248]\tcv_agg's multi_logloss: 1.09514 + 0.0136818\n[249]\tcv_agg's multi_logloss: 1.09502 + 0.0137638\n[250]\tcv_agg's multi_logloss: 1.09492 + 0.0138323\n[251]\tcv_agg's multi_logloss: 1.09476 + 0.0138568\n[252]\tcv_agg's multi_logloss: 1.09463 + 0.0138917\n[253]\tcv_agg's multi_logloss: 1.09447 + 0.0138589\n",
      "[254]\tcv_agg's multi_logloss: 1.09428 + 0.013883\n[255]\tcv_agg's multi_logloss: 1.09415 + 0.0138972\n",
      "[256]\tcv_agg's multi_logloss: 1.094 + 0.0139598\n[257]\tcv_agg's multi_logloss: 1.09387 + 0.0139245\n[258]\tcv_agg's multi_logloss: 1.09372 + 0.0139951\n[259]\tcv_agg's multi_logloss: 1.09357 + 0.0139899\n[260]\tcv_agg's multi_logloss: 1.0934 + 0.0140514\n[261]\tcv_agg's multi_logloss: 1.09334 + 0.014049\n[262]\tcv_agg's multi_logloss: 1.09321 + 0.0140545\n[263]\tcv_agg's multi_logloss: 1.09308 + 0.0140668\n[264]\tcv_agg's multi_logloss: 1.093 + 0.0141328\n[265]\tcv_agg's multi_logloss: 1.09292 + 0.0141203\n[266]\tcv_agg's multi_logloss: 1.09276 + 0.0141831\n",
      "[267]\tcv_agg's multi_logloss: 1.09257 + 0.0142238\n[268]\tcv_agg's multi_logloss: 1.09246 + 0.0142841\n",
      "[269]\tcv_agg's multi_logloss: 1.09232 + 0.0143129\n[270]\tcv_agg's multi_logloss: 1.09217 + 0.0143142\n[271]\tcv_agg's multi_logloss: 1.09206 + 0.0143673\n[272]\tcv_agg's multi_logloss: 1.09195 + 0.0144361\n[273]\tcv_agg's multi_logloss: 1.09182 + 0.0145098\n[274]\tcv_agg's multi_logloss: 1.09171 + 0.0145693\n[275]\tcv_agg's multi_logloss: 1.09163 + 0.0146308\n[276]\tcv_agg's multi_logloss: 1.09154 + 0.0146527\n[277]\tcv_agg's multi_logloss: 1.0914 + 0.0146688\n[278]\tcv_agg's multi_logloss: 1.09127 + 0.0147449\n[279]\tcv_agg's multi_logloss: 1.09115 + 0.0147464\n",
      "[280]\tcv_agg's multi_logloss: 1.09105 + 0.0147515\n[281]\tcv_agg's multi_logloss: 1.09093 + 0.0147384\n",
      "[282]\tcv_agg's multi_logloss: 1.09085 + 0.0148169\n[283]\tcv_agg's multi_logloss: 1.09075 + 0.014863\n[284]\tcv_agg's multi_logloss: 1.09069 + 0.0148864\n[285]\tcv_agg's multi_logloss: 1.09058 + 0.0149253\n[286]\tcv_agg's multi_logloss: 1.09047 + 0.0150264\n[287]\tcv_agg's multi_logloss: 1.09036 + 0.015088\n[288]\tcv_agg's multi_logloss: 1.09026 + 0.0151466\n[289]\tcv_agg's multi_logloss: 1.09012 + 0.0152474\n[290]\tcv_agg's multi_logloss: 1.09002 + 0.0152794\n[291]\tcv_agg's multi_logloss: 1.08993 + 0.0153127\n[292]\tcv_agg's multi_logloss: 1.08986 + 0.0153703\n",
      "[293]\tcv_agg's multi_logloss: 1.08976 + 0.0153921\n[294]\tcv_agg's multi_logloss: 1.0897 + 0.0154547\n",
      "[295]\tcv_agg's multi_logloss: 1.08961 + 0.0154503\n[296]\tcv_agg's multi_logloss: 1.08952 + 0.0154628\n[297]\tcv_agg's multi_logloss: 1.08946 + 0.0155375\n[298]\tcv_agg's multi_logloss: 1.08935 + 0.0156039\n[299]\tcv_agg's multi_logloss: 1.08922 + 0.0156055\n[300]\tcv_agg's multi_logloss: 1.08908 + 0.0156505\n[301]\tcv_agg's multi_logloss: 1.08896 + 0.0156017\n[302]\tcv_agg's multi_logloss: 1.08889 + 0.0156113\n[303]\tcv_agg's multi_logloss: 1.08885 + 0.0156091\n[304]\tcv_agg's multi_logloss: 1.08875 + 0.0155787\n[305]\tcv_agg's multi_logloss: 1.08871 + 0.0155775\n",
      "[306]\tcv_agg's multi_logloss: 1.08857 + 0.0156163\n[307]\tcv_agg's multi_logloss: 1.08847 + 0.0156652\n",
      "[308]\tcv_agg's multi_logloss: 1.08838 + 0.0156615\n[309]\tcv_agg's multi_logloss: 1.08832 + 0.0156616\n[310]\tcv_agg's multi_logloss: 1.08827 + 0.0156756\n[311]\tcv_agg's multi_logloss: 1.08818 + 0.0156863\n[312]\tcv_agg's multi_logloss: 1.08811 + 0.0156835\n[313]\tcv_agg's multi_logloss: 1.08805 + 0.0156782\n[314]\tcv_agg's multi_logloss: 1.08802 + 0.0156768\n[315]\tcv_agg's multi_logloss: 1.08794 + 0.0156967\n[316]\tcv_agg's multi_logloss: 1.08787 + 0.0157355\n[317]\tcv_agg's multi_logloss: 1.08783 + 0.0157478\n[318]\tcv_agg's multi_logloss: 1.08778 + 0.015762\n",
      "[319]\tcv_agg's multi_logloss: 1.08767 + 0.0158005\n[320]\tcv_agg's multi_logloss: 1.08759 + 0.0158295\n",
      "[321]\tcv_agg's multi_logloss: 1.08744 + 0.0158822\n[322]\tcv_agg's multi_logloss: 1.08742 + 0.0159299\n[323]\tcv_agg's multi_logloss: 1.08735 + 0.0159844\n[324]\tcv_agg's multi_logloss: 1.08726 + 0.0160491\n[325]\tcv_agg's multi_logloss: 1.08718 + 0.0161184\n[326]\tcv_agg's multi_logloss: 1.08711 + 0.0161523\n[327]\tcv_agg's multi_logloss: 1.08704 + 0.0162098\n[328]\tcv_agg's multi_logloss: 1.08695 + 0.0162141\n[329]\tcv_agg's multi_logloss: 1.08687 + 0.0161803\n[330]\tcv_agg's multi_logloss: 1.08679 + 0.0162371\n[331]\tcv_agg's multi_logloss: 1.08675 + 0.0162675\n",
      "[332]\tcv_agg's multi_logloss: 1.08674 + 0.0163557\n[333]\tcv_agg's multi_logloss: 1.08673 + 0.0164035\n",
      "[334]\tcv_agg's multi_logloss: 1.08671 + 0.0164173\n[335]\tcv_agg's multi_logloss: 1.08668 + 0.0164584\n[336]\tcv_agg's multi_logloss: 1.08662 + 0.0164645\n[337]\tcv_agg's multi_logloss: 1.0866 + 0.0164465\n[338]\tcv_agg's multi_logloss: 1.08654 + 0.0164454\n[339]\tcv_agg's multi_logloss: 1.08647 + 0.0164553\n[340]\tcv_agg's multi_logloss: 1.08639 + 0.0164833\n[341]\tcv_agg's multi_logloss: 1.08632 + 0.0165283\n[342]\tcv_agg's multi_logloss: 1.08625 + 0.016539\n[343]\tcv_agg's multi_logloss: 1.08617 + 0.0165581\n",
      "[344]\tcv_agg's multi_logloss: 1.08609 + 0.0165835\n[345]\tcv_agg's multi_logloss: 1.08605 + 0.0165973\n[346]\tcv_agg's multi_logloss: 1.08597 + 0.01659\n",
      "[347]\tcv_agg's multi_logloss: 1.08585 + 0.0166061\n[348]\tcv_agg's multi_logloss: 1.08579 + 0.0166096\n[349]\tcv_agg's multi_logloss: 1.08573 + 0.0166479\n[350]\tcv_agg's multi_logloss: 1.0856 + 0.0167016\n[351]\tcv_agg's multi_logloss: 1.08555 + 0.0167158\n[352]\tcv_agg's multi_logloss: 1.08551 + 0.0166949\n[353]\tcv_agg's multi_logloss: 1.08546 + 0.0167277\n[354]\tcv_agg's multi_logloss: 1.08545 + 0.0166951\n[355]\tcv_agg's multi_logloss: 1.08543 + 0.0166975\n[356]\tcv_agg's multi_logloss: 1.08537 + 0.0167561\n",
      "[357]\tcv_agg's multi_logloss: 1.08532 + 0.0167765\n[358]\tcv_agg's multi_logloss: 1.08526 + 0.0168157\n[359]\tcv_agg's multi_logloss: 1.0852 + 0.0168231\n",
      "[360]\tcv_agg's multi_logloss: 1.08512 + 0.0168553\n[361]\tcv_agg's multi_logloss: 1.08508 + 0.0169097\n[362]\tcv_agg's multi_logloss: 1.08504 + 0.0169589\n[363]\tcv_agg's multi_logloss: 1.08499 + 0.0169582\n[364]\tcv_agg's multi_logloss: 1.08501 + 0.0169943\n[365]\tcv_agg's multi_logloss: 1.08507 + 0.0170359\n[366]\tcv_agg's multi_logloss: 1.08498 + 0.0170889\n[367]\tcv_agg's multi_logloss: 1.0849 + 0.0171687\n[368]\tcv_agg's multi_logloss: 1.08487 + 0.0172293\n[369]\tcv_agg's multi_logloss: 1.08481 + 0.0172695\n",
      "[370]\tcv_agg's multi_logloss: 1.0847 + 0.0173094\n[371]\tcv_agg's multi_logloss: 1.08465 + 0.0173288\n[372]\tcv_agg's multi_logloss: 1.08455 + 0.0173688\n",
      "[373]\tcv_agg's multi_logloss: 1.08449 + 0.0174029\n[374]\tcv_agg's multi_logloss: 1.08448 + 0.0174049\n[375]\tcv_agg's multi_logloss: 1.08447 + 0.017407\n[376]\tcv_agg's multi_logloss: 1.08439 + 0.0174552\n[377]\tcv_agg's multi_logloss: 1.08433 + 0.0174714\n[378]\tcv_agg's multi_logloss: 1.08427 + 0.017536\n[379]\tcv_agg's multi_logloss: 1.08422 + 0.0175332\n[380]\tcv_agg's multi_logloss: 1.08422 + 0.0175918\n[381]\tcv_agg's multi_logloss: 1.08412 + 0.0176545\n[382]\tcv_agg's multi_logloss: 1.08407 + 0.0176837\n",
      "[383]\tcv_agg's multi_logloss: 1.08405 + 0.0177407\n[384]\tcv_agg's multi_logloss: 1.08398 + 0.0177567\n[385]\tcv_agg's multi_logloss: 1.08394 + 0.0177679\n",
      "[386]\tcv_agg's multi_logloss: 1.08385 + 0.017808\n[387]\tcv_agg's multi_logloss: 1.08387 + 0.0178534\n[388]\tcv_agg's multi_logloss: 1.08382 + 0.0179167\n[389]\tcv_agg's multi_logloss: 1.08382 + 0.0179674\n[390]\tcv_agg's multi_logloss: 1.08375 + 0.0180107\n[391]\tcv_agg's multi_logloss: 1.0837 + 0.0180222\n[392]\tcv_agg's multi_logloss: 1.08367 + 0.0180358\n[393]\tcv_agg's multi_logloss: 1.08363 + 0.0180374\n[394]\tcv_agg's multi_logloss: 1.08358 + 0.018037\n[395]\tcv_agg's multi_logloss: 1.08355 + 0.0180593\n",
      "[396]\tcv_agg's multi_logloss: 1.08353 + 0.0180348\n[397]\tcv_agg's multi_logloss: 1.08347 + 0.0180764\n[398]\tcv_agg's multi_logloss: 1.08343 + 0.0181169\n",
      "[399]\tcv_agg's multi_logloss: 1.08343 + 0.0181286\n[400]\tcv_agg's multi_logloss: 1.08344 + 0.0181305\n[401]\tcv_agg's multi_logloss: 1.08334 + 0.0181115\n[402]\tcv_agg's multi_logloss: 1.08328 + 0.0180953\n[403]\tcv_agg's multi_logloss: 1.0832 + 0.0180866\n[404]\tcv_agg's multi_logloss: 1.08316 + 0.0180907\n[405]\tcv_agg's multi_logloss: 1.08312 + 0.0181124\n[406]\tcv_agg's multi_logloss: 1.08309 + 0.0181449\n[407]\tcv_agg's multi_logloss: 1.08307 + 0.0181616\n[408]\tcv_agg's multi_logloss: 1.08304 + 0.0181626\n",
      "[409]\tcv_agg's multi_logloss: 1.083 + 0.0181761\n[410]\tcv_agg's multi_logloss: 1.08299 + 0.0181861\n[411]\tcv_agg's multi_logloss: 1.08294 + 0.0182146\n",
      "[412]\tcv_agg's multi_logloss: 1.08285 + 0.0182543\n[413]\tcv_agg's multi_logloss: 1.08281 + 0.0182557\n[414]\tcv_agg's multi_logloss: 1.0828 + 0.0182744\n[415]\tcv_agg's multi_logloss: 1.08277 + 0.0182906\n[416]\tcv_agg's multi_logloss: 1.08274 + 0.0183019\n[417]\tcv_agg's multi_logloss: 1.08267 + 0.0182928\n[418]\tcv_agg's multi_logloss: 1.08264 + 0.0182585\n[419]\tcv_agg's multi_logloss: 1.08259 + 0.0182527\n[420]\tcv_agg's multi_logloss: 1.08247 + 0.0182465\n[421]\tcv_agg's multi_logloss: 1.08244 + 0.0182441\n",
      "[422]\tcv_agg's multi_logloss: 1.0824 + 0.0182807\n[423]\tcv_agg's multi_logloss: 1.08239 + 0.0183074\n[424]\tcv_agg's multi_logloss: 1.08234 + 0.0182651\n",
      "[425]\tcv_agg's multi_logloss: 1.08233 + 0.0182948\n[426]\tcv_agg's multi_logloss: 1.08232 + 0.0183288\n[427]\tcv_agg's multi_logloss: 1.08225 + 0.0183258\n[428]\tcv_agg's multi_logloss: 1.08224 + 0.0183468\n[429]\tcv_agg's multi_logloss: 1.08226 + 0.0183555\n[430]\tcv_agg's multi_logloss: 1.08222 + 0.0183749\n[431]\tcv_agg's multi_logloss: 1.08215 + 0.0183473\n[432]\tcv_agg's multi_logloss: 1.08211 + 0.0183017\n[433]\tcv_agg's multi_logloss: 1.08205 + 0.0182729\n[434]\tcv_agg's multi_logloss: 1.08203 + 0.0182633\n",
      "[435]\tcv_agg's multi_logloss: 1.08204 + 0.0182736\n[436]\tcv_agg's multi_logloss: 1.08199 + 0.018289\n[437]\tcv_agg's multi_logloss: 1.08201 + 0.018266\n",
      "[438]\tcv_agg's multi_logloss: 1.08196 + 0.018283\n[439]\tcv_agg's multi_logloss: 1.08197 + 0.0183069\n[440]\tcv_agg's multi_logloss: 1.08194 + 0.0183143\n[441]\tcv_agg's multi_logloss: 1.08192 + 0.0183341\n[442]\tcv_agg's multi_logloss: 1.08193 + 0.0183373\n[443]\tcv_agg's multi_logloss: 1.08193 + 0.0183608\n[444]\tcv_agg's multi_logloss: 1.08195 + 0.0183774\n[445]\tcv_agg's multi_logloss: 1.08192 + 0.0184148\n[446]\tcv_agg's multi_logloss: 1.08192 + 0.0184698\n[447]\tcv_agg's multi_logloss: 1.08189 + 0.018499\n",
      "[448]\tcv_agg's multi_logloss: 1.08182 + 0.0185517\n[449]\tcv_agg's multi_logloss: 1.08178 + 0.0185687\n[450]\tcv_agg's multi_logloss: 1.08174 + 0.0185758\n",
      "[451]\tcv_agg's multi_logloss: 1.08175 + 0.0186121\n[452]\tcv_agg's multi_logloss: 1.08176 + 0.0186441\n[453]\tcv_agg's multi_logloss: 1.08174 + 0.0186603\n[454]\tcv_agg's multi_logloss: 1.0817 + 0.0186372\n[455]\tcv_agg's multi_logloss: 1.08165 + 0.0186277\n[456]\tcv_agg's multi_logloss: 1.08165 + 0.0186269\n[457]\tcv_agg's multi_logloss: 1.08164 + 0.0186265\n[458]\tcv_agg's multi_logloss: 1.08162 + 0.0185761\n[459]\tcv_agg's multi_logloss: 1.08158 + 0.018604\n",
      "[460]\tcv_agg's multi_logloss: 1.08161 + 0.0186306\n[461]\tcv_agg's multi_logloss: 1.08156 + 0.0186379\n[462]\tcv_agg's multi_logloss: 1.08152 + 0.0186069\n[463]\tcv_agg's multi_logloss: 1.08147 + 0.0186173\n",
      "[464]\tcv_agg's multi_logloss: 1.08141 + 0.0186045\n[465]\tcv_agg's multi_logloss: 1.08139 + 0.0186144\n[466]\tcv_agg's multi_logloss: 1.08135 + 0.0185908\n[467]\tcv_agg's multi_logloss: 1.08134 + 0.0186239\n[468]\tcv_agg's multi_logloss: 1.08131 + 0.0186152\n[469]\tcv_agg's multi_logloss: 1.08126 + 0.0185967\n[470]\tcv_agg's multi_logloss: 1.08124 + 0.018573\n[471]\tcv_agg's multi_logloss: 1.08122 + 0.0186125\n[472]\tcv_agg's multi_logloss: 1.08117 + 0.0186121\n",
      "[473]\tcv_agg's multi_logloss: 1.08116 + 0.0186723\n[474]\tcv_agg's multi_logloss: 1.08111 + 0.0187483\n[475]\tcv_agg's multi_logloss: 1.08108 + 0.0187489\n[476]\tcv_agg's multi_logloss: 1.08106 + 0.0187684\n",
      "[477]\tcv_agg's multi_logloss: 1.08102 + 0.0187818\n[478]\tcv_agg's multi_logloss: 1.081 + 0.0187877\n[479]\tcv_agg's multi_logloss: 1.08097 + 0.0188153\n[480]\tcv_agg's multi_logloss: 1.08093 + 0.0187898\n[481]\tcv_agg's multi_logloss: 1.08089 + 0.0187847\n[482]\tcv_agg's multi_logloss: 1.08094 + 0.0188495\n[483]\tcv_agg's multi_logloss: 1.08096 + 0.0189004\n[484]\tcv_agg's multi_logloss: 1.08096 + 0.0189405\n[485]\tcv_agg's multi_logloss: 1.08095 + 0.0189441\n",
      "[486]\tcv_agg's multi_logloss: 1.08096 + 0.0189493\n[487]\tcv_agg's multi_logloss: 1.08096 + 0.0189112\n[488]\tcv_agg's multi_logloss: 1.08094 + 0.0188985\n[489]\tcv_agg's multi_logloss: 1.08096 + 0.0188951\n",
      "[490]\tcv_agg's multi_logloss: 1.08094 + 0.0188499\n[491]\tcv_agg's multi_logloss: 1.08092 + 0.0188633\n[492]\tcv_agg's multi_logloss: 1.08089 + 0.0189243\n[493]\tcv_agg's multi_logloss: 1.08089 + 0.018975\n[494]\tcv_agg's multi_logloss: 1.08085 + 0.0190057\n[495]\tcv_agg's multi_logloss: 1.08081 + 0.0189962\n[496]\tcv_agg's multi_logloss: 1.08082 + 0.0189987\n[497]\tcv_agg's multi_logloss: 1.08081 + 0.0190153\n[498]\tcv_agg's multi_logloss: 1.08079 + 0.0190304\n[499]\tcv_agg's multi_logloss: 1.08078 + 0.0190058\n",
      "[500]\tcv_agg's multi_logloss: 1.08084 + 0.0189832\n[501]\tcv_agg's multi_logloss: 1.08083 + 0.0189906\n[502]\tcv_agg's multi_logloss: 1.08087 + 0.0189878\n[503]\tcv_agg's multi_logloss: 1.08084 + 0.0189871\n",
      "[504]\tcv_agg's multi_logloss: 1.08086 + 0.0190124\n[505]\tcv_agg's multi_logloss: 1.08084 + 0.0190703\n[506]\tcv_agg's multi_logloss: 1.08085 + 0.0190718\n[507]\tcv_agg's multi_logloss: 1.08086 + 0.0190798\n[508]\tcv_agg's multi_logloss: 1.08088 + 0.0190615\n[509]\tcv_agg's multi_logloss: 1.08086 + 0.0190718\n[510]\tcv_agg's multi_logloss: 1.08085 + 0.0190986\n[511]\tcv_agg's multi_logloss: 1.08081 + 0.0191296\n[512]\tcv_agg's multi_logloss: 1.0808 + 0.0191322\n[513]\tcv_agg's multi_logloss: 1.08083 + 0.0191687\n",
      "[514]\tcv_agg's multi_logloss: 1.08083 + 0.0191721\n[515]\tcv_agg's multi_logloss: 1.08084 + 0.0192162\n[516]\tcv_agg's multi_logloss: 1.08082 + 0.0192153\n[517]\tcv_agg's multi_logloss: 1.08078 + 0.0192259\n",
      "[518]\tcv_agg's multi_logloss: 1.08078 + 0.0192212\n[519]\tcv_agg's multi_logloss: 1.08075 + 0.019213\n[520]\tcv_agg's multi_logloss: 1.0807 + 0.0192048\n[521]\tcv_agg's multi_logloss: 1.08069 + 0.0192006\n[522]\tcv_agg's multi_logloss: 1.08066 + 0.0192219\n[523]\tcv_agg's multi_logloss: 1.08063 + 0.019156\n[524]\tcv_agg's multi_logloss: 1.08063 + 0.0191736\n[525]\tcv_agg's multi_logloss: 1.08065 + 0.0191501\n[526]\tcv_agg's multi_logloss: 1.08068 + 0.0192041\n[527]\tcv_agg's multi_logloss: 1.08071 + 0.0191819\n",
      "[528]\tcv_agg's multi_logloss: 1.08073 + 0.0192151\n[529]\tcv_agg's multi_logloss: 1.08073 + 0.0192324\n[530]\tcv_agg's multi_logloss: 1.08075 + 0.0192541\n[531]\tcv_agg's multi_logloss: 1.08071 + 0.0192423\n",
      "[532]\tcv_agg's multi_logloss: 1.08066 + 0.0192514\n[533]\tcv_agg's multi_logloss: 1.08065 + 0.0192755\n[534]\tcv_agg's multi_logloss: 1.08065 + 0.0192821\n[535]\tcv_agg's multi_logloss: 1.08068 + 0.0192456\n[536]\tcv_agg's multi_logloss: 1.08071 + 0.0192569\n[537]\tcv_agg's multi_logloss: 1.08069 + 0.0192487\n[538]\tcv_agg's multi_logloss: 1.08071 + 0.0192697\n[539]\tcv_agg's multi_logloss: 1.08072 + 0.0192546\n[540]\tcv_agg's multi_logloss: 1.08076 + 0.019295\n[541]\tcv_agg's multi_logloss: 1.08076 + 0.0192858\n",
      "[542]\tcv_agg's multi_logloss: 1.08074 + 0.0193124\n[543]\tcv_agg's multi_logloss: 1.08072 + 0.019366\n[544]\tcv_agg's multi_logloss: 1.08069 + 0.0193734\n[545]\tcv_agg's multi_logloss: 1.08068 + 0.0193855\n",
      "[546]\tcv_agg's multi_logloss: 1.08067 + 0.0194191\n[547]\tcv_agg's multi_logloss: 1.08066 + 0.0194319\n[548]\tcv_agg's multi_logloss: 1.08066 + 0.0194495\n[549]\tcv_agg's multi_logloss: 1.08063 + 0.0194895\n[550]\tcv_agg's multi_logloss: 1.08063 + 0.0195201\n[551]\tcv_agg's multi_logloss: 1.0806 + 0.0194904\n[552]\tcv_agg's multi_logloss: 1.08058 + 0.0194485\n[553]\tcv_agg's multi_logloss: 1.08057 + 0.0194289\n[554]\tcv_agg's multi_logloss: 1.08055 + 0.0193917\n[555]\tcv_agg's multi_logloss: 1.08055 + 0.0193771\n",
      "[556]\tcv_agg's multi_logloss: 1.08059 + 0.0193527\n[557]\tcv_agg's multi_logloss: 1.0806 + 0.0193256\n[558]\tcv_agg's multi_logloss: 1.08059 + 0.0193026\n[559]\tcv_agg's multi_logloss: 1.0806 + 0.0193058\n",
      "[560]\tcv_agg's multi_logloss: 1.08058 + 0.0192754\n[561]\tcv_agg's multi_logloss: 1.08062 + 0.0192555\n[562]\tcv_agg's multi_logloss: 1.08059 + 0.019304\n[563]\tcv_agg's multi_logloss: 1.0806 + 0.0192738\n[564]\tcv_agg's multi_logloss: 1.08057 + 0.0192607\n[565]\tcv_agg's multi_logloss: 1.08055 + 0.0192994\n[566]\tcv_agg's multi_logloss: 1.08049 + 0.0193035\n[567]\tcv_agg's multi_logloss: 1.08045 + 0.0192925\n[568]\tcv_agg's multi_logloss: 1.08042 + 0.019296\n[569]\tcv_agg's multi_logloss: 1.08038 + 0.019338\n",
      "[570]\tcv_agg's multi_logloss: 1.08039 + 0.0193855\n[571]\tcv_agg's multi_logloss: 1.08042 + 0.0193244\n[572]\tcv_agg's multi_logloss: 1.08039 + 0.0193047\n[573]\tcv_agg's multi_logloss: 1.08039 + 0.0192677\n",
      "[574]\tcv_agg's multi_logloss: 1.08034 + 0.0192258\n[575]\tcv_agg's multi_logloss: 1.08032 + 0.0192027\n[576]\tcv_agg's multi_logloss: 1.0803 + 0.019257\n[577]\tcv_agg's multi_logloss: 1.08026 + 0.0193099\n[578]\tcv_agg's multi_logloss: 1.08027 + 0.019304\n[579]\tcv_agg's multi_logloss: 1.08024 + 0.0192766\n[580]\tcv_agg's multi_logloss: 1.08025 + 0.0193273\n[581]\tcv_agg's multi_logloss: 1.08026 + 0.0193236\n[582]\tcv_agg's multi_logloss: 1.08025 + 0.0193092\n[583]\tcv_agg's multi_logloss: 1.08023 + 0.0193172\n",
      "[584]\tcv_agg's multi_logloss: 1.08024 + 0.0193469\n[585]\tcv_agg's multi_logloss: 1.0802 + 0.0193301\n[586]\tcv_agg's multi_logloss: 1.08021 + 0.0193268\n[587]\tcv_agg's multi_logloss: 1.0802 + 0.0193148\n",
      "[588]\tcv_agg's multi_logloss: 1.08022 + 0.0193273\n[589]\tcv_agg's multi_logloss: 1.08022 + 0.0192903\n[590]\tcv_agg's multi_logloss: 1.08021 + 0.0192633\n[591]\tcv_agg's multi_logloss: 1.08019 + 0.0192827\n[592]\tcv_agg's multi_logloss: 1.08013 + 0.0192812\n[593]\tcv_agg's multi_logloss: 1.08012 + 0.0192474\n[594]\tcv_agg's multi_logloss: 1.08011 + 0.019277\n[595]\tcv_agg's multi_logloss: 1.08009 + 0.019284\n[596]\tcv_agg's multi_logloss: 1.08009 + 0.0193067\n[597]\tcv_agg's multi_logloss: 1.08007 + 0.0193252\n",
      "[598]\tcv_agg's multi_logloss: 1.08009 + 0.0193357\n[599]\tcv_agg's multi_logloss: 1.08009 + 0.0193527\n[600]\tcv_agg's multi_logloss: 1.0801 + 0.0193482\n[601]\tcv_agg's multi_logloss: 1.08004 + 0.0193901\n",
      "[602]\tcv_agg's multi_logloss: 1.07999 + 0.0193689\n[603]\tcv_agg's multi_logloss: 1.07995 + 0.0193837\n[604]\tcv_agg's multi_logloss: 1.07999 + 0.0193683\n[605]\tcv_agg's multi_logloss: 1.07994 + 0.0193403\n[606]\tcv_agg's multi_logloss: 1.0799 + 0.0193322\n[607]\tcv_agg's multi_logloss: 1.0799 + 0.0193273\n[608]\tcv_agg's multi_logloss: 1.07989 + 0.019317\n[609]\tcv_agg's multi_logloss: 1.07988 + 0.0193375\n[610]\tcv_agg's multi_logloss: 1.07989 + 0.0193495\n[611]\tcv_agg's multi_logloss: 1.0799 + 0.0193537\n",
      "[612]\tcv_agg's multi_logloss: 1.07992 + 0.0193748\n[613]\tcv_agg's multi_logloss: 1.07991 + 0.0193488\n[614]\tcv_agg's multi_logloss: 1.07994 + 0.0193658\n[615]\tcv_agg's multi_logloss: 1.07996 + 0.0193893\n",
      "[616]\tcv_agg's multi_logloss: 1.08 + 0.0194127\n[617]\tcv_agg's multi_logloss: 1.08 + 0.0194005\n[618]\tcv_agg's multi_logloss: 1.08002 + 0.0194351\n[619]\tcv_agg's multi_logloss: 1.08006 + 0.0193992\n[620]\tcv_agg's multi_logloss: 1.08008 + 0.0193898\n[621]\tcv_agg's multi_logloss: 1.08007 + 0.0193983\n[622]\tcv_agg's multi_logloss: 1.08005 + 0.0194165\n[623]\tcv_agg's multi_logloss: 1.08005 + 0.0194556\n[624]\tcv_agg's multi_logloss: 1.08006 + 0.0194626\n[625]\tcv_agg's multi_logloss: 1.08006 + 0.0194825\n",
      "[626]\tcv_agg's multi_logloss: 1.08006 + 0.0194903\n[627]\tcv_agg's multi_logloss: 1.08004 + 0.0195206\n[628]\tcv_agg's multi_logloss: 1.08004 + 0.0195159\n[629]\tcv_agg's multi_logloss: 1.08006 + 0.0195493\n",
      "[630]\tcv_agg's multi_logloss: 1.08009 + 0.0195712\n[631]\tcv_agg's multi_logloss: 1.08005 + 0.019591\n[632]\tcv_agg's multi_logloss: 1.08 + 0.0196021\n[633]\tcv_agg's multi_logloss: 1.07998 + 0.0196213\n[634]\tcv_agg's multi_logloss: 1.08001 + 0.0196392\n[635]\tcv_agg's multi_logloss: 1.08003 + 0.0196378\n[636]\tcv_agg's multi_logloss: 1.07999 + 0.0195928\n[637]\tcv_agg's multi_logloss: 1.07999 + 0.0196309\n[638]\tcv_agg's multi_logloss: 1.07999 + 0.0196376\n[639]\tcv_agg's multi_logloss: 1.08001 + 0.0196146\n",
      "[640]\tcv_agg's multi_logloss: 1.08002 + 0.0196006\n[641]\tcv_agg's multi_logloss: 1.08 + 0.0196117\n[642]\tcv_agg's multi_logloss: 1.07998 + 0.0196327\n[643]\tcv_agg's multi_logloss: 1.08002 + 0.0196498\n",
      "[644]\tcv_agg's multi_logloss: 1.08 + 0.0196563\n[645]\tcv_agg's multi_logloss: 1.08008 + 0.0196488\n[646]\tcv_agg's multi_logloss: 1.0801 + 0.0196397\n[647]\tcv_agg's multi_logloss: 1.08016 + 0.0196005\n[648]\tcv_agg's multi_logloss: 1.08016 + 0.0195962\n[649]\tcv_agg's multi_logloss: 1.08015 + 0.0195583\n[650]\tcv_agg's multi_logloss: 1.08017 + 0.0195424\n[651]\tcv_agg's multi_logloss: 1.08016 + 0.0195579\n[652]\tcv_agg's multi_logloss: 1.08013 + 0.0195659\n[653]\tcv_agg's multi_logloss: 1.08017 + 0.0195832\n",
      "[654]\tcv_agg's multi_logloss: 1.08021 + 0.0195934\n[655]\tcv_agg's multi_logloss: 1.08026 + 0.0196045\n[656]\tcv_agg's multi_logloss: 1.08028 + 0.0195889\n[657]\tcv_agg's multi_logloss: 1.08026 + 0.0195785\n",
      "[658]\tcv_agg's multi_logloss: 1.08024 + 0.0196042\n[659]\tcv_agg's multi_logloss: 1.08021 + 0.0195623\n[660]\tcv_agg's multi_logloss: 1.08018 + 0.0195524\n[661]\tcv_agg's multi_logloss: 1.08021 + 0.0196136\n[662]\tcv_agg's multi_logloss: 1.08019 + 0.0195842\n[663]\tcv_agg's multi_logloss: 1.08022 + 0.0196423\n[664]\tcv_agg's multi_logloss: 1.08021 + 0.0196929\n[665]\tcv_agg's multi_logloss: 1.08023 + 0.0196981\n[666]\tcv_agg's multi_logloss: 1.08025 + 0.0196728\n[667]\tcv_agg's multi_logloss: 1.08028 + 0.0196478\n",
      "[668]\tcv_agg's multi_logloss: 1.0803 + 0.0196709\n[669]\tcv_agg's multi_logloss: 1.08033 + 0.0197002\n[670]\tcv_agg's multi_logloss: 1.08036 + 0.0196794\n[671]\tcv_agg's multi_logloss: 1.0804 + 0.019678\n",
      "[672]\tcv_agg's multi_logloss: 1.08039 + 0.0196622\n[673]\tcv_agg's multi_logloss: 1.08042 + 0.019657\n[674]\tcv_agg's multi_logloss: 1.08043 + 0.0196678\n[675]\tcv_agg's multi_logloss: 1.08046 + 0.0196842\n[676]\tcv_agg's multi_logloss: 1.08049 + 0.0197113\n[677]\tcv_agg's multi_logloss: 1.08052 + 0.0197549\n[678]\tcv_agg's multi_logloss: 1.08055 + 0.0197857\n[679]\tcv_agg's multi_logloss: 1.0806 + 0.0198317\n[680]\tcv_agg's multi_logloss: 1.08061 + 0.0198502\n[681]\tcv_agg's multi_logloss: 1.08063 + 0.0198534\n",
      "[682]\tcv_agg's multi_logloss: 1.08065 + 0.0198803\n[683]\tcv_agg's multi_logloss: 1.08065 + 0.0199019\n[684]\tcv_agg's multi_logloss: 1.08065 + 0.0198889\n[685]\tcv_agg's multi_logloss: 1.08067 + 0.0198883\n",
      "[686]\tcv_agg's multi_logloss: 1.08063 + 0.0198678\n[687]\tcv_agg's multi_logloss: 1.08061 + 0.0198927\n[688]\tcv_agg's multi_logloss: 1.08061 + 0.0198864\n[689]\tcv_agg's multi_logloss: 1.08062 + 0.019876\n[690]\tcv_agg's multi_logloss: 1.08061 + 0.0198889\n[691]\tcv_agg's multi_logloss: 1.08063 + 0.0198677\n[692]\tcv_agg's multi_logloss: 1.08063 + 0.0198729\n[693]\tcv_agg's multi_logloss: 1.08065 + 0.0199047\n[694]\tcv_agg's multi_logloss: 1.08066 + 0.0198961\n[695]\tcv_agg's multi_logloss: 1.08071 + 0.0198867\n",
      "[696]\tcv_agg's multi_logloss: 1.0807 + 0.0198893\n[697]\tcv_agg's multi_logloss: 1.08072 + 0.0199338\n[698]\tcv_agg's multi_logloss: 1.08075 + 0.0199307\n[699]\tcv_agg's multi_logloss: 1.08076 + 0.0199446\n",
      "[700]\tcv_agg's multi_logloss: 1.08075 + 0.0199564\n[701]\tcv_agg's multi_logloss: 1.0808 + 0.0199685\n[702]\tcv_agg's multi_logloss: 1.08085 + 0.0199968\n[703]\tcv_agg's multi_logloss: 1.08088 + 0.0199819\n[704]\tcv_agg's multi_logloss: 1.08089 + 0.0200258\n[705]\tcv_agg's multi_logloss: 1.08092 + 0.0200426\n[706]\tcv_agg's multi_logloss: 1.08095 + 0.0200657\n[707]\tcv_agg's multi_logloss: 1.081 + 0.020073\n[708]\tcv_agg's multi_logloss: 1.08101 + 0.0201121\n[709]\tcv_agg's multi_logloss: 1.08106 + 0.0201197\n",
      "[710]\tcv_agg's multi_logloss: 1.08112 + 0.0201674\n[711]\tcv_agg's multi_logloss: 1.08111 + 0.0201519\n[712]\tcv_agg's multi_logloss: 1.08109 + 0.0200829\n[713]\tcv_agg's multi_logloss: 1.08108 + 0.0200639\n",
      "[714]\tcv_agg's multi_logloss: 1.08107 + 0.0200712\n[715]\tcv_agg's multi_logloss: 1.08112 + 0.0200878\n[716]\tcv_agg's multi_logloss: 1.08106 + 0.0201325\n[717]\tcv_agg's multi_logloss: 1.0811 + 0.0201503\n[718]\tcv_agg's multi_logloss: 1.0811 + 0.0201926\n[719]\tcv_agg's multi_logloss: 1.08109 + 0.0202354\n[720]\tcv_agg's multi_logloss: 1.08106 + 0.0202605\n[721]\tcv_agg's multi_logloss: 1.08106 + 0.0202503\n[722]\tcv_agg's multi_logloss: 1.08104 + 0.0202106\n[723]\tcv_agg's multi_logloss: 1.08107 + 0.0201853\n",
      "[724]\tcv_agg's multi_logloss: 1.0811 + 0.0201693\n[725]\tcv_agg's multi_logloss: 1.08112 + 0.0201881\n[726]\tcv_agg's multi_logloss: 1.08113 + 0.0201405\n[727]\tcv_agg's multi_logloss: 1.08116 + 0.0201165\n",
      "[728]\tcv_agg's multi_logloss: 1.0812 + 0.0201009\n[729]\tcv_agg's multi_logloss: 1.08119 + 0.0200955\n[730]\tcv_agg's multi_logloss: 1.08119 + 0.0200448\n[731]\tcv_agg's multi_logloss: 1.08125 + 0.0200529\n[732]\tcv_agg's multi_logloss: 1.08124 + 0.0201053\n[733]\tcv_agg's multi_logloss: 1.08125 + 0.0201476\n[734]\tcv_agg's multi_logloss: 1.08126 + 0.020188\n[735]\tcv_agg's multi_logloss: 1.08126 + 0.0201799\n[736]\tcv_agg's multi_logloss: 1.08128 + 0.0201544\n",
      "[737]\tcv_agg's multi_logloss: 1.08127 + 0.0201005\n[738]\tcv_agg's multi_logloss: 1.08127 + 0.0200964\n[739]\tcv_agg's multi_logloss: 1.08135 + 0.0201186\n[740]\tcv_agg's multi_logloss: 1.08134 + 0.0200882\n",
      "[741]\tcv_agg's multi_logloss: 1.08139 + 0.0201011\n[742]\tcv_agg's multi_logloss: 1.08148 + 0.0201357\n[743]\tcv_agg's multi_logloss: 1.08154 + 0.0201689\n[744]\tcv_agg's multi_logloss: 1.08157 + 0.0201815\n[745]\tcv_agg's multi_logloss: 1.08165 + 0.0202483\n[746]\tcv_agg's multi_logloss: 1.0817 + 0.0202638\n[747]\tcv_agg's multi_logloss: 1.0817 + 0.0203202\n[748]\tcv_agg's multi_logloss: 1.08173 + 0.0203033\n[749]\tcv_agg's multi_logloss: 1.08174 + 0.0203097\n",
      "[750]\tcv_agg's multi_logloss: 1.08174 + 0.0203243\n[751]\tcv_agg's multi_logloss: 1.08175 + 0.0203341\n[752]\tcv_agg's multi_logloss: 1.08174 + 0.0203637\n[753]\tcv_agg's multi_logloss: 1.08174 + 0.0203697\n[754]\tcv_agg's multi_logloss: 1.08174 + 0.0203736\n",
      "[755]\tcv_agg's multi_logloss: 1.08178 + 0.0203723\n[756]\tcv_agg's multi_logloss: 1.08181 + 0.0204167\n[757]\tcv_agg's multi_logloss: 1.08181 + 0.0203988\n[758]\tcv_agg's multi_logloss: 1.08185 + 0.0204133\n[759]\tcv_agg's multi_logloss: 1.08183 + 0.0204155\n[760]\tcv_agg's multi_logloss: 1.08185 + 0.0204284\n[761]\tcv_agg's multi_logloss: 1.08188 + 0.0204252\n[762]\tcv_agg's multi_logloss: 1.08189 + 0.020422\n[763]\tcv_agg's multi_logloss: 1.08191 + 0.0204461\n",
      "[764]\tcv_agg's multi_logloss: 1.08195 + 0.0204831\n[765]\tcv_agg's multi_logloss: 1.08197 + 0.0205231\n[766]\tcv_agg's multi_logloss: 1.082 + 0.0205616\n[767]\tcv_agg's multi_logloss: 1.082 + 0.0205606\n[768]\tcv_agg's multi_logloss: 1.08201 + 0.0206014\n",
      "[769]\tcv_agg's multi_logloss: 1.08203 + 0.0206054\n[770]\tcv_agg's multi_logloss: 1.08207 + 0.0205961\n[771]\tcv_agg's multi_logloss: 1.08206 + 0.0206896\n[772]\tcv_agg's multi_logloss: 1.08214 + 0.0206816\n[773]\tcv_agg's multi_logloss: 1.08215 + 0.0207383\n[774]\tcv_agg's multi_logloss: 1.08225 + 0.0207344\n[775]\tcv_agg's multi_logloss: 1.08232 + 0.0207773\n[776]\tcv_agg's multi_logloss: 1.08237 + 0.0207849\n[777]\tcv_agg's multi_logloss: 1.08242 + 0.020867\n",
      "[778]\tcv_agg's multi_logloss: 1.08243 + 0.0209658\n[779]\tcv_agg's multi_logloss: 1.08245 + 0.0209841\n[780]\tcv_agg's multi_logloss: 1.08244 + 0.0209665\n[781]\tcv_agg's multi_logloss: 1.08244 + 0.0209385\n[782]\tcv_agg's multi_logloss: 1.08246 + 0.0209389\n",
      "[783]\tcv_agg's multi_logloss: 1.08246 + 0.020947\n[784]\tcv_agg's multi_logloss: 1.08247 + 0.0209575\n[785]\tcv_agg's multi_logloss: 1.0825 + 0.0209454\n[786]\tcv_agg's multi_logloss: 1.08252 + 0.0209494\n[787]\tcv_agg's multi_logloss: 1.08255 + 0.0209903\n[788]\tcv_agg's multi_logloss: 1.08256 + 0.0209701\n[789]\tcv_agg's multi_logloss: 1.08258 + 0.0209891\n[790]\tcv_agg's multi_logloss: 1.08259 + 0.020987\n[791]\tcv_agg's multi_logloss: 1.08264 + 0.021015\n",
      "[792]\tcv_agg's multi_logloss: 1.08267 + 0.0210032\n[793]\tcv_agg's multi_logloss: 1.08269 + 0.021\n[794]\tcv_agg's multi_logloss: 1.08273 + 0.0210345\n[795]\tcv_agg's multi_logloss: 1.08279 + 0.0210193\n[796]\tcv_agg's multi_logloss: 1.0828 + 0.0210104\n",
      "[797]\tcv_agg's multi_logloss: 1.08282 + 0.0210504\n[798]\tcv_agg's multi_logloss: 1.08283 + 0.0210794\n[799]\tcv_agg's multi_logloss: 1.08283 + 0.0211046\n[800]\tcv_agg's multi_logloss: 1.08285 + 0.0210943\n[801]\tcv_agg's multi_logloss: 1.08291 + 0.0211129\n[802]\tcv_agg's multi_logloss: 1.08291 + 0.0211505\n[803]\tcv_agg's multi_logloss: 1.08294 + 0.0211757\n[804]\tcv_agg's multi_logloss: 1.08297 + 0.021187\n[805]\tcv_agg's multi_logloss: 1.083 + 0.0212022\n",
      "[806]\tcv_agg's multi_logloss: 1.083 + 0.0211966\n[807]\tcv_agg's multi_logloss: 1.08299 + 0.0211835\n[808]\tcv_agg's multi_logloss: 1.08301 + 0.0211773\n[809]\tcv_agg's multi_logloss: 1.08304 + 0.0211783\n",
      "{'multi_logloss-mean': [1.2829481804104088, 1.2804255519775956, 1.2780642426213253, 1.2757743857112245, 1.2735667576376741, 1.2712588140488397, 1.2688161640176816, 1.266598753111911, 1.2642904364722813, 1.262196944535776, 1.2599921664649005, 1.258045567973304, 1.2558546444672922, 1.253724388222954, 1.251637745490211, 1.2497864723079648, 1.2478680792514087, 1.2459191928312037, 1.244164358254229, 1.2421999073989536, 1.2403939121942067, 1.2388462308986334, 1.2370294208816839, 1.2352228134228995, 1.2333687462653864, 1.2315511843957347, 1.2297068771035335, 1.2278999919658689, 1.2260723065252777, 1.2243387352891313, 1.222790502378849, 1.2211272263095672, 1.2195397699613004, 1.2179552530328661, 1.216448008570834, 1.214933720870485, 1.2133883764967295, 1.2118238663348344, 1.2102870431479866, 1.2089334806441083, 1.2076189575802534, 1.2062801331637427, 1.20488007455577, 1.2034793607329055, 1.2021140967572441, 1.2007145167600677, 1.199391666433201, 1.1980027742303014, 1.1966959200847458, 1.1952909904897333, 1.1939829842666982, 1.19275258179719, 1.1915891661615738, 1.1903249142224848, 1.1892761298631818, 1.1881999152268126, 1.187047088148034, 1.1858354822053996, 1.184649606474522, 1.1835434054151432, 1.1823994721803228, 1.1813420565491612, 1.1803139322727838, 1.1790964829295218, 1.1779457243622418, 1.1768541263930932, 1.1758502415239966, 1.1748489248548566, 1.1738748517345956, 1.1728745906498959, 1.1718054736313195, 1.1708172639996781, 1.1699231747157426, 1.1689488486657398, 1.1679356481190921, 1.1669668299310334, 1.1659665989635735, 1.1648998626140357, 1.1639275220931389, 1.1629049397109283, 1.1619472705778753, 1.1609890927018562, 1.1600594305548788, 1.1591781241219057, 1.1582608589061578, 1.1574378048020533, 1.1565843845313803, 1.155796883347844, 1.1549895225459799, 1.1541754294854025, 1.1534397597376262, 1.1526692629516737, 1.1518884986191487, 1.1511320108095904, 1.150323956194716, 1.1495693669737286, 1.148800254945939, 1.1480551254856746, 1.147324489915457, 1.1466206914638186, 1.1459591380495104, 1.1453187200227393, 1.144589764891546, 1.1439537114758918, 1.1433280247677982, 1.1426619062230852, 1.1420090961613947, 1.1413638252381166, 1.1407646293142344, 1.1401342692224126, 1.1395655556329813, 1.138986675387542, 1.1383715532379977, 1.1378161587732647, 1.1371728139502488, 1.136549923419493, 1.1360388167919093, 1.135546549937028, 1.1350076737269486, 1.1343911753643714, 1.1338580646893661, 1.1332879811173342, 1.132799659773559, 1.1322773163730921, 1.1317814865117608, 1.1312428064633977, 1.130734698936558, 1.1301338148496873, 1.1296698951811472, 1.1292004027827747, 1.1286817820021269, 1.1282025351550404, 1.1277550803525191, 1.1272292491646172, 1.12676109606024, 1.1263153505288892, 1.125827528587974, 1.1254259176092032, 1.1249117373484314, 1.1244780019160294, 1.1239694674113614, 1.1235262334776128, 1.123114740043777, 1.1226527063586973, 1.1221547859855354, 1.121780990109858, 1.1213328502700524, 1.1209389431209589, 1.12050531057292, 1.1201145321055226, 1.1197430775055934, 1.1194451436194657, 1.1191174955272305, 1.1188199361124291, 1.1184105777360074, 1.1180232309149374, 1.1176170259649614, 1.1172552951692531, 1.1168878358693168, 1.1165512591502047, 1.1161846719550064, 1.1159230435851375, 1.1155682229837236, 1.1151907501656455, 1.1148206678729855, 1.1144640817831672, 1.1140572475692168, 1.1136861867355463, 1.113381745397128, 1.1130759662803869, 1.1127797573166542, 1.1124596316443922, 1.1121528837346506, 1.111818866449194, 1.1114683947667667, 1.1111451213972336, 1.1108172328523076, 1.1105052896245287, 1.110195765430354, 1.1099282459739994, 1.1095863654753049, 1.1092791947961254, 1.1090208963926536, 1.1087175029366783, 1.1084912405955332, 1.1082248416261076, 1.1079373063954985, 1.1076158467847883, 1.1073726508571955, 1.107131627066265, 1.1068796679888078, 1.1066606761422861, 1.1064434479096907, 1.1062045024013716, 1.1059326118498523, 1.1056400358780365, 1.1053670676184264, 1.1051517253783127, 1.104914661869701, 1.1046219729725222, 1.1044467120828751, 1.1042318134358466, 1.103978919622421, 1.1036948206362465, 1.1035018167564188, 1.1033062524621289, 1.103083907267206, 1.1027981876919217, 1.1025646104399525, 1.1022932132222478, 1.102071967230086, 1.1018511551023296, 1.1016050063708485, 1.101353878111013, 1.101151028364961, 1.1009343767430793, 1.1006684293809674, 1.100422970110904, 1.100222231964853, 1.1000375865130436, 1.099847708797192, 1.0996555950965645, 1.0994725056852608, 1.0992765914498102, 1.0991034325433051, 1.0989380908559887, 1.098792625693005, 1.0985816013166994, 1.0983616030989736, 1.0981986935751207, 1.0979950819559496, 1.0978367179737567, 1.097716338728873, 1.0975111528042725, 1.0973527746237937, 1.0971898602160404, 1.0970751405103178, 1.0969271579311486, 1.096737838051402, 1.096559370458286, 1.0963780663435283, 1.0962016615817924, 1.0959851182134641, 1.0957638523190074, 1.0955848992718074, 1.0954190434797384, 1.0952717701755614, 1.0951445164104359, 1.0950192441980977, 1.094919403746213, 1.0947580494684344, 1.0946308586790452, 1.0944688624846368, 1.094284772053116, 1.0941475947265027, 1.0939989818857405, 1.0938720866073717, 1.0937210451930994, 1.093573299601565, 1.0934018580916836, 1.0933448001147918, 1.0932055312704667, 1.0930790075271735, 1.0929968440219815, 1.0929168882407994, 1.0927565712919542, 1.0925677074444597, 1.0924572241581225, 1.0923176920364521, 1.0921749870502198, 1.0920615944214034, 1.09194742267687, 1.0918239566494468, 1.09170685782194, 1.091631044629778, 1.091535675528473, 1.0913994434837042, 1.0912650533352444, 1.091146622237955, 1.091045986517567, 1.0909338724763011, 1.0908503490411154, 1.0907505708410528, 1.0906945704780031, 1.090583614243306, 1.090467600420037, 1.090359335629453, 1.0902565793843362, 1.0901154280224807, 1.0900237077453652, 1.08993115433606, 1.0898578756617219, 1.0897640297396323, 1.0896995866415715, 1.089609444513896, 1.0895158244254544, 1.0894550583106335, 1.0893455413801292, 1.089218750942644, 1.0890769593764087, 1.0889646943223403, 1.0888929618088818, 1.0888489188811912, 1.0887503142003818, 1.0887053974002012, 1.0885714759264173, 1.0884738411801274, 1.0883795919039219, 1.0883206097004552, 1.0882743059496374, 1.0881767899933525, 1.0881108919840368, 1.0880508866027492, 1.0880193748992675, 1.0879445826230927, 1.0878676014255542, 1.0878258664962948, 1.087779682919804, 1.0876681226126084, 1.0875854491220422, 1.0874396806614635, 1.0874233244012517, 1.0873519013034771, 1.0872578779952733, 1.08718188703646, 1.0871125455720883, 1.0870407841946976, 1.0869522488287662, 1.0868736588608114, 1.0867911112089277, 1.0867499786295118, 1.0867354988151332, 1.086729952172564, 1.0867079491001725, 1.0866754297849612, 1.0866205987430508, 1.086604094489309, 1.086539218729006, 1.0864677481677216, 1.0863937190731972, 1.08632044525908, 1.086246460048224, 1.0861706715556043, 1.0860855462607837, 1.0860506956025442, 1.0859655575940939, 1.085853673803034, 1.085785513906123, 1.085728407098933, 1.0855990195288283, 1.0855520106793501, 1.0855055278156416, 1.0854571293113917, 1.0854465060135694, 1.0854256595666871, 1.0853675286244744, 1.0853209034727476, 1.085255762050788, 1.0851988321664396, 1.0851214831384104, 1.0850840401665311, 1.0850428815866162, 1.0849905146556809, 1.085014541319658, 1.0850666230816002, 1.0849793494366629, 1.084899269617241, 1.084866224471768, 1.084808215561853, 1.0847021967090265, 1.0846537522118815, 1.0845537981174367, 1.084489909798003, 1.084477442312581, 1.084465228198692, 1.0843944399325847, 1.0843343178994107, 1.0842736744175687, 1.0842194249747932, 1.0842153428380854, 1.084121449637024, 1.0840718009658465, 1.0840462474909922, 1.0839842157245942, 1.0839389491338725, 1.0838533084043092, 1.0838654545442898, 1.0838234954730002, 1.0838170017303264, 1.0837504991494091, 1.0836969379207904, 1.0836680492169513, 1.0836318621224301, 1.0835813882343068, 1.0835496983388484, 1.0835316926688616, 1.0834731634761714, 1.0834265196671238, 1.0834254363735263, 1.0834420943721808, 1.0833431475119653, 1.0832776384630551, 1.0831994575893173, 1.083162193413008, 1.0831150415877684, 1.0830947923905376, 1.0830668035226556, 1.0830434001312808, 1.0829986940405392, 1.0829861656383817, 1.0829373303576761, 1.0828539821187668, 1.082813289468414, 1.0828018678803486, 1.0827746439973907, 1.082742113038904, 1.082672183193641, 1.0826395157969537, 1.0825892723347432, 1.0824712734941635, 1.0824360728785412, 1.0824046122336797, 1.0823870740365735, 1.0823362957453282, 1.0823268477835002, 1.0823171969962284, 1.082249715757418, 1.0822373260372862, 1.0822618921077027, 1.0822178292639948, 1.082152927107748, 1.082112503264137, 1.0820540076885743, 1.0820299457098823, 1.0820393686192022, 1.081994610340939, 1.0820061469824753, 1.0819595888926454, 1.0819710818867574, 1.0819388105153285, 1.0819214923637486, 1.0819285928783855, 1.0819308761458761, 1.081952023147589, 1.0819240929106702, 1.081918190416137, 1.0818926963814026, 1.0818215331616468, 1.0817833110274204, 1.081738475239853, 1.0817505001348224, 1.0817605561727581, 1.0817411628391074, 1.0817000508886863, 1.0816461391858152, 1.0816488653765821, 1.0816440298018093, 1.0816165922482144, 1.081583605610353, 1.0816109525825115, 1.0815562535767553, 1.0815244202905867, 1.0814665754481703, 1.0814126336578869, 1.0813872713264976, 1.0813452942072648, 1.0813426392030423, 1.081314781499405, 1.0812631371678154, 1.0812441401158712, 1.0812163266040062, 1.0811734243519535, 1.0811584577828008, 1.0811136900916791, 1.081081320798504, 1.0810582441025627, 1.0810166601694458, 1.08099973541264, 1.0809722098896963, 1.080926294122054, 1.0808941156356409, 1.080936414464805, 1.0809581342287147, 1.080961851069178, 1.0809512826280392, 1.0809567938882225, 1.080959232293606, 1.080944718592785, 1.0809647406482257, 1.080939861399528, 1.0809245549870328, 1.0808887269554823, 1.0808870250617773, 1.080851784223017, 1.080806505012676, 1.0808212355027815, 1.0808143732834516, 1.080789892679044, 1.0807843597235878, 1.0808351529793945, 1.0808277702705755, 1.080870110606258, 1.0808366611214242, 1.0808566923644758, 1.0808416750750962, 1.0808528501832464, 1.0808597038161456, 1.080877248640911, 1.0808575709846877, 1.0808543430517596, 1.08081442780767, 1.0808037869511067, 1.080829498262355, 1.0808316410646692, 1.080835222476278, 1.0808200686828078, 1.0807788379734098, 1.080775307196139, 1.0807490971088005, 1.08070148894202, 1.0806853595800603, 1.080660871539898, 1.0806319590658915, 1.0806335730938579, 1.080654720502395, 1.0806833389989063, 1.0807089795026437, 1.0807291589548478, 1.080727539497975, 1.0807542020216572, 1.0807075665076782, 1.080655549537282, 1.0806503845273823, 1.0806523687737593, 1.0806807640158964, 1.0807057645398213, 1.080691689047565, 1.0807117179495633, 1.0807238742681384, 1.0807582701980813, 1.0807592237303854, 1.0807431564194427, 1.0807183256525001, 1.0806928844081254, 1.0806753603094468, 1.0806729176339105, 1.0806611547999965, 1.0806550573354785, 1.0806331077611844, 1.0806314572029045, 1.080598049978929, 1.0805817029940095, 1.0805727497086703, 1.0805530737428506, 1.0805465785926525, 1.0805878646310962, 1.0806043681683033, 1.0805893345056747, 1.0805958524064063, 1.0805845396062237, 1.0806171397342574, 1.0805946260135124, 1.0806017087451885, 1.0805720206074783, 1.0805536789303352, 1.08049193778633, 1.0804512099798362, 1.0804202289068467, 1.080383706140416, 1.080393507007104, 1.080415074301045, 1.0803884909689903, 1.080386520195658, 1.0803448871632786, 1.0803150921325348, 1.0802959962297667, 1.0802634826212298, 1.0802734264074332, 1.0802412753513528, 1.08025488595965, 1.0802558990993372, 1.0802482764373458, 1.0802276940494147, 1.0802425076159583, 1.080202825711408, 1.0802091375466536, 1.0801959137339927, 1.0802228899270736, 1.0802239620736631, 1.0802076414120003, 1.080187279878253, 1.0801331308377424, 1.0801175159930545, 1.080107223983293, 1.0800864488973256, 1.080090204095316, 1.080074369393709, 1.0800856547882953, 1.080085173625771, 1.080104635802003, 1.08003653041355, 1.0799941975257925, 1.0799506706527096, 1.079988928028308, 1.0799393568542517, 1.079903463730187, 1.0799038388842168, 1.0798935534775675, 1.079881187230438], 'multi_logloss-stdv': [0.0005396078533236218, 0.000556150252470816, 0.0006330003669208294, 0.0006539909687575531, 0.0007048312646219892, 0.0007654699854438871, 0.0008067521254522485, 0.0008996067696057659, 0.001002254752180728, 0.0010572658086489726, 0.0011102718393741257, 0.0012068755336663108, 0.001294928832104028, 0.001487177540394193, 0.0016032553127316707, 0.0016906264578760751, 0.001715181757881349, 0.0017562569631660717, 0.001737763629182208, 0.0017870968812357972, 0.0017678020138951057, 0.00178808210882715, 0.001816256331258625, 0.0018258274550598786, 0.0018720814224471773, 0.0019478662823997537, 0.0019503931134184317, 0.001971643916418882, 0.0019792122500394333, 0.0020458664432897143, 0.002078431368254539, 0.002131836174525128, 0.002167717411429829, 0.002187745647531323, 0.0022495334355834918, 0.002418306865410899, 0.0025064941183149786, 0.002556635244159834, 0.0026653155747572914, 0.0027891442357141655, 0.0028630824349871286, 0.0029088076453572483, 0.0028936522496440854, 0.0029518773547388957, 0.002994041057994506, 0.003031750311689788, 0.0029841130442807354, 0.003032598929049498, 0.003092925923663472, 0.003173963142607157, 0.0032355592698958156, 0.003300857426105134, 0.0033453382755202106, 0.0034039675306692203, 0.003460980223360466, 0.003582473933489048, 0.0036776392186305875, 0.003741693190475248, 0.003819921732931051, 0.003943953467092554, 0.004011904283643749, 0.004058405009143682, 0.004126938256422422, 0.004241263013202169, 0.004360657993252046, 0.004433105277406822, 0.004440302162476428, 0.004527771507989553, 0.004581702746442938, 0.004654481784928309, 0.00469132378765725, 0.004757494252563279, 0.004810978837293653, 0.004842375313863774, 0.0048783454836679105, 0.004881616691855837, 0.005006690599616591, 0.005083531958047263, 0.005217796273479713, 0.0053147699571178516, 0.0053565821943044704, 0.005366294118406327, 0.005422274776968976, 0.005418354457041984, 0.005463164130392985, 0.005498842573456085, 0.005567006572638794, 0.005522201236057767, 0.005491972372617555, 0.005485976748650522, 0.005559262187378038, 0.005596073308081683, 0.00564339494766765, 0.005673189682166892, 0.005716944515473052, 0.005802627667567662, 0.005840785890883706, 0.005907945780488413, 0.005958020817850039, 0.006026386051761473, 0.006012298963567707, 0.00599802726211267, 0.0060706823019586915, 0.006109619362227954, 0.006172067475030734, 0.006277209532814026, 0.006426360456274133, 0.006472444288879525, 0.0064768704327139645, 0.006530235225546088, 0.0066007397647951955, 0.006693421923301212, 0.006736198301615279, 0.006807395461918574, 0.006910874715812129, 0.006998709474063938, 0.007035658528746101, 0.00707318362224192, 0.007090818036241743, 0.007152251673942417, 0.007208796993520177, 0.007265044377059467, 0.007325696959213115, 0.007425352679849292, 0.007493260382806949, 0.007589234513324482, 0.007689405925730196, 0.007764687732101015, 0.007847303009964359, 0.007906895026969408, 0.00800156907575699, 0.008105369270959227, 0.00819064555040935, 0.008253389343457047, 0.00834872012486291, 0.008382907303323939, 0.008444004609551864, 0.008503937791482364, 0.008584666098386547, 0.008667693096961538, 0.008726397425149177, 0.008818453688031674, 0.00887374229850091, 0.008982168188625293, 0.009097208314172439, 0.0091102371388531, 0.00916859403909956, 0.009236860668482332, 0.009300704617707215, 0.00938620257981883, 0.009457593151529888, 0.009504893599199347, 0.009575454350289666, 0.00967733837995725, 0.009730572547669618, 0.009794871909173863, 0.009903920670997789, 0.009925250250823423, 0.01002695958592012, 0.010139442631265847, 0.010205579092549481, 0.010327978332715853, 0.010385273170402935, 0.010481503420578296, 0.010601623183828493, 0.010577583176502191, 0.010624875014394393, 0.010656697529575985, 0.010665084586589376, 0.010680203897449194, 0.010736499498698105, 0.010762542260448772, 0.01079727687198144, 0.010909847131762428, 0.010946600158779712, 0.010979956770186951, 0.011018936064754667, 0.011096046522008195, 0.011086753160764032, 0.011138260804445578, 0.011159095088765216, 0.011186378274585058, 0.011229808670651617, 0.011272152194646463, 0.011338068491659744, 0.011378671704318343, 0.011431348903706265, 0.01146723916347928, 0.0114699429373341, 0.011472023338716298, 0.011515097826746102, 0.011499923844454104, 0.011473679606007123, 0.011482821065262456, 0.011493360135174664, 0.011545564357542908, 0.011543791438369052, 0.011617199875625702, 0.011680546847538054, 0.011683192297917321, 0.011728311673054685, 0.011783562557720836, 0.01180993528850565, 0.011880277775673184, 0.011932073398319653, 0.01196785375546641, 0.012004685705949463, 0.012007985270406987, 0.012028210733475628, 0.012089407872760426, 0.012145442932218, 0.012219403821952319, 0.012273016235116502, 0.012352522156174883, 0.012440678748802694, 0.012469275262980887, 0.012515384666649254, 0.012567470305713688, 0.01256004082490284, 0.0125733014057635, 0.012639157670720675, 0.012670608762193857, 0.012699383097605415, 0.012778743749544427, 0.01285484770223701, 0.012837462071316846, 0.012869449044370325, 0.01283201189885396, 0.012819605832244512, 0.012847237967283829, 0.012892367683069908, 0.013000370406380947, 0.013038517694573468, 0.013110164505264746, 0.013184255029244996, 0.01317826839308226, 0.013208394070950077, 0.013218998373446582, 0.013262344868926659, 0.013334144540896764, 0.013339044507597373, 0.01340409677578725, 0.013448231194179427, 0.013453281936784285, 0.013517562158909386, 0.013596160866272005, 0.01362102162934604, 0.01368177482084359, 0.013763791307421872, 0.013832259994587365, 0.013856780135713885, 0.013891670295596502, 0.0138589075649259, 0.01388301191156487, 0.013897194055910679, 0.013959831424183115, 0.013924474109707458, 0.01399507921962293, 0.013989890002199221, 0.014051401023231186, 0.014048992993448726, 0.014054487796748996, 0.014066776913103445, 0.014132764197756838, 0.014120342599199158, 0.014183081636737987, 0.014223769565788469, 0.01428412567358499, 0.014312913551621374, 0.014314216112517548, 0.014367255895228265, 0.014436093039705637, 0.01450975531175035, 0.014569321430745, 0.014630772127121815, 0.014652670404445301, 0.014668794980557192, 0.014744949269851568, 0.014746364989512562, 0.014751485002351954, 0.014738361696359363, 0.014816925152708096, 0.014863047695338789, 0.014886413571522428, 0.014925291135959829, 0.015026364064951099, 0.015088038193746817, 0.015146589092556409, 0.015247390725901937, 0.015279449142435744, 0.015312741471671543, 0.015370274880078923, 0.01539211075043598, 0.015454657359488437, 0.015450259727770813, 0.015462837587656115, 0.01553747024271069, 0.015603877484226342, 0.015605549123278436, 0.01565052550478882, 0.015601663426623795, 0.015611275129099104, 0.015609099289208716, 0.015578723242723632, 0.015577512387865847, 0.015616298492010258, 0.01566522462103349, 0.015661517816566113, 0.015661622116232125, 0.015675550008603514, 0.015686346938131264, 0.015683451804930127, 0.015678224469274176, 0.015676822266003077, 0.015696748404277403, 0.01573553172049033, 0.015747797052014154, 0.015762046222853463, 0.015800526948854074, 0.015829473903443615, 0.015882248983658167, 0.015929939189184634, 0.015984446236356028, 0.016049101407208433, 0.016118428263417667, 0.016152311237361352, 0.01620984671333476, 0.016214062621277822, 0.016180304075471524, 0.016237126607453852, 0.01626746698423232, 0.01635570424249102, 0.016403451218752516, 0.01641726256264012, 0.016458395903906804, 0.01646453128130151, 0.01644646698888728, 0.016445432989611812, 0.016455293420573135, 0.016483347298349958, 0.016528347474596083, 0.016538984427816355, 0.01655810983028364, 0.016583538236130214, 0.016597253936669294, 0.01658999057360793, 0.016606107894419388, 0.01660960029921908, 0.016647946214866864, 0.016701600591162245, 0.01671581864824868, 0.016694866528039767, 0.016727704954602934, 0.016695084586666985, 0.01669749931529943, 0.016756066381267976, 0.016776501755328656, 0.016815703868680847, 0.01682306100923863, 0.016855253679179862, 0.016909661315641054, 0.01695886539033943, 0.016958164911769352, 0.016994293637336167, 0.017035891118362383, 0.01708891934300742, 0.017168687741177593, 0.017229338240254348, 0.01726948697669667, 0.017309432377494247, 0.017328763211772517, 0.017368844251549016, 0.01740288755321285, 0.017404919179619466, 0.01740700273456077, 0.017455207132710763, 0.017471420143248116, 0.01753599228893339, 0.017533228796531714, 0.017591771738501977, 0.017654502594490817, 0.01768367422734157, 0.01774073573055228, 0.017756669318096673, 0.017767890079660155, 0.017808037530792496, 0.01785344718440583, 0.01791669454299324, 0.0179673566158507, 0.018010698356125277, 0.018022167136660168, 0.01803577493031312, 0.018037377740333066, 0.018037027508335118, 0.018059251480412535, 0.01803481145084019, 0.018076408782732187, 0.018116905324333903, 0.018128627307659316, 0.01813047350719329, 0.018111473614655156, 0.018095280909360467, 0.01808657066314143, 0.01809073268579908, 0.018112428341804244, 0.018144926553838748, 0.018161633162908985, 0.018162558837380827, 0.018176131759321798, 0.018186093833909362, 0.01821463858827262, 0.018254325215514944, 0.018255659701832516, 0.018274423901451786, 0.01829056468522416, 0.018301872102329798, 0.018292785913215186, 0.018258491993344415, 0.01825269283087901, 0.018246457837283965, 0.018244117534639753, 0.018280694992319324, 0.01830739745613027, 0.01826512187094972, 0.018294814925481746, 0.01832876765410484, 0.01832583817413572, 0.018346787190238585, 0.018355462761305594, 0.018374902199774713, 0.01834734696103996, 0.0183017134242562, 0.018272879689317366, 0.018263342282993703, 0.01827361479336195, 0.01828900481460082, 0.01826595459338939, 0.018283013009036914, 0.018306850101913092, 0.01831432468708819, 0.018334145121043637, 0.018337255207554966, 0.018360845282337092, 0.018377384905716256, 0.018414759600911962, 0.018469769852731983, 0.018498979274695175, 0.018551719952067874, 0.018568684834192068, 0.018575831363339942, 0.018612121446752904, 0.01864411795823591, 0.0186602755224328, 0.018637225158681135, 0.018627670328954713, 0.01862686463521813, 0.018626540619151324, 0.018576059376998424, 0.018603977056152743, 0.01863060116309734, 0.018637933230906685, 0.018606870680012554, 0.018617327036786813, 0.018604520690724876, 0.018614399093105232, 0.01859080906474382, 0.018623918068686858, 0.018615216772163105, 0.018596672270507535, 0.018572981818899506, 0.018612488046106435, 0.018612062323087455, 0.018672329431556126, 0.018748293908496135, 0.018748889276141545, 0.018768365155932002, 0.018781802316241485, 0.01878765680052499, 0.018815276387734545, 0.018789830053352566, 0.018784687548929403, 0.018849452142553097, 0.018900407078213697, 0.018940533385758917, 0.018944106572860508, 0.01894930141768607, 0.01891118124097259, 0.018898452353623616, 0.01889509607266615, 0.01884989389307319, 0.018863310838390657, 0.01892429467509554, 0.0189750479426148, 0.019005698090969032, 0.018996220797587608, 0.01899865434059851, 0.019015267148098855, 0.019030435222691246, 0.01900579847580287, 0.018983207380124916, 0.018990575836342116, 0.01898777008301939, 0.01898709611629492, 0.01901237728908365, 0.01907030711325698, 0.019071809269715755, 0.01907982870101542, 0.01906145017531865, 0.019071796793306152, 0.019098628897888627, 0.01912959520744633, 0.019132229021082033, 0.019168672480417828, 0.019172139655176456, 0.019216239731579068, 0.019215322050417233, 0.019225872631825947, 0.019221190390929108, 0.01921298469247135, 0.01920481908425141, 0.019200600007613068, 0.019221884048140677, 0.019156031440421672, 0.01917361561278718, 0.0191500714092415, 0.019204078941809834, 0.019181912274113953, 0.019215089010500307, 0.019232433484192606, 0.019254132510663022, 0.019242277443267855, 0.01925135520595637, 0.019275545598218945, 0.019282128683208343, 0.01924556521358084, 0.019256925944624855, 0.019248666908175834, 0.019269717126300292, 0.019254636789816572, 0.019295042807945178, 0.019285751769327605, 0.019312394895555723, 0.01936601344558293, 0.01937338376539574, 0.019385474620295405, 0.019419115018961323, 0.01943192165447208, 0.019449498896636257, 0.019489536225440602, 0.019520094012997702, 0.019490392423451717, 0.01944846042520749, 0.019428889810982713, 0.019391734661284778, 0.019377116207405072, 0.0193526673553908, 0.019325603418012247, 0.019302643068637004, 0.019305789576313497, 0.019275353322568266, 0.019255470907940386, 0.01930401819392777, 0.01927382239306787, 0.019260682694568296, 0.019299352245396077, 0.01930354574162063, 0.01929250168738508, 0.019296010205330304, 0.019338043895143098, 0.019385451113738083, 0.019324384890068855, 0.019304748653968962, 0.01926766293627076, 0.019225802816561888, 0.019202651302232684, 0.01925704489740798, 0.019309893267129608, 0.019303990483424342, 0.019276631904983434, 0.01932729084778531, 0.019323563673094672, 0.01930915136807716, 0.019317225645963245, 0.019346915876356202, 0.019330138542419127, 0.019326761649753, 0.019314826495658768, 0.0193273059618458, 0.019290296404296917, 0.019263309038397257, 0.01928273636940717, 0.01928118751574122, 0.01924738189857395, 0.01927701222110461, 0.019284024952379016, 0.019306689570812344, 0.0193251671201633, 0.019335691876780157, 0.019352659972558316, 0.01934819840883413, 0.019390102249360233, 0.01936888691910734, 0.019383711628496527, 0.019368297957016903, 0.01934031931022178, 0.019332184828385474, 0.019327258519657824, 0.019317007571116422, 0.01933746101880932]}\n交叉验证中最优的multi_logloss-mean为 1.07988，对应的标准差为0.01934.\n模型最优的迭代次数为609.\n",
      "模型在测试集上的效果是0.62812。\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/wjunneng/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\nNew categorical_feature is ['Parameter10', 'Parameter5', 'Parameter6', 'Parameter7', 'Parameter8', 'Parameter9']\n  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, mean_squared_log_error\n",
    "\n",
    "params = {\n",
    "        'learning_rate': 0.01,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 4,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'max_depth': 7,\n",
    "        'seed': 42,\n",
    "        'num_leaves': 1000,\n",
    "        'n_threads':10\n",
    "    }\n",
    "\n",
    "def run_cv(df_train, df_test, sample_weight=None):\n",
    "    print(sample_weight)\n",
    "    if sample_weight is not None:\n",
    "        train_set = lgb.Dataset(\n",
    "            df_train.drop('Quality_label', axis=1),\n",
    "            label=df_train.loc[:, 'Quality_label'], weight=sample_weight)\n",
    "\n",
    "    else:\n",
    "        train_set = lgb.Dataset(\n",
    "            df_train.drop('Quality_label', axis=1),\n",
    "            label=df_train.loc[:, 'Quality_label'])\n",
    "\n",
    "    # Perform cross validation with early stopping\n",
    "    params.pop('n_estimators', None)\n",
    "    \n",
    "    N_FOLDS = 5\n",
    "    cv_results = lgb.cv(\n",
    "        params,\n",
    "        train_set,\n",
    "        num_boost_round=10000,\n",
    "        nfold=N_FOLDS,\n",
    "        categorical_feature=categorical_columns,\n",
    "        early_stopping_rounds=200,\n",
    "        verbose_eval=True,\n",
    "        seed=42)\n",
    "    \n",
    "    print(cv_results)\n",
    "    print('交叉验证中最优的multi_logloss-mean为 {:.5f}，对应的标准差为{:.5f}.'.format(\n",
    "    cv_results['multi_logloss-mean'][-1], cv_results['multi_logloss-stdv'][-1]))\n",
    "    \n",
    "    print('模型最优的迭代次数为{}.'.format(len(cv_results['multi_logloss-mean'])))\n",
    "\n",
    "    params['n_estimators'] = len(cv_results['multi_logloss-mean'])\n",
    "    \n",
    "    model_cv = lgb.LGBMClassifier(**params)\n",
    "    model_cv.fit(df_train.drop('Quality_label', axis=1),\n",
    "                 df_train.loc[:, 'Quality_label'])\n",
    "\n",
    "    # AUC\n",
    "    preds_test_cv = model_cv.predict_proba(\n",
    "        df_test.drop('Quality_label', axis=1))[:, 1]\n",
    "    auc_test_cv = mean_squared_log_error(df_test.loc[:, 'Quality_label'], preds_test_cv)\n",
    "    print('模型在测试集上的效果是{:.5f}。'.format(\n",
    "        auc_test_cv))\n",
    "\n",
    "    return model_cv\n",
    "\n",
    "model_cv = run_cv(X_train, X_valid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.30663527, 0.29104435, 0.30663527, ..., 0.30329901, 0.30329901,\n       0.30663527])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 127
    }
   ],
   "source": [
    "preds_adv[:len(X_train)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[0.30663527 0.29104435 0.30663527 ... 0.30329901 0.30329901 0.30663527]\n",
      "[1]\tcv_agg's multi_logloss: 1.28107 + 0.00104946\n",
      "[2]\tcv_agg's multi_logloss: 1.27878 + 0.0011632\n[3]\tcv_agg's multi_logloss: 1.27652 + 0.00132023\n[4]\tcv_agg's multi_logloss: 1.27432 + 0.0013996\n",
      "[5]\tcv_agg's multi_logloss: 1.27231 + 0.00140583\n[6]\tcv_agg's multi_logloss: 1.27009 + 0.00151348\n[7]\tcv_agg's multi_logloss: 1.2678 + 0.00152624\n[8]\tcv_agg's multi_logloss: 1.26569 + 0.00162266\n[9]\tcv_agg's multi_logloss: 1.26352 + 0.00171057\n[10]\tcv_agg's multi_logloss: 1.26146 + 0.00180955\n[11]\tcv_agg's multi_logloss: 1.25939 + 0.00188993\n[12]\tcv_agg's multi_logloss: 1.25756 + 0.00203081\n",
      "[13]\tcv_agg's multi_logloss: 1.2555 + 0.00215642\n[14]\tcv_agg's multi_logloss: 1.2535 + 0.00225602\n",
      "[15]\tcv_agg's multi_logloss: 1.25154 + 0.00240758\n[16]\tcv_agg's multi_logloss: 1.24981 + 0.00248886\n[17]\tcv_agg's multi_logloss: 1.24795 + 0.00254729\n",
      "[18]\tcv_agg's multi_logloss: 1.24606 + 0.00262592\n[19]\tcv_agg's multi_logloss: 1.24446 + 0.00260036\n[20]\tcv_agg's multi_logloss: 1.24268 + 0.00265115\n[21]\tcv_agg's multi_logloss: 1.24107 + 0.00269077\n[22]\tcv_agg's multi_logloss: 1.23965 + 0.00273423\n[23]\tcv_agg's multi_logloss: 1.23801 + 0.00275353\n[24]\tcv_agg's multi_logloss: 1.23637 + 0.00272292\n[25]\tcv_agg's multi_logloss: 1.23463 + 0.00281909\n",
      "[26]\tcv_agg's multi_logloss: 1.23295 + 0.00290672\n[27]\tcv_agg's multi_logloss: 1.23124 + 0.00298966\n",
      "[28]\tcv_agg's multi_logloss: 1.22952 + 0.00304652\n[29]\tcv_agg's multi_logloss: 1.22786 + 0.00307522\n[30]\tcv_agg's multi_logloss: 1.22619 + 0.00317128\n",
      "[31]\tcv_agg's multi_logloss: 1.22462 + 0.0032093\n[32]\tcv_agg's multi_logloss: 1.22309 + 0.00325125\n[33]\tcv_agg's multi_logloss: 1.22152 + 0.00325016\n[34]\tcv_agg's multi_logloss: 1.22002 + 0.00328091\n[35]\tcv_agg's multi_logloss: 1.2186 + 0.0033055\n[36]\tcv_agg's multi_logloss: 1.21718 + 0.0033801\n[37]\tcv_agg's multi_logloss: 1.21571 + 0.00344696\n",
      "[38]\tcv_agg's multi_logloss: 1.21427 + 0.00349507\n[39]\tcv_agg's multi_logloss: 1.21283 + 0.00353669\n",
      "[40]\tcv_agg's multi_logloss: 1.21166 + 0.00366099\n[41]\tcv_agg's multi_logloss: 1.21044 + 0.00370254\n[42]\tcv_agg's multi_logloss: 1.20913 + 0.00376662\n",
      "[43]\tcv_agg's multi_logloss: 1.20774 + 0.00378459\n[44]\tcv_agg's multi_logloss: 1.20641 + 0.00388422\n[45]\tcv_agg's multi_logloss: 1.20509 + 0.00394718\n[46]\tcv_agg's multi_logloss: 1.20373 + 0.00395499\n[47]\tcv_agg's multi_logloss: 1.20241 + 0.00399706\n[48]\tcv_agg's multi_logloss: 1.20107 + 0.00400475\n[49]\tcv_agg's multi_logloss: 1.19983 + 0.00401986\n",
      "[50]\tcv_agg's multi_logloss: 1.19856 + 0.00407571\n[51]\tcv_agg's multi_logloss: 1.19729 + 0.00409695\n[52]\tcv_agg's multi_logloss: 1.19608 + 0.00413248\n",
      "[53]\tcv_agg's multi_logloss: 1.19498 + 0.00417795\n[54]\tcv_agg's multi_logloss: 1.19375 + 0.00425537\n[55]\tcv_agg's multi_logloss: 1.19271 + 0.00428688\n",
      "[56]\tcv_agg's multi_logloss: 1.19169 + 0.00436154\n[57]\tcv_agg's multi_logloss: 1.19065 + 0.00443113\n[58]\tcv_agg's multi_logloss: 1.18938 + 0.004452\n[59]\tcv_agg's multi_logloss: 1.1882 + 0.0045628\n[60]\tcv_agg's multi_logloss: 1.1872 + 0.00463905\n[61]\tcv_agg's multi_logloss: 1.18612 + 0.00465716\n[62]\tcv_agg's multi_logloss: 1.18519 + 0.00467357\n",
      "[63]\tcv_agg's multi_logloss: 1.18423 + 0.00473366\n[64]\tcv_agg's multi_logloss: 1.18314 + 0.00481841\n[65]\tcv_agg's multi_logloss: 1.18207 + 0.00487713\n",
      "[66]\tcv_agg's multi_logloss: 1.18105 + 0.0048843\n[67]\tcv_agg's multi_logloss: 1.18004 + 0.00494219\n[68]\tcv_agg's multi_logloss: 1.17908 + 0.00498002\n",
      "[69]\tcv_agg's multi_logloss: 1.17813 + 0.00493988\n[70]\tcv_agg's multi_logloss: 1.17715 + 0.00493946\n[71]\tcv_agg's multi_logloss: 1.17625 + 0.00497297\n[72]\tcv_agg's multi_logloss: 1.1754 + 0.00499537\n[73]\tcv_agg's multi_logloss: 1.17461 + 0.00506318\n[74]\tcv_agg's multi_logloss: 1.17373 + 0.00511548\n[75]\tcv_agg's multi_logloss: 1.17277 + 0.00515148\n",
      "[76]\tcv_agg's multi_logloss: 1.17185 + 0.00518521\n[77]\tcv_agg's multi_logloss: 1.17089 + 0.00522432\n[78]\tcv_agg's multi_logloss: 1.1699 + 0.00521647\n",
      "[79]\tcv_agg's multi_logloss: 1.16897 + 0.00527117\n[80]\tcv_agg's multi_logloss: 1.168 + 0.00529681\n[81]\tcv_agg's multi_logloss: 1.16717 + 0.00531011\n",
      "[82]\tcv_agg's multi_logloss: 1.16623 + 0.00526149\n[83]\tcv_agg's multi_logloss: 1.16535 + 0.00530205\n[84]\tcv_agg's multi_logloss: 1.16458 + 0.00529421\n[85]\tcv_agg's multi_logloss: 1.16373 + 0.00535034\n[86]\tcv_agg's multi_logloss: 1.16288 + 0.00545963\n[87]\tcv_agg's multi_logloss: 1.16206 + 0.00549074\n",
      "[88]\tcv_agg's multi_logloss: 1.16131 + 0.00550814\n[89]\tcv_agg's multi_logloss: 1.16053 + 0.00554608\n[90]\tcv_agg's multi_logloss: 1.15973 + 0.00556207\n",
      "[91]\tcv_agg's multi_logloss: 1.15899 + 0.0056687\n[92]\tcv_agg's multi_logloss: 1.15826 + 0.00573284\n[93]\tcv_agg's multi_logloss: 1.15743 + 0.00576314\n[94]\tcv_agg's multi_logloss: 1.15674 + 0.0057866\n",
      "[95]\tcv_agg's multi_logloss: 1.15598 + 0.00584947\n[96]\tcv_agg's multi_logloss: 1.15528 + 0.00590382\n[97]\tcv_agg's multi_logloss: 1.15454 + 0.00593649\n[98]\tcv_agg's multi_logloss: 1.15383 + 0.00600181\n[99]\tcv_agg's multi_logloss: 1.15305 + 0.00602574\n[100]\tcv_agg's multi_logloss: 1.15242 + 0.00605215\n",
      "[101]\tcv_agg's multi_logloss: 1.15168 + 0.00604484\n[102]\tcv_agg's multi_logloss: 1.15101 + 0.0060593\n[103]\tcv_agg's multi_logloss: 1.15036 + 0.00618813\n",
      "[104]\tcv_agg's multi_logloss: 1.14976 + 0.00624407\n[105]\tcv_agg's multi_logloss: 1.14909 + 0.00633638\n[106]\tcv_agg's multi_logloss: 1.14843 + 0.00644489\n[107]\tcv_agg's multi_logloss: 1.14778 + 0.00653184\n",
      "[108]\tcv_agg's multi_logloss: 1.14719 + 0.00656315\n[109]\tcv_agg's multi_logloss: 1.14657 + 0.00663153\n[110]\tcv_agg's multi_logloss: 1.14598 + 0.00669241\n[111]\tcv_agg's multi_logloss: 1.14546 + 0.00673419\n[112]\tcv_agg's multi_logloss: 1.14488 + 0.00681914\n[113]\tcv_agg's multi_logloss: 1.14428 + 0.00690318\n",
      "[114]\tcv_agg's multi_logloss: 1.14372 + 0.00695098\n[115]\tcv_agg's multi_logloss: 1.14316 + 0.00697601\n[116]\tcv_agg's multi_logloss: 1.14254 + 0.00703637\n",
      "[117]\tcv_agg's multi_logloss: 1.14204 + 0.00711178\n[118]\tcv_agg's multi_logloss: 1.14152 + 0.00716577\n[119]\tcv_agg's multi_logloss: 1.14099 + 0.00727827\n",
      "[120]\tcv_agg's multi_logloss: 1.14039 + 0.00736394\n[121]\tcv_agg's multi_logloss: 1.13986 + 0.00744895\n[122]\tcv_agg's multi_logloss: 1.13933 + 0.00753525\n[123]\tcv_agg's multi_logloss: 1.13891 + 0.007579\n[124]\tcv_agg's multi_logloss: 1.13843 + 0.00767923\n[125]\tcv_agg's multi_logloss: 1.13789 + 0.0076867\n",
      "[126]\tcv_agg's multi_logloss: 1.13733 + 0.00774971\n[127]\tcv_agg's multi_logloss: 1.13682 + 0.00782153\n[128]\tcv_agg's multi_logloss: 1.1363 + 0.0078553\n",
      "[129]\tcv_agg's multi_logloss: 1.13587 + 0.00797049\n[130]\tcv_agg's multi_logloss: 1.1354 + 0.00800051\n[131]\tcv_agg's multi_logloss: 1.13491 + 0.00804348\n",
      "[132]\tcv_agg's multi_logloss: 1.1345 + 0.00811628\n[133]\tcv_agg's multi_logloss: 1.13408 + 0.00816325\n[134]\tcv_agg's multi_logloss: 1.13358 + 0.00823872\n[135]\tcv_agg's multi_logloss: 1.13309 + 0.00827632\n[136]\tcv_agg's multi_logloss: 1.13264 + 0.00831544\n[137]\tcv_agg's multi_logloss: 1.13211 + 0.00833742\n[138]\tcv_agg's multi_logloss: 1.13165 + 0.00839359\n",
      "[139]\tcv_agg's multi_logloss: 1.13115 + 0.00846171\n[140]\tcv_agg's multi_logloss: 1.1307 + 0.00848625\n",
      "[141]\tcv_agg's multi_logloss: 1.13022 + 0.00854103\n[142]\tcv_agg's multi_logloss: 1.12979 + 0.00857981\n[143]\tcv_agg's multi_logloss: 1.12936 + 0.00865666\n",
      "[144]\tcv_agg's multi_logloss: 1.1289 + 0.00872119\n[145]\tcv_agg's multi_logloss: 1.12842 + 0.00880006\n[146]\tcv_agg's multi_logloss: 1.12808 + 0.008821\n[147]\tcv_agg's multi_logloss: 1.12764 + 0.00887793\n[148]\tcv_agg's multi_logloss: 1.12723 + 0.0089093\n[149]\tcv_agg's multi_logloss: 1.12679 + 0.00894095\n[150]\tcv_agg's multi_logloss: 1.12639 + 0.00898113\n",
      "[151]\tcv_agg's multi_logloss: 1.12596 + 0.00900963\n[152]\tcv_agg's multi_logloss: 1.12558 + 0.00908699\n[153]\tcv_agg's multi_logloss: 1.12521 + 0.00916056\n",
      "[154]\tcv_agg's multi_logloss: 1.12489 + 0.00924542\n[155]\tcv_agg's multi_logloss: 1.12452 + 0.00931379\n[156]\tcv_agg's multi_logloss: 1.12411 + 0.00935813\n",
      "[157]\tcv_agg's multi_logloss: 1.12375 + 0.00941931\n[158]\tcv_agg's multi_logloss: 1.12347 + 0.0094271\n[159]\tcv_agg's multi_logloss: 1.12312 + 0.0095523\n[160]\tcv_agg's multi_logloss: 1.12276 + 0.00961813\n[161]\tcv_agg's multi_logloss: 1.12247 + 0.00965307\n[162]\tcv_agg's multi_logloss: 1.12216 + 0.00973347\n",
      "[163]\tcv_agg's multi_logloss: 1.1218 + 0.00977314\n[164]\tcv_agg's multi_logloss: 1.12146 + 0.00980205\n[165]\tcv_agg's multi_logloss: 1.12114 + 0.00982739\n",
      "[166]\tcv_agg's multi_logloss: 1.12076 + 0.00979446\n[167]\tcv_agg's multi_logloss: 1.12031 + 0.0098173\n[168]\tcv_agg's multi_logloss: 1.11996 + 0.00984104\n",
      "[169]\tcv_agg's multi_logloss: 1.11962 + 0.00980058\n[170]\tcv_agg's multi_logloss: 1.11927 + 0.00979999\n[171]\tcv_agg's multi_logloss: 1.119 + 0.00988974\n[172]\tcv_agg's multi_logloss: 1.11873 + 0.00994114\n[173]\tcv_agg's multi_logloss: 1.11842 + 0.00996748\n[174]\tcv_agg's multi_logloss: 1.11817 + 0.0100281\n",
      "[175]\tcv_agg's multi_logloss: 1.1179 + 0.0100205\n[176]\tcv_agg's multi_logloss: 1.11757 + 0.0100339\n[177]\tcv_agg's multi_logloss: 1.11721 + 0.0100754\n",
      "[178]\tcv_agg's multi_logloss: 1.11685 + 0.0102023\n[179]\tcv_agg's multi_logloss: 1.11659 + 0.0102262\n[180]\tcv_agg's multi_logloss: 1.11635 + 0.0102643\n",
      "[181]\tcv_agg's multi_logloss: 1.11603 + 0.0103315\n[182]\tcv_agg's multi_logloss: 1.11572 + 0.0103254\n[183]\tcv_agg's multi_logloss: 1.11542 + 0.0104074\n[184]\tcv_agg's multi_logloss: 1.11511 + 0.0104465\n[185]\tcv_agg's multi_logloss: 1.11483 + 0.0105095\n[186]\tcv_agg's multi_logloss: 1.11452 + 0.0105618\n[187]\tcv_agg's multi_logloss: 1.11425 + 0.0106305\n",
      "[188]\tcv_agg's multi_logloss: 1.11397 + 0.0107007\n[189]\tcv_agg's multi_logloss: 1.11371 + 0.0107098\n",
      "[190]\tcv_agg's multi_logloss: 1.11349 + 0.010779\n[191]\tcv_agg's multi_logloss: 1.1132 + 0.0108168\n[192]\tcv_agg's multi_logloss: 1.11299 + 0.0108342\n",
      "[193]\tcv_agg's multi_logloss: 1.11273 + 0.0108076\n[194]\tcv_agg's multi_logloss: 1.11248 + 0.0108263\n[195]\tcv_agg's multi_logloss: 1.11223 + 0.0108682\n[196]\tcv_agg's multi_logloss: 1.112 + 0.0108908\n[197]\tcv_agg's multi_logloss: 1.11173 + 0.0108744\n[198]\tcv_agg's multi_logloss: 1.11149 + 0.0108964\n[199]\tcv_agg's multi_logloss: 1.1112 + 0.010925\n",
      "[200]\tcv_agg's multi_logloss: 1.11092 + 0.0109226\n[201]\tcv_agg's multi_logloss: 1.11072 + 0.0109435\n",
      "[202]\tcv_agg's multi_logloss: 1.11051 + 0.0109581\n[203]\tcv_agg's multi_logloss: 1.11028 + 0.0109984\n[204]\tcv_agg's multi_logloss: 1.11003 + 0.0110393\n",
      "[205]\tcv_agg's multi_logloss: 1.1098 + 0.0110721\n[206]\tcv_agg's multi_logloss: 1.10953 + 0.0111569\n[207]\tcv_agg's multi_logloss: 1.10931 + 0.0111581\n[208]\tcv_agg's multi_logloss: 1.10908 + 0.011163\n[209]\tcv_agg's multi_logloss: 1.10889 + 0.0112045\n[210]\tcv_agg's multi_logloss: 1.10869 + 0.0112162\n[211]\tcv_agg's multi_logloss: 1.10842 + 0.0112524\n",
      "[212]\tcv_agg's multi_logloss: 1.10819 + 0.0112625\n[213]\tcv_agg's multi_logloss: 1.10795 + 0.0113487\n",
      "[214]\tcv_agg's multi_logloss: 1.10772 + 0.0113803\n[215]\tcv_agg's multi_logloss: 1.10748 + 0.0114576\n[216]\tcv_agg's multi_logloss: 1.10727 + 0.0114775\n",
      "[217]\tcv_agg's multi_logloss: 1.10706 + 0.0115165\n[218]\tcv_agg's multi_logloss: 1.10685 + 0.0115663\n[219]\tcv_agg's multi_logloss: 1.10668 + 0.0116023\n[220]\tcv_agg's multi_logloss: 1.10649 + 0.0116934\n[221]\tcv_agg's multi_logloss: 1.10629 + 0.0117321\n[222]\tcv_agg's multi_logloss: 1.10611 + 0.0117839\n[223]\tcv_agg's multi_logloss: 1.10588 + 0.0118217\n",
      "[224]\tcv_agg's multi_logloss: 1.10565 + 0.0118134\n[225]\tcv_agg's multi_logloss: 1.10544 + 0.0118414\n",
      "[226]\tcv_agg's multi_logloss: 1.10521 + 0.0118565\n[227]\tcv_agg's multi_logloss: 1.10507 + 0.0118909\n[228]\tcv_agg's multi_logloss: 1.10491 + 0.011908\n[229]\tcv_agg's multi_logloss: 1.10472 + 0.011931\n",
      "[230]\tcv_agg's multi_logloss: 1.10451 + 0.0119702\n[231]\tcv_agg's multi_logloss: 1.10431 + 0.0120084\n[232]\tcv_agg's multi_logloss: 1.10416 + 0.0120727\n[233]\tcv_agg's multi_logloss: 1.10397 + 0.0120933\n[234]\tcv_agg's multi_logloss: 1.10381 + 0.012134\n[235]\tcv_agg's multi_logloss: 1.10364 + 0.012223\n",
      "[236]\tcv_agg's multi_logloss: 1.10347 + 0.0122333\n[237]\tcv_agg's multi_logloss: 1.10323 + 0.0122615\n",
      "[238]\tcv_agg's multi_logloss: 1.10304 + 0.012271\n[239]\tcv_agg's multi_logloss: 1.10285 + 0.0123009\n[240]\tcv_agg's multi_logloss: 1.10265 + 0.0123431\n[241]\tcv_agg's multi_logloss: 1.10251 + 0.0123713\n",
      "[242]\tcv_agg's multi_logloss: 1.10235 + 0.0123997\n[243]\tcv_agg's multi_logloss: 1.10218 + 0.0124569\n[244]\tcv_agg's multi_logloss: 1.10199 + 0.012485\n[245]\tcv_agg's multi_logloss: 1.10185 + 0.0125585\n[246]\tcv_agg's multi_logloss: 1.10171 + 0.0126371\n[247]\tcv_agg's multi_logloss: 1.10158 + 0.0126637\n",
      "[248]\tcv_agg's multi_logloss: 1.10146 + 0.0127011\n[249]\tcv_agg's multi_logloss: 1.10131 + 0.012737\n",
      "[250]\tcv_agg's multi_logloss: 1.10116 + 0.0127527\n[251]\tcv_agg's multi_logloss: 1.10102 + 0.0127431\n[252]\tcv_agg's multi_logloss: 1.1009 + 0.0127602\n[253]\tcv_agg's multi_logloss: 1.10075 + 0.0127555\n[254]\tcv_agg's multi_logloss: 1.10064 + 0.0127684\n",
      "[255]\tcv_agg's multi_logloss: 1.10055 + 0.0127779\n[256]\tcv_agg's multi_logloss: 1.10038 + 0.0128256\n[257]\tcv_agg's multi_logloss: 1.10016 + 0.0128782\n[258]\tcv_agg's multi_logloss: 1.1 + 0.0128937\n[259]\tcv_agg's multi_logloss: 1.09985 + 0.0129455\n",
      "[260]\tcv_agg's multi_logloss: 1.09964 + 0.0130072\n[261]\tcv_agg's multi_logloss: 1.09954 + 0.0130177\n",
      "[262]\tcv_agg's multi_logloss: 1.09941 + 0.0130733\n[263]\tcv_agg's multi_logloss: 1.09928 + 0.0130997\n[264]\tcv_agg's multi_logloss: 1.09917 + 0.013177\n[265]\tcv_agg's multi_logloss: 1.09904 + 0.0132051\n[266]\tcv_agg's multi_logloss: 1.09896 + 0.0132717\n",
      "[267]\tcv_agg's multi_logloss: 1.09878 + 0.0133245\n[268]\tcv_agg's multi_logloss: 1.0987 + 0.0133329\n[269]\tcv_agg's multi_logloss: 1.09858 + 0.0133248\n[270]\tcv_agg's multi_logloss: 1.09843 + 0.013296\n[271]\tcv_agg's multi_logloss: 1.09832 + 0.0133179\n",
      "[272]\tcv_agg's multi_logloss: 1.0982 + 0.0133549\n[273]\tcv_agg's multi_logloss: 1.09809 + 0.0133908\n",
      "[274]\tcv_agg's multi_logloss: 1.098 + 0.0134105\n[275]\tcv_agg's multi_logloss: 1.09789 + 0.0134306\n[276]\tcv_agg's multi_logloss: 1.09782 + 0.0134247\n[277]\tcv_agg's multi_logloss: 1.09765 + 0.0134519\n[278]\tcv_agg's multi_logloss: 1.09745 + 0.0135219\n",
      "[279]\tcv_agg's multi_logloss: 1.09728 + 0.0135394\n[280]\tcv_agg's multi_logloss: 1.09715 + 0.0136263\n[281]\tcv_agg's multi_logloss: 1.09702 + 0.0136588\n[282]\tcv_agg's multi_logloss: 1.09687 + 0.0137233\n[283]\tcv_agg's multi_logloss: 1.09677 + 0.0137452\n[284]\tcv_agg's multi_logloss: 1.09664 + 0.0137902\n",
      "[285]\tcv_agg's multi_logloss: 1.09651 + 0.0138364\n[286]\tcv_agg's multi_logloss: 1.09643 + 0.0139177\n",
      "[287]\tcv_agg's multi_logloss: 1.09634 + 0.0139142\n[288]\tcv_agg's multi_logloss: 1.09622 + 0.0139644\n[289]\tcv_agg's multi_logloss: 1.09606 + 0.0140023\n[290]\tcv_agg's multi_logloss: 1.09593 + 0.0140392\n[291]\tcv_agg's multi_logloss: 1.09584 + 0.0140994\n",
      "[292]\tcv_agg's multi_logloss: 1.09578 + 0.0141522\n[293]\tcv_agg's multi_logloss: 1.0957 + 0.014216\n[294]\tcv_agg's multi_logloss: 1.09565 + 0.0142389\n[295]\tcv_agg's multi_logloss: 1.09558 + 0.014288\n[296]\tcv_agg's multi_logloss: 1.09549 + 0.0142843\n[297]\tcv_agg's multi_logloss: 1.09538 + 0.0143004\n",
      "[298]\tcv_agg's multi_logloss: 1.09531 + 0.0143028\n[299]\tcv_agg's multi_logloss: 1.09519 + 0.0143188\n",
      "[300]\tcv_agg's multi_logloss: 1.09507 + 0.0143536\n[301]\tcv_agg's multi_logloss: 1.095 + 0.0143316\n[302]\tcv_agg's multi_logloss: 1.0949 + 0.0143154\n[303]\tcv_agg's multi_logloss: 1.09483 + 0.0143105\n[304]\tcv_agg's multi_logloss: 1.09471 + 0.014293\n",
      "[305]\tcv_agg's multi_logloss: 1.09464 + 0.0142905\n[306]\tcv_agg's multi_logloss: 1.09454 + 0.0143193\n[307]\tcv_agg's multi_logloss: 1.09444 + 0.0143753\n[308]\tcv_agg's multi_logloss: 1.09433 + 0.0143632\n[309]\tcv_agg's multi_logloss: 1.09422 + 0.0143916\n",
      "[310]\tcv_agg's multi_logloss: 1.0942 + 0.0144332\n[311]\tcv_agg's multi_logloss: 1.09411 + 0.0145496\n",
      "[312]\tcv_agg's multi_logloss: 1.09403 + 0.0145633\n[313]\tcv_agg's multi_logloss: 1.09401 + 0.0145768\n[314]\tcv_agg's multi_logloss: 1.09392 + 0.0145703\n[315]\tcv_agg's multi_logloss: 1.0938 + 0.0145961\n[316]\tcv_agg's multi_logloss: 1.09374 + 0.0146248\n[317]\tcv_agg's multi_logloss: 1.09366 + 0.0146624\n",
      "[318]\tcv_agg's multi_logloss: 1.09356 + 0.0147109\n[319]\tcv_agg's multi_logloss: 1.0934 + 0.0147369\n[320]\tcv_agg's multi_logloss: 1.09335 + 0.0147968\n[321]\tcv_agg's multi_logloss: 1.09324 + 0.0148607\n[322]\tcv_agg's multi_logloss: 1.09321 + 0.0148941\n",
      "[323]\tcv_agg's multi_logloss: 1.09315 + 0.0149539\n[324]\tcv_agg's multi_logloss: 1.09302 + 0.0150473\n",
      "[325]\tcv_agg's multi_logloss: 1.09297 + 0.0150997\n[326]\tcv_agg's multi_logloss: 1.09288 + 0.0151661\n[327]\tcv_agg's multi_logloss: 1.09277 + 0.0152207\n[328]\tcv_agg's multi_logloss: 1.09269 + 0.0152434\n[329]\tcv_agg's multi_logloss: 1.09257 + 0.0152426\n",
      "[330]\tcv_agg's multi_logloss: 1.09245 + 0.0152812\n[331]\tcv_agg's multi_logloss: 1.09238 + 0.0153179\n[332]\tcv_agg's multi_logloss: 1.09233 + 0.0154228\n[333]\tcv_agg's multi_logloss: 1.09231 + 0.01546\n[334]\tcv_agg's multi_logloss: 1.09225 + 0.0154982\n[335]\tcv_agg's multi_logloss: 1.09221 + 0.0155487\n",
      "[336]\tcv_agg's multi_logloss: 1.09219 + 0.0156203\n",
      "[337]\tcv_agg's multi_logloss: 1.09219 + 0.0156783\n[338]\tcv_agg's multi_logloss: 1.09216 + 0.0157379\n[339]\tcv_agg's multi_logloss: 1.09212 + 0.015751\n[340]\tcv_agg's multi_logloss: 1.09204 + 0.0157634\n[341]\tcv_agg's multi_logloss: 1.09194 + 0.0158145\n[342]\tcv_agg's multi_logloss: 1.09183 + 0.0158264\n",
      "[343]\tcv_agg's multi_logloss: 1.09175 + 0.0158572\n[344]\tcv_agg's multi_logloss: 1.09165 + 0.015859\n[345]\tcv_agg's multi_logloss: 1.09154 + 0.0158813\n[346]\tcv_agg's multi_logloss: 1.09145 + 0.0159627\n[347]\tcv_agg's multi_logloss: 1.09139 + 0.0160287\n[348]\tcv_agg's multi_logloss: 1.09134 + 0.0160732\n",
      "[349]\tcv_agg's multi_logloss: 1.09128 + 0.0161272\n",
      "[350]\tcv_agg's multi_logloss: 1.09122 + 0.0162298\n[351]\tcv_agg's multi_logloss: 1.09114 + 0.0162442\n[352]\tcv_agg's multi_logloss: 1.09113 + 0.0162454\n[353]\tcv_agg's multi_logloss: 1.09106 + 0.0162606\n[354]\tcv_agg's multi_logloss: 1.09101 + 0.0162095\n[355]\tcv_agg's multi_logloss: 1.09096 + 0.0162007\n",
      "[356]\tcv_agg's multi_logloss: 1.09093 + 0.0161838\n[357]\tcv_agg's multi_logloss: 1.09088 + 0.0162006\n[358]\tcv_agg's multi_logloss: 1.09078 + 0.0162238\n[359]\tcv_agg's multi_logloss: 1.09069 + 0.0162455\n[360]\tcv_agg's multi_logloss: 1.09065 + 0.0162465\n[361]\tcv_agg's multi_logloss: 1.09058 + 0.0162592\n",
      "[362]\tcv_agg's multi_logloss: 1.09047 + 0.0161962\n",
      "[363]\tcv_agg's multi_logloss: 1.09047 + 0.0162006\n[364]\tcv_agg's multi_logloss: 1.09043 + 0.0161488\n[365]\tcv_agg's multi_logloss: 1.09038 + 0.0161691\n[366]\tcv_agg's multi_logloss: 1.09034 + 0.0162097\n[367]\tcv_agg's multi_logloss: 1.09029 + 0.0162784\n[368]\tcv_agg's multi_logloss: 1.09024 + 0.0163314\n",
      "[369]\tcv_agg's multi_logloss: 1.09022 + 0.0163929\n[370]\tcv_agg's multi_logloss: 1.09019 + 0.0164472\n[371]\tcv_agg's multi_logloss: 1.09015 + 0.0164738\n[372]\tcv_agg's multi_logloss: 1.09008 + 0.0165023\n[373]\tcv_agg's multi_logloss: 1.09002 + 0.0164419\n[374]\tcv_agg's multi_logloss: 1.09001 + 0.0164389\n",
      "[375]\tcv_agg's multi_logloss: 1.08994 + 0.0164569\n",
      "[376]\tcv_agg's multi_logloss: 1.08984 + 0.0164667\n[377]\tcv_agg's multi_logloss: 1.0898 + 0.0165476\n[378]\tcv_agg's multi_logloss: 1.08975 + 0.0165888\n[379]\tcv_agg's multi_logloss: 1.08967 + 0.0166054\n[380]\tcv_agg's multi_logloss: 1.08961 + 0.0165909\n[381]\tcv_agg's multi_logloss: 1.08952 + 0.0166167\n",
      "[382]\tcv_agg's multi_logloss: 1.08948 + 0.0166157\n[383]\tcv_agg's multi_logloss: 1.08949 + 0.0166387\n[384]\tcv_agg's multi_logloss: 1.08942 + 0.0166384\n[385]\tcv_agg's multi_logloss: 1.08936 + 0.0166478\n[386]\tcv_agg's multi_logloss: 1.08932 + 0.0166734\n[387]\tcv_agg's multi_logloss: 1.08929 + 0.0166702\n",
      "[388]\tcv_agg's multi_logloss: 1.08929 + 0.016669\n",
      "[389]\tcv_agg's multi_logloss: 1.08927 + 0.0166824\n[390]\tcv_agg's multi_logloss: 1.08926 + 0.0166958\n[391]\tcv_agg's multi_logloss: 1.08923 + 0.0167215\n[392]\tcv_agg's multi_logloss: 1.08919 + 0.016764\n[393]\tcv_agg's multi_logloss: 1.08914 + 0.0167541\n[394]\tcv_agg's multi_logloss: 1.08912 + 0.0167759\n",
      "[395]\tcv_agg's multi_logloss: 1.08907 + 0.0168035\n[396]\tcv_agg's multi_logloss: 1.08904 + 0.0167919\n[397]\tcv_agg's multi_logloss: 1.08899 + 0.0168076\n[398]\tcv_agg's multi_logloss: 1.08896 + 0.0168019\n[399]\tcv_agg's multi_logloss: 1.08895 + 0.0168143\n[400]\tcv_agg's multi_logloss: 1.08894 + 0.0167729\n",
      "[401]\tcv_agg's multi_logloss: 1.08887 + 0.0168126\n",
      "[402]\tcv_agg's multi_logloss: 1.08871 + 0.0168789\n[403]\tcv_agg's multi_logloss: 1.08867 + 0.0169174\n[404]\tcv_agg's multi_logloss: 1.08865 + 0.0169806\n[405]\tcv_agg's multi_logloss: 1.08859 + 0.0170185\n[406]\tcv_agg's multi_logloss: 1.08851 + 0.0170676\n[407]\tcv_agg's multi_logloss: 1.08849 + 0.0170821\n",
      "[408]\tcv_agg's multi_logloss: 1.08849 + 0.0171198\n[409]\tcv_agg's multi_logloss: 1.08849 + 0.0171602\n[410]\tcv_agg's multi_logloss: 1.08846 + 0.0172096\n[411]\tcv_agg's multi_logloss: 1.08846 + 0.0172021\n[412]\tcv_agg's multi_logloss: 1.08843 + 0.0171992\n[413]\tcv_agg's multi_logloss: 1.08837 + 0.0172396\n",
      "[414]\tcv_agg's multi_logloss: 1.08833 + 0.017239\n",
      "[415]\tcv_agg's multi_logloss: 1.0883 + 0.017266\n[416]\tcv_agg's multi_logloss: 1.08822 + 0.0172603\n[417]\tcv_agg's multi_logloss: 1.08817 + 0.0172309\n[418]\tcv_agg's multi_logloss: 1.08815 + 0.0171999\n[419]\tcv_agg's multi_logloss: 1.08807 + 0.0172242\n[420]\tcv_agg's multi_logloss: 1.088 + 0.0172212\n",
      "[421]\tcv_agg's multi_logloss: 1.08793 + 0.0172377\n[422]\tcv_agg's multi_logloss: 1.08791 + 0.0172156\n[423]\tcv_agg's multi_logloss: 1.08789 + 0.0172093\n[424]\tcv_agg's multi_logloss: 1.08783 + 0.0172281\n[425]\tcv_agg's multi_logloss: 1.08781 + 0.0172368\n[426]\tcv_agg's multi_logloss: 1.08783 + 0.0172361\n",
      "[427]\tcv_agg's multi_logloss: 1.08781 + 0.01728\n",
      "[428]\tcv_agg's multi_logloss: 1.08779 + 0.017284\n[429]\tcv_agg's multi_logloss: 1.08777 + 0.0173358\n[430]\tcv_agg's multi_logloss: 1.08774 + 0.0173314\n[431]\tcv_agg's multi_logloss: 1.08771 + 0.0173144\n[432]\tcv_agg's multi_logloss: 1.08769 + 0.0173084\n[433]\tcv_agg's multi_logloss: 1.08766 + 0.0173141\n",
      "[434]\tcv_agg's multi_logloss: 1.08766 + 0.0172586\n[435]\tcv_agg's multi_logloss: 1.08767 + 0.0172431\n[436]\tcv_agg's multi_logloss: 1.08763 + 0.0172732\n[437]\tcv_agg's multi_logloss: 1.08763 + 0.0172897\n[438]\tcv_agg's multi_logloss: 1.08762 + 0.0172814\n[439]\tcv_agg's multi_logloss: 1.0876 + 0.0173239\n",
      "[440]\tcv_agg's multi_logloss: 1.08758 + 0.017362\n",
      "[441]\tcv_agg's multi_logloss: 1.08755 + 0.0173665\n[442]\tcv_agg's multi_logloss: 1.08752 + 0.017391\n[443]\tcv_agg's multi_logloss: 1.0875 + 0.0174271\n[444]\tcv_agg's multi_logloss: 1.0875 + 0.0175045\n[445]\tcv_agg's multi_logloss: 1.08748 + 0.0175308\n[446]\tcv_agg's multi_logloss: 1.08747 + 0.0175636\n",
      "[447]\tcv_agg's multi_logloss: 1.08743 + 0.0176345\n[448]\tcv_agg's multi_logloss: 1.08744 + 0.0176702\n[449]\tcv_agg's multi_logloss: 1.08738 + 0.0176767\n[450]\tcv_agg's multi_logloss: 1.0873 + 0.0177194\n[451]\tcv_agg's multi_logloss: 1.08733 + 0.0177404\n[452]\tcv_agg's multi_logloss: 1.08731 + 0.0177506\n",
      "[453]\tcv_agg's multi_logloss: 1.08728 + 0.0177861\n",
      "[454]\tcv_agg's multi_logloss: 1.08725 + 0.017807\n[455]\tcv_agg's multi_logloss: 1.08719 + 0.0178156\n[456]\tcv_agg's multi_logloss: 1.08716 + 0.0178224\n[457]\tcv_agg's multi_logloss: 1.08712 + 0.0178251\n[458]\tcv_agg's multi_logloss: 1.08708 + 0.0178392\n[459]\tcv_agg's multi_logloss: 1.08707 + 0.0178217\n",
      "[460]\tcv_agg's multi_logloss: 1.08701 + 0.0178221\n[461]\tcv_agg's multi_logloss: 1.08703 + 0.0177961\n[462]\tcv_agg's multi_logloss: 1.08698 + 0.017744\n[463]\tcv_agg's multi_logloss: 1.08699 + 0.0177392\n[464]\tcv_agg's multi_logloss: 1.08698 + 0.0177208\n[465]\tcv_agg's multi_logloss: 1.08697 + 0.017715\n",
      "[466]\tcv_agg's multi_logloss: 1.08696 + 0.0177081\n",
      "[467]\tcv_agg's multi_logloss: 1.08693 + 0.0177098\n[468]\tcv_agg's multi_logloss: 1.08693 + 0.0177132\n[469]\tcv_agg's multi_logloss: 1.08692 + 0.0177053\n[470]\tcv_agg's multi_logloss: 1.08692 + 0.0177031\n[471]\tcv_agg's multi_logloss: 1.08694 + 0.017737\n[472]\tcv_agg's multi_logloss: 1.08693 + 0.0177194\n",
      "[473]\tcv_agg's multi_logloss: 1.08692 + 0.017704\n[474]\tcv_agg's multi_logloss: 1.08694 + 0.0177399\n[475]\tcv_agg's multi_logloss: 1.08695 + 0.0177523\n[476]\tcv_agg's multi_logloss: 1.08694 + 0.0177702\n[477]\tcv_agg's multi_logloss: 1.08691 + 0.0177805\n[478]\tcv_agg's multi_logloss: 1.08686 + 0.01779\n",
      "[479]\tcv_agg's multi_logloss: 1.08693 + 0.0178045\n",
      "[480]\tcv_agg's multi_logloss: 1.08686 + 0.0178405\n[481]\tcv_agg's multi_logloss: 1.08682 + 0.017823\n[482]\tcv_agg's multi_logloss: 1.08682 + 0.0178496\n[483]\tcv_agg's multi_logloss: 1.08678 + 0.0178747\n[484]\tcv_agg's multi_logloss: 1.08675 + 0.0178601\n[485]\tcv_agg's multi_logloss: 1.08674 + 0.0178595\n",
      "[486]\tcv_agg's multi_logloss: 1.08676 + 0.0178788\n[487]\tcv_agg's multi_logloss: 1.08677 + 0.0178618\n[488]\tcv_agg's multi_logloss: 1.08676 + 0.0178755\n[489]\tcv_agg's multi_logloss: 1.08674 + 0.0178416\n[490]\tcv_agg's multi_logloss: 1.08671 + 0.0178368\n[491]\tcv_agg's multi_logloss: 1.08663 + 0.017853\n",
      "[492]\tcv_agg's multi_logloss: 1.08659 + 0.0179227\n",
      "[493]\tcv_agg's multi_logloss: 1.0866 + 0.0179735\n[494]\tcv_agg's multi_logloss: 1.08655 + 0.0180449\n[495]\tcv_agg's multi_logloss: 1.08656 + 0.0180706\n[496]\tcv_agg's multi_logloss: 1.08655 + 0.0180929\n[497]\tcv_agg's multi_logloss: 1.08653 + 0.0181053\n[498]\tcv_agg's multi_logloss: 1.08654 + 0.0181589\n[499]\tcv_agg's multi_logloss: 1.08657 + 0.0181729\n",
      "[500]\tcv_agg's multi_logloss: 1.08654 + 0.018198\n[501]\tcv_agg's multi_logloss: 1.08648 + 0.0182138\n[502]\tcv_agg's multi_logloss: 1.08647 + 0.0182011\n[503]\tcv_agg's multi_logloss: 1.08648 + 0.0182272\n[504]\tcv_agg's multi_logloss: 1.0865 + 0.0182515\n",
      "[505]\tcv_agg's multi_logloss: 1.08645 + 0.0182298\n",
      "[506]\tcv_agg's multi_logloss: 1.08645 + 0.0182214\n[507]\tcv_agg's multi_logloss: 1.08641 + 0.0181986\n[508]\tcv_agg's multi_logloss: 1.08634 + 0.0182123\n[509]\tcv_agg's multi_logloss: 1.08634 + 0.0181991\n[510]\tcv_agg's multi_logloss: 1.08631 + 0.0182303\n[511]\tcv_agg's multi_logloss: 1.08628 + 0.0182905\n[512]\tcv_agg's multi_logloss: 1.08624 + 0.0183055\n[513]\tcv_agg's multi_logloss: 1.08624 + 0.0183426\n",
      "[514]\tcv_agg's multi_logloss: 1.08624 + 0.0183342\n[515]\tcv_agg's multi_logloss: 1.08626 + 0.0183527\n[516]\tcv_agg's multi_logloss: 1.08623 + 0.0183853\n[517]\tcv_agg's multi_logloss: 1.08621 + 0.0184195\n[518]\tcv_agg's multi_logloss: 1.08619 + 0.0184434\n",
      "[519]\tcv_agg's multi_logloss: 1.08616 + 0.0184504\n",
      "[520]\tcv_agg's multi_logloss: 1.08614 + 0.0184949\n[521]\tcv_agg's multi_logloss: 1.08615 + 0.018477\n[522]\tcv_agg's multi_logloss: 1.08615 + 0.018533\n[523]\tcv_agg's multi_logloss: 1.08611 + 0.0185544\n[524]\tcv_agg's multi_logloss: 1.08613 + 0.0185322\n[525]\tcv_agg's multi_logloss: 1.08611 + 0.0185623\n[526]\tcv_agg's multi_logloss: 1.08614 + 0.0185736\n",
      "[527]\tcv_agg's multi_logloss: 1.08619 + 0.0185722\n[528]\tcv_agg's multi_logloss: 1.08622 + 0.0185751\n[529]\tcv_agg's multi_logloss: 1.08622 + 0.0185782\n[530]\tcv_agg's multi_logloss: 1.08624 + 0.0186013\n[531]\tcv_agg's multi_logloss: 1.08624 + 0.0186088\n",
      "[532]\tcv_agg's multi_logloss: 1.08621 + 0.0186331\n",
      "[533]\tcv_agg's multi_logloss: 1.08622 + 0.0186826\n[534]\tcv_agg's multi_logloss: 1.08623 + 0.0187131\n[535]\tcv_agg's multi_logloss: 1.08618 + 0.0187536\n[536]\tcv_agg's multi_logloss: 1.08618 + 0.0187537\n[537]\tcv_agg's multi_logloss: 1.08616 + 0.0187729\n[538]\tcv_agg's multi_logloss: 1.08618 + 0.0187899\n[539]\tcv_agg's multi_logloss: 1.08619 + 0.0188167\n[540]\tcv_agg's multi_logloss: 1.08621 + 0.0188533\n",
      "[541]\tcv_agg's multi_logloss: 1.08622 + 0.0188417\n[542]\tcv_agg's multi_logloss: 1.08622 + 0.018868\n[543]\tcv_agg's multi_logloss: 1.0862 + 0.0188831\n[544]\tcv_agg's multi_logloss: 1.08624 + 0.0188819\n",
      "[545]\tcv_agg's multi_logloss: 1.08623 + 0.0189045\n",
      "[546]\tcv_agg's multi_logloss: 1.08614 + 0.0189184\n[547]\tcv_agg's multi_logloss: 1.08607 + 0.0189871\n[548]\tcv_agg's multi_logloss: 1.08606 + 0.0190292\n[549]\tcv_agg's multi_logloss: 1.08604 + 0.0190628\n[550]\tcv_agg's multi_logloss: 1.08603 + 0.0190973\n[551]\tcv_agg's multi_logloss: 1.08601 + 0.0191248\n[552]\tcv_agg's multi_logloss: 1.08602 + 0.0191394\n[553]\tcv_agg's multi_logloss: 1.08602 + 0.0191005\n",
      "[554]\tcv_agg's multi_logloss: 1.08603 + 0.0190996\n[555]\tcv_agg's multi_logloss: 1.08607 + 0.0190756\n[556]\tcv_agg's multi_logloss: 1.08607 + 0.0190556\n[557]\tcv_agg's multi_logloss: 1.08603 + 0.0190935\n",
      "[558]\tcv_agg's multi_logloss: 1.08599 + 0.0190889\n",
      "[559]\tcv_agg's multi_logloss: 1.08594 + 0.0190926\n[560]\tcv_agg's multi_logloss: 1.08593 + 0.0190885\n[561]\tcv_agg's multi_logloss: 1.08594 + 0.0191027\n[562]\tcv_agg's multi_logloss: 1.08592 + 0.0190864\n[563]\tcv_agg's multi_logloss: 1.08594 + 0.0190889\n[564]\tcv_agg's multi_logloss: 1.0859 + 0.0190893\n[565]\tcv_agg's multi_logloss: 1.08591 + 0.0190752\n[566]\tcv_agg's multi_logloss: 1.08589 + 0.0190858\n",
      "[567]\tcv_agg's multi_logloss: 1.08589 + 0.0190803\n[568]\tcv_agg's multi_logloss: 1.08589 + 0.0190845\n[569]\tcv_agg's multi_logloss: 1.08587 + 0.019126\n[570]\tcv_agg's multi_logloss: 1.08586 + 0.0191249\n",
      "[571]\tcv_agg's multi_logloss: 1.08588 + 0.0191182\n",
      "[572]\tcv_agg's multi_logloss: 1.08594 + 0.0190862\n[573]\tcv_agg's multi_logloss: 1.0859 + 0.0190557\n[574]\tcv_agg's multi_logloss: 1.08586 + 0.0191013\n[575]\tcv_agg's multi_logloss: 1.08585 + 0.0190931\n[576]\tcv_agg's multi_logloss: 1.08586 + 0.0191178\n[577]\tcv_agg's multi_logloss: 1.08589 + 0.0191658\n[578]\tcv_agg's multi_logloss: 1.08589 + 0.0191509\n[579]\tcv_agg's multi_logloss: 1.08587 + 0.0191469\n[580]\tcv_agg's multi_logloss: 1.08589 + 0.0191655\n",
      "[581]\tcv_agg's multi_logloss: 1.0859 + 0.0191525\n[582]\tcv_agg's multi_logloss: 1.08589 + 0.0191802\n[583]\tcv_agg's multi_logloss: 1.08588 + 0.0191965\n[584]\tcv_agg's multi_logloss: 1.08594 + 0.0192087\n",
      "[585]\tcv_agg's multi_logloss: 1.08594 + 0.0192149\n",
      "[586]\tcv_agg's multi_logloss: 1.08593 + 0.01924\n[587]\tcv_agg's multi_logloss: 1.08592 + 0.0192536\n[588]\tcv_agg's multi_logloss: 1.08597 + 0.0192884\n[589]\tcv_agg's multi_logloss: 1.08594 + 0.0192509\n[590]\tcv_agg's multi_logloss: 1.08595 + 0.0192525\n[591]\tcv_agg's multi_logloss: 1.08599 + 0.0192604\n[592]\tcv_agg's multi_logloss: 1.08599 + 0.0192843\n[593]\tcv_agg's multi_logloss: 1.08599 + 0.0192622\n",
      "[594]\tcv_agg's multi_logloss: 1.08598 + 0.0192931\n[595]\tcv_agg's multi_logloss: 1.086 + 0.0193337\n[596]\tcv_agg's multi_logloss: 1.08601 + 0.0193265\n[597]\tcv_agg's multi_logloss: 1.08599 + 0.0193245\n",
      "[598]\tcv_agg's multi_logloss: 1.08601 + 0.0193146\n",
      "[599]\tcv_agg's multi_logloss: 1.08599 + 0.0193096\n[600]\tcv_agg's multi_logloss: 1.08601 + 0.0193341\n[601]\tcv_agg's multi_logloss: 1.086 + 0.0193523\n[602]\tcv_agg's multi_logloss: 1.08599 + 0.0193363\n[603]\tcv_agg's multi_logloss: 1.08591 + 0.0193622\n[604]\tcv_agg's multi_logloss: 1.08593 + 0.0193902\n[605]\tcv_agg's multi_logloss: 1.08589 + 0.0193223\n[606]\tcv_agg's multi_logloss: 1.08593 + 0.0192824\n",
      "[607]\tcv_agg's multi_logloss: 1.08595 + 0.0192673\n[608]\tcv_agg's multi_logloss: 1.08595 + 0.0192672\n[609]\tcv_agg's multi_logloss: 1.08593 + 0.019295\n[610]\tcv_agg's multi_logloss: 1.08595 + 0.019266\n[611]\tcv_agg's multi_logloss: 1.08595 + 0.0193023\n",
      "[612]\tcv_agg's multi_logloss: 1.08597 + 0.0193185\n",
      "[613]\tcv_agg's multi_logloss: 1.08596 + 0.0193236\n[614]\tcv_agg's multi_logloss: 1.086 + 0.0193341\n[615]\tcv_agg's multi_logloss: 1.08599 + 0.0193398\n[616]\tcv_agg's multi_logloss: 1.08602 + 0.0193533\n[617]\tcv_agg's multi_logloss: 1.08605 + 0.0193705\n[618]\tcv_agg's multi_logloss: 1.08608 + 0.0193784\n[619]\tcv_agg's multi_logloss: 1.0861 + 0.0193509\n",
      "[620]\tcv_agg's multi_logloss: 1.08611 + 0.0193638\n[621]\tcv_agg's multi_logloss: 1.08613 + 0.0193534\n[622]\tcv_agg's multi_logloss: 1.0861 + 0.0193364\n[623]\tcv_agg's multi_logloss: 1.08611 + 0.0193411\n[624]\tcv_agg's multi_logloss: 1.08612 + 0.0193359\n[625]\tcv_agg's multi_logloss: 1.0861 + 0.0193874\n",
      "[626]\tcv_agg's multi_logloss: 1.0861 + 0.0194005\n",
      "[627]\tcv_agg's multi_logloss: 1.08609 + 0.0194186\n[628]\tcv_agg's multi_logloss: 1.08606 + 0.0194161\n[629]\tcv_agg's multi_logloss: 1.08606 + 0.0194313\n[630]\tcv_agg's multi_logloss: 1.08606 + 0.0194207\n[631]\tcv_agg's multi_logloss: 1.08606 + 0.0194156\n[632]\tcv_agg's multi_logloss: 1.08603 + 0.0194309\n[633]\tcv_agg's multi_logloss: 1.086 + 0.019432\n[634]\tcv_agg's multi_logloss: 1.086 + 0.0194372\n",
      "[635]\tcv_agg's multi_logloss: 1.08603 + 0.0194278\n[636]\tcv_agg's multi_logloss: 1.08598 + 0.0194238\n[637]\tcv_agg's multi_logloss: 1.08598 + 0.0194276\n[638]\tcv_agg's multi_logloss: 1.08595 + 0.0193975\n[639]\tcv_agg's multi_logloss: 1.08593 + 0.0193762\n",
      "[640]\tcv_agg's multi_logloss: 1.08588 + 0.0193893\n",
      "[641]\tcv_agg's multi_logloss: 1.08591 + 0.0193775\n[642]\tcv_agg's multi_logloss: 1.08594 + 0.0193872\n[643]\tcv_agg's multi_logloss: 1.08594 + 0.0193838\n[644]\tcv_agg's multi_logloss: 1.08594 + 0.0193624\n[645]\tcv_agg's multi_logloss: 1.08597 + 0.0193545\n[646]\tcv_agg's multi_logloss: 1.08595 + 0.0193285\n[647]\tcv_agg's multi_logloss: 1.08596 + 0.0193061\n[648]\tcv_agg's multi_logloss: 1.086 + 0.0192511\n",
      "[649]\tcv_agg's multi_logloss: 1.08602 + 0.019257\n[650]\tcv_agg's multi_logloss: 1.08605 + 0.019226\n[651]\tcv_agg's multi_logloss: 1.08609 + 0.0192533\n[652]\tcv_agg's multi_logloss: 1.08606 + 0.0192498\n[653]\tcv_agg's multi_logloss: 1.08613 + 0.0192691\n",
      "[654]\tcv_agg's multi_logloss: 1.08619 + 0.0192979\n",
      "[655]\tcv_agg's multi_logloss: 1.08619 + 0.0193346\n[656]\tcv_agg's multi_logloss: 1.08622 + 0.019322\n[657]\tcv_agg's multi_logloss: 1.0862 + 0.0193252\n[658]\tcv_agg's multi_logloss: 1.0862 + 0.0193305\n[659]\tcv_agg's multi_logloss: 1.08622 + 0.0193233\n[660]\tcv_agg's multi_logloss: 1.08623 + 0.0193461\n[661]\tcv_agg's multi_logloss: 1.08619 + 0.0193893\n[662]\tcv_agg's multi_logloss: 1.08622 + 0.0193616\n",
      "[663]\tcv_agg's multi_logloss: 1.08624 + 0.0194075\n[664]\tcv_agg's multi_logloss: 1.08627 + 0.0194002\n[665]\tcv_agg's multi_logloss: 1.08629 + 0.0194079\n[666]\tcv_agg's multi_logloss: 1.08629 + 0.0194206\n",
      "[667]\tcv_agg's multi_logloss: 1.08629 + 0.0194152\n",
      "[668]\tcv_agg's multi_logloss: 1.08631 + 0.0194093\n[669]\tcv_agg's multi_logloss: 1.08637 + 0.0194224\n[670]\tcv_agg's multi_logloss: 1.08637 + 0.0194133\n[671]\tcv_agg's multi_logloss: 1.08641 + 0.0194242\n[672]\tcv_agg's multi_logloss: 1.08642 + 0.019378\n[673]\tcv_agg's multi_logloss: 1.08641 + 0.0194043\n[674]\tcv_agg's multi_logloss: 1.08644 + 0.0193868\n[675]\tcv_agg's multi_logloss: 1.08648 + 0.019344\n[676]\tcv_agg's multi_logloss: 1.08652 + 0.0193688\n",
      "[677]\tcv_agg's multi_logloss: 1.08653 + 0.0193666\n[678]\tcv_agg's multi_logloss: 1.08659 + 0.0193693\n[679]\tcv_agg's multi_logloss: 1.08661 + 0.0194427\n[680]\tcv_agg's multi_logloss: 1.08665 + 0.0194482\n",
      "[681]\tcv_agg's multi_logloss: 1.08667 + 0.0194863\n",
      "[682]\tcv_agg's multi_logloss: 1.08664 + 0.0195047\n[683]\tcv_agg's multi_logloss: 1.08665 + 0.0195321\n[684]\tcv_agg's multi_logloss: 1.08663 + 0.0195787\n[685]\tcv_agg's multi_logloss: 1.0866 + 0.0195973\n[686]\tcv_agg's multi_logloss: 1.08663 + 0.0195682\n[687]\tcv_agg's multi_logloss: 1.0866 + 0.0195728\n[688]\tcv_agg's multi_logloss: 1.08657 + 0.0195453\n[689]\tcv_agg's multi_logloss: 1.08656 + 0.0195456\n[690]\tcv_agg's multi_logloss: 1.08655 + 0.0195139\n",
      "[691]\tcv_agg's multi_logloss: 1.08658 + 0.0195278\n[692]\tcv_agg's multi_logloss: 1.08659 + 0.0195455\n[693]\tcv_agg's multi_logloss: 1.08661 + 0.019558\n[694]\tcv_agg's multi_logloss: 1.08663 + 0.0195729\n",
      "[695]\tcv_agg's multi_logloss: 1.08664 + 0.0195808\n",
      "[696]\tcv_agg's multi_logloss: 1.08662 + 0.0196215\n[697]\tcv_agg's multi_logloss: 1.08662 + 0.0196331\n[698]\tcv_agg's multi_logloss: 1.08661 + 0.019639\n[699]\tcv_agg's multi_logloss: 1.08659 + 0.0196612\n[700]\tcv_agg's multi_logloss: 1.08665 + 0.0196436\n[701]\tcv_agg's multi_logloss: 1.08669 + 0.0196658\n[702]\tcv_agg's multi_logloss: 1.0867 + 0.0196746\n[703]\tcv_agg's multi_logloss: 1.08673 + 0.0196685\n",
      "[704]\tcv_agg's multi_logloss: 1.08678 + 0.0196738\n[705]\tcv_agg's multi_logloss: 1.08683 + 0.0196996\n[706]\tcv_agg's multi_logloss: 1.08687 + 0.0197103\n[707]\tcv_agg's multi_logloss: 1.08691 + 0.0197319\n[708]\tcv_agg's multi_logloss: 1.08692 + 0.0197394\n",
      "[709]\tcv_agg's multi_logloss: 1.087 + 0.0197801\n",
      "[710]\tcv_agg's multi_logloss: 1.08708 + 0.0197692\n[711]\tcv_agg's multi_logloss: 1.08706 + 0.0197746\n[712]\tcv_agg's multi_logloss: 1.08708 + 0.0197603\n[713]\tcv_agg's multi_logloss: 1.08707 + 0.019762\n[714]\tcv_agg's multi_logloss: 1.08704 + 0.0197686\n[715]\tcv_agg's multi_logloss: 1.08709 + 0.0198019\n[716]\tcv_agg's multi_logloss: 1.08708 + 0.0198307\n[717]\tcv_agg's multi_logloss: 1.0871 + 0.0198436\n",
      "[718]\tcv_agg's multi_logloss: 1.08713 + 0.0198033\n[719]\tcv_agg's multi_logloss: 1.08713 + 0.0198452\n[720]\tcv_agg's multi_logloss: 1.08715 + 0.0198877\n[721]\tcv_agg's multi_logloss: 1.08716 + 0.0199181\n",
      "[722]\tcv_agg's multi_logloss: 1.08723 + 0.0199249\n",
      "[723]\tcv_agg's multi_logloss: 1.08727 + 0.0198912\n[724]\tcv_agg's multi_logloss: 1.08732 + 0.0198886\n[725]\tcv_agg's multi_logloss: 1.08737 + 0.0199577\n[726]\tcv_agg's multi_logloss: 1.08734 + 0.0199549\n[727]\tcv_agg's multi_logloss: 1.08735 + 0.0199641\n[728]\tcv_agg's multi_logloss: 1.08735 + 0.0199258\n[729]\tcv_agg's multi_logloss: 1.0873 + 0.0199373\n[730]\tcv_agg's multi_logloss: 1.0873 + 0.0199162\n",
      "[731]\tcv_agg's multi_logloss: 1.08733 + 0.0199107\n[732]\tcv_agg's multi_logloss: 1.08735 + 0.0199422\n[733]\tcv_agg's multi_logloss: 1.08736 + 0.0199213\n[734]\tcv_agg's multi_logloss: 1.08738 + 0.0199165\n[735]\tcv_agg's multi_logloss: 1.0874 + 0.0199143\n",
      "[736]\tcv_agg's multi_logloss: 1.08743 + 0.0199145\n[737]\tcv_agg's multi_logloss: 1.08744 + 0.0199414\n[738]\tcv_agg's multi_logloss: 1.08747 + 0.0199393\n[739]\tcv_agg's multi_logloss: 1.0875 + 0.0199577\n[740]\tcv_agg's multi_logloss: 1.08751 + 0.0198948\n[741]\tcv_agg's multi_logloss: 1.08754 + 0.0198971\n[742]\tcv_agg's multi_logloss: 1.08756 + 0.0199232\n[743]\tcv_agg's multi_logloss: 1.0876 + 0.0199137\n",
      "[744]\tcv_agg's multi_logloss: 1.08762 + 0.0199399\n[745]\tcv_agg's multi_logloss: 1.08769 + 0.0199418\n[746]\tcv_agg's multi_logloss: 1.0877 + 0.0199433\n[747]\tcv_agg's multi_logloss: 1.08771 + 0.0199388\n[748]\tcv_agg's multi_logloss: 1.08768 + 0.0199305\n",
      "[749]\tcv_agg's multi_logloss: 1.08767 + 0.0199423\n[750]\tcv_agg's multi_logloss: 1.08764 + 0.0199773\n[751]\tcv_agg's multi_logloss: 1.08765 + 0.0199851\n[752]\tcv_agg's multi_logloss: 1.08764 + 0.0199923\n[753]\tcv_agg's multi_logloss: 1.0876 + 0.0199906\n[754]\tcv_agg's multi_logloss: 1.08761 + 0.0199727\n[755]\tcv_agg's multi_logloss: 1.08762 + 0.0199771\n[756]\tcv_agg's multi_logloss: 1.08762 + 0.0199814\n[757]\tcv_agg's multi_logloss: 1.08766 + 0.0200181\n",
      "[758]\tcv_agg's multi_logloss: 1.08764 + 0.0200219\n[759]\tcv_agg's multi_logloss: 1.08762 + 0.0200132\n[760]\tcv_agg's multi_logloss: 1.08761 + 0.020018\n[761]\tcv_agg's multi_logloss: 1.08764 + 0.0200084\n[762]\tcv_agg's multi_logloss: 1.08762 + 0.020029\n",
      "[763]\tcv_agg's multi_logloss: 1.08766 + 0.0200418\n[764]\tcv_agg's multi_logloss: 1.08765 + 0.0200482\n[765]\tcv_agg's multi_logloss: 1.08764 + 0.0200776\n[766]\tcv_agg's multi_logloss: 1.08764 + 0.0201077\n[767]\tcv_agg's multi_logloss: 1.08769 + 0.0201237\n[768]\tcv_agg's multi_logloss: 1.08774 + 0.020104\n[769]\tcv_agg's multi_logloss: 1.08776 + 0.0200819\n[770]\tcv_agg's multi_logloss: 1.08782 + 0.0200996\n",
      "[771]\tcv_agg's multi_logloss: 1.08782 + 0.0201616\n[772]\tcv_agg's multi_logloss: 1.08784 + 0.0202184\n[773]\tcv_agg's multi_logloss: 1.08787 + 0.0202664\n[774]\tcv_agg's multi_logloss: 1.08793 + 0.0202603\n[775]\tcv_agg's multi_logloss: 1.08798 + 0.020319\n",
      "{'multi_logloss-mean': [1.2810727664194796, 1.2787757601393852, 1.2765195957897562, 1.2743236285810169, 1.2723062009201036, 1.27008787769976, 1.2678037572576875, 1.265694839036707, 1.2635163477207345, 1.2614590217497565, 1.2593858339739286, 1.2575576797429737, 1.2555029019722, 1.2534994934589285, 1.2515374380193314, 1.2498133547932935, 1.2479482928346706, 1.246062336451244, 1.2444648288087052, 1.2426842404629865, 1.2410698894972905, 1.2396457777058754, 1.238008964634974, 1.2363664168865756, 1.2346340289614155, 1.2329459792420974, 1.231241041732693, 1.2295153868719821, 1.227855042283054, 1.2261883957922417, 1.2246194670587833, 1.2230928579505185, 1.2215231491214038, 1.2200216251910418, 1.218595690416286, 1.2171750897018714, 1.2157111695170082, 1.2142672704892767, 1.2128284198213646, 1.211660043798971, 1.2104396928159495, 1.2091326768408392, 1.2077410462608316, 1.2064088729849174, 1.205092756175804, 1.203734364549129, 1.2024149721368511, 1.2010651039894418, 1.1998267396494418, 1.198558222450989, 1.197285941355535, 1.1960842514620134, 1.1949760369798945, 1.193749045187567, 1.192708276523043, 1.1916913246163898, 1.1906509716715743, 1.1893757215009795, 1.1882035191961353, 1.1871955562854608, 1.1861236866907987, 1.1851906558353686, 1.184231362077415, 1.1831404041580043, 1.1820684862227968, 1.1810454394995376, 1.1800359712017436, 1.1790781951190743, 1.1781295871879587, 1.1771544912965226, 1.1762475558111656, 1.1753957591104705, 1.1746090397763924, 1.1737347000908447, 1.1727690920347111, 1.1718457642469786, 1.1708875218004167, 1.1699034653814682, 1.168971956554785, 1.1679992264888672, 1.1671702266976998, 1.1662324438176552, 1.1653457890306311, 1.1645811783670765, 1.163725458935993, 1.1628847107720552, 1.1620551474363403, 1.1613096855558627, 1.1605278078219776, 1.1597340480297669, 1.1589920893582, 1.1582640412208263, 1.1574301786724686, 1.1567352109196452, 1.155982203378252, 1.1552760206256645, 1.1545353188376715, 1.1538302601478168, 1.153046837388142, 1.1524203172859224, 1.1516829542876743, 1.1510060422175397, 1.1503617442839418, 1.1497616248557376, 1.1490938022631656, 1.14842575669149, 1.1477786903893379, 1.147192194061657, 1.1465730433663737, 1.145984640245835, 1.1454590508856246, 1.1448755755108861, 1.144281819462945, 1.1437177350570964, 1.1431608117775753, 1.14253700750904, 1.1420371784651917, 1.141517755394945, 1.140990820117087, 1.1403888586104247, 1.1398599929503945, 1.1393278957610982, 1.1389086329652296, 1.138434849993401, 1.1378861758898142, 1.1373300673033397, 1.136816879641387, 1.1362997614074555, 1.1358664960360394, 1.1354025318228347, 1.1349071742508743, 1.1344997792873197, 1.134080752482886, 1.1335849778303473, 1.1330927350515956, 1.1326411621076564, 1.1321052131685059, 1.1316461866928136, 1.1311546663917418, 1.1307018427611337, 1.1302186672179109, 1.1297927655725115, 1.1293604489938187, 1.128902493365625, 1.128419159181359, 1.1280768962238383, 1.1276369516033324, 1.1272273641778165, 1.1267929103646686, 1.1263940052618895, 1.1259561934303441, 1.1255757497759191, 1.1252142748784562, 1.1248936454345793, 1.1245153097608351, 1.1241078452502737, 1.1237531473482567, 1.1234660593410903, 1.123124961901604, 1.1227631165241978, 1.1224657654989436, 1.122164515459706, 1.1217953879494469, 1.121459726553622, 1.1211423871514807, 1.1207599711093101, 1.1203054865456992, 1.119956622936372, 1.1196227007425597, 1.1192651815687202, 1.1190001398989995, 1.1187257433613775, 1.11841958537827, 1.11817416080599, 1.1178997657406198, 1.117570614535272, 1.1172052533243437, 1.116847313840248, 1.1165861512748094, 1.1163473439328542, 1.116033297396665, 1.1157223053019503, 1.1154177187899683, 1.1151063904391212, 1.114826902832966, 1.114517278677917, 1.114248953904059, 1.113965417133604, 1.1137126442250478, 1.1134895936718545, 1.1132037536343855, 1.112990655864419, 1.1127252297580177, 1.112477109235575, 1.1122327833122454, 1.1119987542946366, 1.1117317342386113, 1.1114889986670575, 1.1111996312622214, 1.1109207103013314, 1.1107211312616598, 1.110514182433466, 1.1102789918851446, 1.1100274607017464, 1.1097973213932941, 1.1095250974010682, 1.1093050657057204, 1.1090836840621994, 1.1088932237250044, 1.108685365784003, 1.1084184877319507, 1.1081885521777965, 1.1079474851017763, 1.107715821156476, 1.1074795398565915, 1.1072698088830317, 1.1070606116578914, 1.1068488043040712, 1.106681296639131, 1.1064885820274308, 1.106286077438642, 1.1061073983664866, 1.1058825606763072, 1.1056506755655362, 1.1054398573565867, 1.1052088421177984, 1.105074920473911, 1.1049062185715415, 1.1047238561146342, 1.1045111758587318, 1.1043108337677299, 1.1041597183305523, 1.1039664653571424, 1.1038055408904415, 1.1036423141151503, 1.1034747548985204, 1.1032312980342116, 1.1030389590513066, 1.1028510920340664, 1.1026514566504875, 1.102511786769596, 1.1023464124663351, 1.102175341956277, 1.1019869970714449, 1.1018468941650277, 1.1017065447730685, 1.1015756555914291, 1.1014620631729137, 1.1013107295775435, 1.1011561561688257, 1.101016674750462, 1.1009008030462997, 1.1007487895825516, 1.1006411818776656, 1.100547696888931, 1.1003841744223353, 1.1001639188846846, 1.099999239929259, 1.0998491386866722, 1.0996420996266147, 1.0995447176666189, 1.0994058407951535, 1.0992783579367202, 1.099169124853046, 1.0990410521212604, 1.0989604807662667, 1.0987753847752273, 1.098699957888183, 1.0985780536609517, 1.0984303347538167, 1.098321038207049, 1.098195832800839, 1.098092395949087, 1.0980007899721642, 1.0978944956633192, 1.0978204240154668, 1.0976473247619292, 1.0974509907280114, 1.0972787312218668, 1.0971506684734462, 1.0970177353216308, 1.0968669480869837, 1.0967661950098972, 1.0966386643405315, 1.0965123726449306, 1.0964307193732705, 1.096339595659251, 1.0962227417589363, 1.0960569992313718, 1.0959279670896893, 1.0958400689992027, 1.0957797545641108, 1.0956983838267287, 1.0956470335783877, 1.0955769917413136, 1.095488122115841, 1.0953838338257051, 1.095307554364389, 1.0951928403841176, 1.0950732711499045, 1.0950000363288264, 1.094903874693419, 1.094830544090516, 1.0947149361857107, 1.0946389908164353, 1.094540393480732, 1.0944415239351302, 1.0943265634496104, 1.0942184564959978, 1.0942009936571815, 1.0941130906549037, 1.0940327612652523, 1.0940081870243765, 1.0939238282277208, 1.093796125824388, 1.0937431184560062, 1.093658541003748, 1.0935561540375047, 1.0934040097638926, 1.0933487232743846, 1.0932420429910032, 1.0932120981869713, 1.0931518634600874, 1.0930198094073003, 1.0929685135393907, 1.092877289160716, 1.0927744742752212, 1.0926885072714332, 1.092573718083592, 1.0924482064091052, 1.0923799142362043, 1.0923332346265853, 1.092306010477893, 1.0922539398246056, 1.0922114932801876, 1.092193490349585, 1.0921886250458446, 1.0921580992322342, 1.092119837029546, 1.0920435306547427, 1.0919379521530685, 1.0918301909760975, 1.091745083069073, 1.091646502778858, 1.0915420366149862, 1.0914495692658424, 1.0913858261709857, 1.09133736740533, 1.0912824775736296, 1.0912237928605868, 1.0911369426882023, 1.0911277855266845, 1.0910592013461156, 1.0910095597785947, 1.090958417675769, 1.0909332752077987, 1.0908823537870007, 1.0907796948626065, 1.090693183730567, 1.0906501248161522, 1.0905841662605915, 1.0904739515906474, 1.0904732760531948, 1.090425508685882, 1.090375735715455, 1.0903415752368295, 1.0902916182597775, 1.0902425760202499, 1.0902162051555577, 1.0901857806199797, 1.0901528073773725, 1.090082946504066, 1.0900204073517739, 1.09001004340075, 1.0899424804892361, 1.0898395711795008, 1.0897957774232803, 1.0897457403193327, 1.0896687093881288, 1.0896142446388353, 1.0895211937685854, 1.089476716795407, 1.089487883057604, 1.0894170971354016, 1.0893618067568127, 1.0893240502657935, 1.0892906505587432, 1.0892902629773413, 1.089274699872473, 1.0892566076766201, 1.0892252375616804, 1.0891898946754015, 1.0891439118607988, 1.0891247790430083, 1.089074095813082, 1.0890358677107066, 1.0889890813994465, 1.0889589973953093, 1.0889499366113014, 1.0889353121715377, 1.0888695631575218, 1.0887132075766774, 1.088672801825758, 1.0886506245524057, 1.0885897187868845, 1.0885097687020018, 1.0884857739494929, 1.088493030081322, 1.0884878794441282, 1.0884649894955045, 1.0884610593774728, 1.0884291433024536, 1.0883679384474534, 1.0883297916695531, 1.0883014894007426, 1.0882240701771242, 1.0881703417988131, 1.0881464378618138, 1.0880698732481022, 1.088002749445826, 1.087932277464822, 1.0879100320210449, 1.0878930865908125, 1.0878286263801706, 1.0878129640810854, 1.0878276967061435, 1.087809749524791, 1.0877940909876904, 1.0877718344739695, 1.087737628838246, 1.0877149313783812, 1.0876924584390841, 1.0876554350475067, 1.0876630573885715, 1.087665064055321, 1.0876268466856507, 1.0876320346980817, 1.0876167695942152, 1.0876030016216842, 1.087580046807603, 1.0875481141766055, 1.0875169080922997, 1.0875039792668033, 1.087495189409618, 1.0874809728041999, 1.0874689540052083, 1.087432826795073, 1.0874375541499426, 1.087375542153439, 1.087301563135811, 1.0873285846010312, 1.0873087452616885, 1.0872770052746827, 1.0872493609775589, 1.0871880496512762, 1.0871564409952614, 1.0871206153233444, 1.0870823170608694, 1.0870713517514141, 1.0870077937431488, 1.0870301933889348, 1.0869775569098297, 1.086993530430535, 1.0869840907643837, 1.0869699438970657, 1.086958945772638, 1.0869347092545074, 1.0869265085454438, 1.0869161672589123, 1.0869241389694664, 1.0869401730796888, 1.086927944198161, 1.08692019898499, 1.0869360640994472, 1.0869542903459333, 1.0869351130023028, 1.0869136095684608, 1.0868618151842215, 1.0869326502077077, 1.0868610735754607, 1.0868215828434846, 1.08682499233363, 1.0867836593990359, 1.0867450560553102, 1.0867364706864655, 1.0867614531162642, 1.086767945455926, 1.08676259287041, 1.086739143904587, 1.0867088403523306, 1.0866296507987858, 1.0865945361175728, 1.086601085952655, 1.086547459592651, 1.086558366979776, 1.0865509764840362, 1.0865341380038305, 1.0865436437943097, 1.0865736820865162, 1.0865394816477305, 1.0864848210879292, 1.0864713918903743, 1.086480334484723, 1.0865038475098192, 1.0864515591889687, 1.0864478158143782, 1.086405514846493, 1.0863430400047474, 1.0863443275039362, 1.0863146313001875, 1.0862826622696846, 1.0862437743577322, 1.0862355116490212, 1.0862351879718841, 1.0862613659910145, 1.0862258653132508, 1.0862082067688548, 1.086189960529079, 1.0861572047111998, 1.0861432739396903, 1.0861517671737988, 1.0861496620472662, 1.0861082070511001, 1.0861343780651218, 1.0861141020272913, 1.086138881625845, 1.086192211039356, 1.0862204679506833, 1.0862224102873748, 1.0862427459863215, 1.086235897214483, 1.0862136712758281, 1.0862214221277502, 1.0862306792853909, 1.086181176035312, 1.08617820529022, 1.086160953250252, 1.086176385445814, 1.0861920808697545, 1.086214984208669, 1.0862171218501069, 1.086215476743245, 1.0861994594014637, 1.0862358222138166, 1.0862302502107366, 1.0861400999575885, 1.0860721674510536, 1.086063316149597, 1.086044252203359, 1.0860279934792585, 1.0860133616219496, 1.086023953604356, 1.0860162573234724, 1.0860304736275972, 1.086065900369741, 1.0860710106293499, 1.086025971722691, 1.0859894236995236, 1.0859443205710761, 1.0859268756811438, 1.0859392901907199, 1.085916996183137, 1.085943631812826, 1.0859034354156, 1.0859057276651, 1.0858914788907434, 1.0858893152784828, 1.0858916388691402, 1.0858700537881956, 1.0858591972982117, 1.0858756758609007, 1.0859414541696057, 1.0858959869602196, 1.0858621585227612, 1.0858521813791433], 'multi_logloss-stdv': [0.0010494645788719488, 0.0011632009554482378, 0.0013202333764398176, 0.0013995963496860895, 0.0014058347918021975, 0.0015134830108962823, 0.0015262366748558715, 0.0016226617299567956, 0.001710569368469034, 0.0018095467198358832, 0.0018899261294532572, 0.002030810784717077, 0.0021564246997003095, 0.0022560193520650834, 0.0024075807482026304, 0.0024888586280236327, 0.0025472924926943554, 0.002625917081176714, 0.002600364408797905, 0.0026511489044758673, 0.002690772001864611, 0.0027342336364439023, 0.002753526289708929, 0.002722921827090416, 0.0028190884232458737, 0.0029067232041775685, 0.0029896593151841635, 0.003046515382354489, 0.003075218078819344, 0.003171284905536906, 0.0032092994506861022, 0.0032512546186651537, 0.0032501559943832734, 0.003280908860968138, 0.0033055039746368886, 0.0033800961972547065, 0.0034469558455145735, 0.003495069958125925, 0.0035366920090419973, 0.0036609865959411508, 0.0037025391283577636, 0.0037666187159122425, 0.0037845868930465936, 0.0038842246625391853, 0.003947175930631871, 0.003954990228910539, 0.0039970637141282924, 0.004004752341706858, 0.004019857412383226, 0.004075708816204507, 0.004096953788367346, 0.0041324773488366755, 0.004177950960814645, 0.0042553703572594075, 0.004286875955728784, 0.004361541345988406, 0.004431125103507624, 0.004451996046196319, 0.004562802865057191, 0.004639052784782136, 0.004657162697018115, 0.0046735672954212135, 0.0047336557400726635, 0.004818410119476263, 0.004877126690795461, 0.004884303280571109, 0.0049421892286536295, 0.004980019474785243, 0.004939883100865321, 0.004939461844241188, 0.004972969143989956, 0.004995371494982493, 0.005063184319684294, 0.005115476413972313, 0.005151481304997453, 0.0051852101672591805, 0.005224323994546838, 0.00521646709211853, 0.005271166118266916, 0.00529680574876903, 0.005310114495377223, 0.005261486377826488, 0.0053020491632037176, 0.005294213133811483, 0.0053503395754273195, 0.005459628335207385, 0.005490736001636048, 0.005508140965153816, 0.0055460845656864705, 0.005562066662739098, 0.005668700818915689, 0.005732840604070587, 0.0057631444899694535, 0.005786604916963384, 0.005849466905669076, 0.0059038202062338015, 0.005936486902990852, 0.006001811728008216, 0.006025735680932759, 0.006052153676246563, 0.006044838359061352, 0.006059302963408739, 0.006188126084021411, 0.00624406885347956, 0.006336382859894692, 0.006444888637529487, 0.00653184005980705, 0.0065631540458146, 0.006631528638835453, 0.006692413323371355, 0.006734185708803104, 0.006819138734527659, 0.006903177604200938, 0.006950980021895532, 0.0069760115273334545, 0.007036374432093373, 0.0071117782808984694, 0.007165770675759594, 0.00727827319243767, 0.007363942276841661, 0.007448949630639037, 0.007535248060746775, 0.007579000050986401, 0.007679229165642855, 0.007686704425146368, 0.0077497092708627875, 0.007821534015485963, 0.00785529539527787, 0.007970494142055131, 0.008000510687407694, 0.008043481409056698, 0.008116280043201338, 0.008163249434398064, 0.008238716164144894, 0.008276323928494903, 0.00831543713810045, 0.008337420077190103, 0.008393585517344695, 0.008461713290512565, 0.00848625280825049, 0.008541028439641309, 0.008579808156135769, 0.00865665576683383, 0.008721189190057587, 0.008800060993132634, 0.0088209955686155, 0.008877925181137135, 0.008909300257297054, 0.00894095027013066, 0.008981126080051277, 0.009009633779415143, 0.009086994076473369, 0.009160560245210713, 0.009245419660227565, 0.009313785844214854, 0.00935812793782526, 0.00941930969983113, 0.009427096816093177, 0.00955229945898369, 0.009618132190806547, 0.00965306931899301, 0.009733466429079117, 0.009773142564309096, 0.009802048100315975, 0.009827392571872975, 0.00979445812753856, 0.009817302647695907, 0.009841042490241923, 0.009800583758171963, 0.009799993491681553, 0.009889744923783096, 0.009941140978865448, 0.009967477698950379, 0.010028073132301463, 0.010020462246657423, 0.010033927646463967, 0.01007544655721653, 0.01020227928380597, 0.010226175343822337, 0.01026432534087987, 0.010331530586617396, 0.01032541828941375, 0.010407379069457079, 0.010446482982755462, 0.01050952394587206, 0.010561844025943864, 0.010630473812607627, 0.010700696081412777, 0.010709789417834662, 0.010779022942475482, 0.01081676261588464, 0.010834225161958387, 0.010807585906965431, 0.010826262930484802, 0.010868166934984247, 0.010890762677615249, 0.010874449485344391, 0.010896358357531657, 0.010925039198462775, 0.010922623194474103, 0.010943514089307636, 0.010958134891399489, 0.010998375297299084, 0.011039324113586504, 0.01107210887261798, 0.01115686680309033, 0.011158149887513725, 0.011162994918936959, 0.011204489225519833, 0.011216155965176692, 0.011252357651198738, 0.011262535264453777, 0.011348691802603653, 0.011380289545200682, 0.011457644392221805, 0.011477477992138035, 0.011516483027393734, 0.011566286636615337, 0.011602296028866184, 0.011693435354422868, 0.01173210828000763, 0.011783868837046704, 0.011821707421145864, 0.011813402359958616, 0.011841369744388552, 0.011856537335021202, 0.011890896976055944, 0.011908015326336615, 0.011930976068112142, 0.011970156062363792, 0.012008383426505585, 0.012072740296272722, 0.012093339698478974, 0.012133989845872543, 0.012223032550906527, 0.012233283466882896, 0.01226147291023862, 0.012271018259025624, 0.012300915086818652, 0.012343118336619777, 0.01237129321359083, 0.012399693844109615, 0.012456939777712677, 0.012484993602376487, 0.01255848637554429, 0.012637078608166976, 0.012663669786149285, 0.012701111123941023, 0.012737026852476213, 0.012752703935054528, 0.012743112335671323, 0.01276019069171991, 0.012755457804857259, 0.012768357488794957, 0.012777867712475938, 0.012825559204567096, 0.012878173783291503, 0.012893703717069783, 0.01294554877083637, 0.013007176890430225, 0.01301774362961136, 0.013073346317830466, 0.013099730651131888, 0.013177042493039215, 0.013205062411480964, 0.01327172324081757, 0.01332451702249857, 0.013332897750220936, 0.013324798759953566, 0.01329596297741825, 0.013317880840477433, 0.013354934666236174, 0.013390849118727318, 0.013410523408419755, 0.013430631715509924, 0.013424664813827885, 0.013451935511268201, 0.013521943089782835, 0.013539378996321258, 0.013626334164077599, 0.013658760264820305, 0.01372331866635235, 0.01374517060359711, 0.01379016900605926, 0.013836426771746109, 0.013917699486087199, 0.013914229020841561, 0.013964419812944646, 0.014002253181890236, 0.014039169385924229, 0.014099375378246628, 0.0141522250818115, 0.014216015668229259, 0.01423888158275075, 0.01428804043287383, 0.014284318112855564, 0.014300354349348612, 0.01430284178871157, 0.014318834834901394, 0.014353616976231415, 0.014331570878381623, 0.014315400251580297, 0.014310480253936471, 0.01429295481113088, 0.014290465216084855, 0.014319277792028011, 0.014375331816061473, 0.0143632400310432, 0.014391644931281646, 0.014433226993662297, 0.01454963881733487, 0.014563253098189035, 0.014576776964976808, 0.014570250396316355, 0.014596138470102974, 0.014624827829280072, 0.014662350298440084, 0.014710862507764048, 0.014736866692230758, 0.014796844856967261, 0.014860663975204372, 0.014894141576689016, 0.014953941462302016, 0.01504731879442864, 0.01509970585697672, 0.015166103715462734, 0.015220679784666714, 0.015243392867839059, 0.015242589234329773, 0.015281176678740242, 0.015317881531125926, 0.015422818198470401, 0.015459975394752405, 0.01549820621330099, 0.015548744466579013, 0.01562030209201424, 0.01567828757910161, 0.015737932885987283, 0.015751022964292493, 0.015763448242863243, 0.015814474703456132, 0.01582643059433872, 0.015857161689521063, 0.01585902653833767, 0.015881308723415134, 0.015962711369831184, 0.016028658592025367, 0.016073179943838365, 0.016127168729417954, 0.016229794723758583, 0.016244168346968922, 0.016245435303722147, 0.01626056129562578, 0.01620945556838537, 0.016200677043290885, 0.016183768004324126, 0.016200574196733136, 0.01622376526823554, 0.01624552727463249, 0.016246474880978464, 0.016259165569235217, 0.01619621188864756, 0.01620063913371356, 0.016148756210833018, 0.01616911096767369, 0.016209707403820293, 0.016278375641137287, 0.01633142996004375, 0.016392889829283865, 0.016447176178255297, 0.01647384848407611, 0.016502315744934114, 0.01644185299976495, 0.016438887796871846, 0.01645691485376889, 0.01646668253774533, 0.016547591043194792, 0.01658880655027685, 0.01660541113323708, 0.01659085490376869, 0.016616734150234784, 0.016615709364329257, 0.016638737964454964, 0.016638447173320022, 0.016647837238694545, 0.01667335400761115, 0.01667017927682588, 0.016669026327972382, 0.016682400384109883, 0.01669577320929367, 0.016721503661954698, 0.016763989628687817, 0.01675405446501499, 0.016775883027148, 0.016803472960584365, 0.01679193962093152, 0.01680759685432181, 0.016801888427689222, 0.016814316513984448, 0.016772858175100675, 0.01681258033580645, 0.016878886240043287, 0.01691744376861673, 0.016980649039978268, 0.017018498062383314, 0.017067600477368702, 0.01708211018512079, 0.017119767007529114, 0.017160191845280146, 0.0172096168747252, 0.017202126573840067, 0.01719921177527637, 0.017239615482267906, 0.01723904794794805, 0.017265970246390407, 0.01726031539547691, 0.01723092245540907, 0.017199941846930716, 0.017224186944286082, 0.017221193884013546, 0.01723772796520478, 0.017215575928545945, 0.01720926754649406, 0.01722806008585611, 0.017236820220762828, 0.017236093257172676, 0.01728002674524005, 0.017283953040106444, 0.01733577075962335, 0.017331386763626656, 0.01731437838469977, 0.017308429942301966, 0.01731412170561845, 0.017258552558005864, 0.017243075026597766, 0.01727316176897117, 0.017289731356269464, 0.017281440240020814, 0.017323921775668744, 0.017362031377363626, 0.017366547975193755, 0.017391018503355806, 0.017427111107529158, 0.01750445992451002, 0.017530824169365904, 0.01756364545613641, 0.01763449380150502, 0.01767023032623253, 0.017676665600617272, 0.017719418382537544, 0.017740421317862565, 0.017750595041990825, 0.017786089618087395, 0.0178069816601146, 0.017815592009679377, 0.017822367908320674, 0.017825146646002012, 0.017839222144884037, 0.017821706001212922, 0.01782211247155177, 0.01779611588275152, 0.017743963503562433, 0.017739214884826274, 0.01772077580788983, 0.017714977995533177, 0.017708124386495848, 0.017709752049073928, 0.017713215380640333, 0.01770534820029853, 0.017703113803077895, 0.017737029148270186, 0.01771939337737517, 0.017704044592005155, 0.017739869347725066, 0.0177522662878296, 0.017770157455664626, 0.017780528579945977, 0.01779002715085276, 0.01780451092838446, 0.017840475703134177, 0.01782300692843252, 0.01784961290323552, 0.01787465115746407, 0.017860080295274243, 0.01785950738206828, 0.01787875794682875, 0.017861793816364328, 0.017875532947088952, 0.017841587373916244, 0.0178367659387479, 0.017853034157404916, 0.017922662228946132, 0.017973461823107256, 0.018044878202866165, 0.018070635930087838, 0.01809290982984299, 0.018105277462643468, 0.01815888075824286, 0.01817288900556139, 0.01819795540085806, 0.018213776991263413, 0.01820113314572444, 0.018227200839115724, 0.018251526275987612, 0.01822978334749954, 0.018221384809360495, 0.018198646263963614, 0.01821233882163581, 0.018199137629005338, 0.018230316837646615, 0.018290548371640934, 0.018305461915087303, 0.018342562552011606, 0.018334199349513008, 0.018352729516529616, 0.018385348396027974, 0.0184194836752526, 0.01844341398134115, 0.018450439698402248, 0.018494910627396433, 0.01847703719313853, 0.018532958340241625, 0.018554368954839494, 0.018532242689436776, 0.018562255010327565, 0.018573569868434035, 0.01857218627470388, 0.01857512188670621, 0.01857822038967911, 0.018601252927548394, 0.018608830127903465, 0.0186331452580475, 0.01868255965861788, 0.01871314526054785, 0.018753573793131115, 0.01875372785800078, 0.018772878973177403, 0.01878989806793658, 0.01881671257836317, 0.018853323124254643, 0.018841705931138007, 0.018868049269489793, 0.01888307656662289, 0.018881878656035477, 0.01890446145160566, 0.018918351816510297, 0.01898705491192111, 0.019029182575929823, 0.01906280443585672, 0.019097299640852106, 0.019124795164633845, 0.019139427454389315, 0.01910045152363758, 0.01909956287932477, 0.019075626108953785, 0.019055645984844605, 0.01909352088558619, 0.019088941028108614, 0.01909261217829352, 0.019088518740036454, 0.019102717825850383, 0.01908635868150673, 0.01908887164206185, 0.01908928894958556, 0.019075216671738702, 0.019085792843618336, 0.01908030041251821, 0.019084516765386635, 0.01912603951756603, 0.019124901304927385, 0.01911821413626295, 0.019086247258230188, 0.01905566559083606, 0.019101320431778295, 0.019093127073335218]}\n交叉验证中最优的multi_logloss-mean为 1.08585，对应的标准差为0.01909.\n模型最优的迭代次数为575.\n",
      "模型在测试集上的效果是0.62766。\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/wjunneng/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\nNew categorical_feature is ['Parameter10', 'Parameter5', 'Parameter6', 'Parameter7', 'Parameter8', 'Parameter9']\n  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model_cv_wight = run_cv(X_train, X_valid, sample_weight=preds_adv[:len(X_train)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "pycharm-e50da876",
   "language": "python",
   "display_name": "PyCharm (ForecastScore)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}