{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a59747a47ae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         clf.fit(train.iloc[trn_idx], target.iloc[trn_idx], eval_set=[(train.iloc[val_idx], target.iloc[val_idx])],\n\u001b[0;32m--> 137\u001b[0;31m                 verbose=500, early_stopping_rounds=200)  # , early_stopping_rounds=100\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0moof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# oof += clf.predict_proba(train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    742\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Aug 24 22:36:31 2019\n",
    "\n",
    "@author: 31037\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics, ensemble\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, KFold, StratifiedKFold\n",
    "# from sklearn import neural_network\n",
    "from sklearn.decomposition import PCA, FactorAnalysis, TruncatedSVD\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "project_path = '/home/wjunneng/Ubuntu/2019-CCF-Prediction-Of-The-Quality-Compliance-Rate-Of-Workpieces-In-Discrete-Manufacturing-Processes'\n",
    "\n",
    "test = pd.read_csv(project_path + '/data/original/first_round_testing_data.csv')\n",
    "train = pd.read_csv(project_path + '/data/original/first_round_training_data.csv')\n",
    "# train['Group'] = test['Group']\n",
    "sub_group = pd.DataFrame(test['Group'])\n",
    "subsample = pd.read_csv(project_path + '/data/original/submit_example.csv')\n",
    "\n",
    "features = ['Parameter1', 'Parameter2', 'Parameter3', 'Parameter4', 'Parameter5',\n",
    "            'Parameter6', 'Parameter7', 'Parameter8', 'Parameter9', 'Parameter10']\n",
    "target = train['Quality_label']\n",
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "lbl.fit(target)\n",
    "target = pd.Series(lbl.transform(target))\n",
    "\n",
    "data = pd.concat([train[features], test[features]], ignore_index=True)\n",
    "# features.remove('Group')\n",
    "\n",
    "n_unique = [data[col].nunique() for col in features]\n",
    "n_unique = pd.DataFrame(n_unique, index=features, columns=['nunique'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=n_unique.index, y=n_unique['nunique'])\n",
    "plt.show()\n",
    "\n",
    "category_cols = ['Parameter' + str(i) for i in range(5, 11)]\n",
    "num_cols = ['Parameter' + str(i) for i in range(1, 5)]\n",
    "for c_col in category_cols:\n",
    "    # lbl = preprocessing.LabelEncoder()\n",
    "    # data[c_col] = lbl.fit_transform(data[c_col])\n",
    "    data[c_col + '_cnt'] = data[c_col].map(data[c_col].value_counts())\n",
    "    for n_col in num_cols:\n",
    "        if n_col + '_log' not in data.columns.values:\n",
    "            data[n_col + '_log'] = np.log(data[n_col])\n",
    "        data[n_col + '_groupby_' + c_col + '_mean_ratio'] = data[n_col] / (\n",
    "            data[c_col].map(data[n_col].groupby(data[c_col]).mean()))\n",
    "\n",
    "\n",
    "def _std_bins(x, s, m):\n",
    "    if x > m + 3 * s or x < m - 3 * s:\n",
    "        return 3\n",
    "    elif x > m + 2 * s or x < m - 2 * s:\n",
    "        return 2\n",
    "    elif x > m + s or x < m - s:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "bin_cols = [col + str('_log') for col in num_cols]\n",
    "for col in bin_cols:\n",
    "    std = data[col].std()\n",
    "    mean = data[col].mean()\n",
    "    data[col + '_std_bins'] = data[col].apply(lambda x: _std_bins(x, std, mean))\n",
    "    data[col + '_std_ratio'] = data[col] / data[col].std()\n",
    "\n",
    "data['std_num_cols'] = data[num_cols].std(axis=1)\n",
    "data['mean_num_cols'] = data[num_cols].mean(axis=1)\n",
    "\n",
    "'''\n",
    "n_com = 2\n",
    "tsvd = TruncatedSVD(n_components=n_com,random_state=12)\n",
    "for i in range(n_com):\n",
    "    data['tsvd'+str(i)]=tsvd.fit_transform(data[features])[:,i]\n",
    "'''\n",
    "\n",
    "# Parameter5, Parameter6, Parameter7, Parameter8, Parameter9, Parameter10是类别变量\n",
    "# data.drop(['Group'],axis=1,inplace=True)\n",
    "\n",
    "train = data.iloc[0:train.shape[0], ]\n",
    "# features = train.columns.values\n",
    "# ros = RandomOverSampler(random_state=128)\n",
    "# train,target = ros.fit_resample(train,target)\n",
    "# train = pd.DataFrame(train,columns=features)\n",
    "# target = pd.Series(target,name='target')\n",
    "\n",
    "test = data.iloc[train.shape[0]:, ]\n",
    "del data\n",
    "\n",
    "# folds = KFold(n_splits=5,shuffle=True,random_state=128)\n",
    "folds = StratifiedKFold(n_splits=5, random_state=12)\n",
    "prediction = np.zeros([test.shape[0], 4])\n",
    "oof = np.zeros([target.shape[0], 4])\n",
    "\n",
    "feature_importance = pd.DataFrame(train.columns.values, columns=['features'])\n",
    "feature_importance['importance'] = np.zeros(feature_importance.shape[0])\n",
    "\n",
    "params = {'num_leaves': 256,\n",
    "          'feature_fraction': 0.6,\n",
    "          'bagging_fraction': 0.4,\n",
    "          'min_data_in_leaf': 32,\n",
    "          'objective': 'multiclass',\n",
    "          'num_class': 4,\n",
    "          'learning_rate': 0.005,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'multi_logloss',\n",
    "          \"verbosity\": -1,\n",
    "          'lambda_l1': 0.35,\n",
    "          'lambda_l2': 0.45,\n",
    "          'random_state': 47,\n",
    "          'is_unbalance': True\n",
    "          }\n",
    "seeds_num = 5\n",
    "seeds = np.random.randint(100, 1000, seeds_num)\n",
    "epoch = 0\n",
    "\n",
    "for seed in seeds:\n",
    "    epoch += 1\n",
    "    print(f'----------seed:{seed}', f'epoch:{epoch}------------')\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train, target)):\n",
    "        print(\"Fold {}\".format(fold_))\n",
    "        clf = lgb.LGBMClassifier(**params, n_estimators=3000)\n",
    "        clf.fit(train.iloc[trn_idx], target.iloc[trn_idx], eval_set=[(train.iloc[val_idx], target.iloc[val_idx])],\n",
    "                verbose=500, early_stopping_rounds=200)  # , early_stopping_rounds=100\n",
    "        oof[val_idx] += clf.predict_proba(train.iloc[val_idx])\n",
    "        # oof += clf.predict_proba(train)\n",
    "        prediction += clf.predict_proba(test) / folds.n_splits\n",
    "        feature_importance['importance'] += clf.feature_importances_\n",
    "\n",
    "oof = oof / seeds_num\n",
    "prediction = prediction / seeds_num\n",
    "print('log_loss:{}'.format(metrics.log_loss(target, oof)))\n",
    "\n",
    "\n",
    "def _softmax(matrix):\n",
    "    matrix_sort = np.argmax(matrix, axis=1)\n",
    "    # matrix_sort = np.argmax(np.bincount(matrix))\n",
    "    return matrix_sort\n",
    "\n",
    "\n",
    "oof = _softmax(oof)\n",
    "print(metrics.classification_report(target, oof))\n",
    "\n",
    "# feature_importance.to_excel(project_path + '/data/original/feature_importance.xlsx', encoding='utf-8-sig')\n",
    "\n",
    "plt.figure(figsize=(8, 20))\n",
    "sns.barplot(x='importance', y='features', data=feature_importance.sort_values('importance', ascending=False))\n",
    "plt.title('feature_importance', fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "cols = ['Excellent', 'Fail', 'Good', 'Pass']\n",
    "# 0,1,2,3\n",
    "# prediction = prediction / (fold_+1)\n",
    "sub = pd.DataFrame(prediction, columns=list(lbl.classes_))\n",
    "sub['Group'] = sub_group\n",
    "sub = sub.groupby('Group')[cols].mean()\n",
    "sub.columns = [col + ' ratio' for col in sub.columns.values]\n",
    "sub.reset_index(inplace=True)\n",
    "sub = sub[subsample.columns]\n",
    "\n",
    "import datetime\n",
    "\n",
    "filename = \"{:%Y-%m-%d_%H_%M}_sub\".format(datetime.datetime.now())\n",
    "sub.to_csv(project_path + '/data/submit/' + filename + '_accuracy{}.csv'.format(round(metrics.accuracy_score(target, oof), 4)),\n",
    "           index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "pycharm-e50da876",
   "language": "python",
   "display_name": "PyCharm (ForecastScore)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}