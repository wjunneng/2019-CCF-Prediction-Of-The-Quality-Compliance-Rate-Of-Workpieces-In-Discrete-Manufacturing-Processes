{
 "cells": [],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "pycharm-b82596ec",
   "language": "python",
   "display_name": "PyCharm (2019-CCF-Prediction-Of-The-Quality-Compliance-Rate-Of-Workpieces-In-Discrete-Manufacturing-Processes)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "import catboost as cbt\n",
     "import numpy as np\n",
     "import pandas as pd\n",
     "from xgboost import XGBClassifier\n",
     "import lightgbm as lgb\n",
     "from lightgbm import LGBMClassifier\n",
     "from sklearn.model_selection import KFold\n",
     "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
     "from sklearn.metrics import accuracy_score, roc_auc_score,log_loss\n",
     "from sklearn.model_selection import GridSearchCV\n",
     "from sklearn.metrics import fbeta_score, make_scorer\n",
     "import matplotlib as mpl\n",
     "mpl.use(‘Agg’)\n",
     "import matplotlib.pyplot as plt\n",
     "import time\n",
     "import copy\n",
     "import gc\n",
     "import os\n",
     "train_data =\n",
     "test_data =\n",
     "dit = {‘Excellent’:0,’Good’:1,’Pass’:2,’Fail’:3}\n",
     "train_data[‘Quality_label’] = train_data[‘Quality_label’].map(dit)\n",
     "labels = pd.get_dummies(train_data[‘Quality_label’]).values\n",
     "submit =\n",
     "features = [‘Parameter5’, ‘Parameter7’, ‘Parameter8’, ‘Parameter9’, ‘Parameter10’]\n",
     "for fc in features:\n",
     "n = train_data[‘{}’.format(fc)].nunique()\n",
     "\n",
     "这个的作用就是显示特征中的唯一值\n",
     "print(fc + ':', n)\n",
     "x_train = train_data[features].values\n",
     "x_test = test_data[features].values\n",
     "\n",
     "def lightgbm_model():\n",
     "model = LGBMClassifier(max_depth=7, learning_rate=0.01, n_estimators=1000, num_leaves=16,\n",
     "objective=’multiclass’, silent=True,\n",
     "reg_lambda=4., #reg_alpha=1.,\n",
     "#bagging_fraction=0.9, feature_fraction=0.9,\n",
     ")\n",
     "return model\n",
     "\n",
     "def xgboost_model():\n",
     "model = XGBClassifier(max_depth=5, n_estimators=1000, learning_rate=0.01, silent=True\n",
     "#objective=’multi:softmax’\n",
     ")\n",
     "return model\n",
     "\n",
     "def catboost_model():\n",
     "cbt_model = cbt.CatBoostClassifier(#iterations=100000, learning_rate=0.01, verbose=0,\n",
     "iterations=3000, learning_rate=0.01, verbose=0,\n",
     "max_depth=6, #reg_lambda=5.,\n",
     "task_type=’GPU’, # cat_features=cat_list,\n",
     "loss_function=’MultiClass’,\n",
     ")\n",
     "return cbt_model\n",
     "\n",
     "def catboost_importance():\n",
     "model = catboost_model()\n",
     "model.fit(x_train, np.argmax(labels, 1))\n",
     "importance = model.get_feature_importance(prettified=True)\n",
     "\n",
     "这个其实就是类似PCA一样，找到特征的贡献\n",
     "print(importance.columns)\n",
     "for i in range(len(features)):\n",
     "print(features[int(importance['Feature Id'][i])] + ' :', importance['Importances'][i])\n",
     "catboost_importance()\n",
     "def kfold_train(mode):\n",
     "acc_list, loss_list = [], []\n",
     "prediction = np.zeros((x_test.shape[0], 4))\n",
     "for i in range(10):\n",
     "print(str(i+1) + ‘ th kflod’ + ‘‘50)\n",
     "kf = KFold(n_splits=5, shuffle=True, random_state=i)\n",
     "kfold_list = []\n",
     "for k, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
     "print(str(k+1) + ‘fold————–’)\n",
     "train_x, train_y = x_train[train_index], labels[train_index]\n",
     "test_x, test_y = x_train[test_index], labels[test_index]\n",
     "# train\n",
     "if mode == ‘cat’:\n",
     "model = catboost_model()\n",
     "model.fit(train_x, np.argmax(train_y, 1), eval_set=(test_x, np.argmax(test_y, 1)),\n",
     "#early_stopping_rounds=1000, verbose=False\n",
     ")\n",
     "#print(pd.DataFrame({‘column’: features, ‘importance’: model.feature_importances_}).sort_values(by=’importance’))\n",
     "if mode == ‘lgb’:\n",
     "model = lightgbm_model()\n",
     "model.fit(train_x, np.argmax(train_y, 1), eval_set=(test_x, np.argmax(test_y, 1)),\n",
     "# early_stopping_rounds=50, verbose=True\n",
     "verbose=False\n",
     ")\n",
     "if mode == ‘xgb’:\n",
     "model = xgboost_model()\n",
     "model.fit(train_x, np.argmax(train_y, 1), verbose=True)\n",
     "pred = model.predict_proba(test_x)\n",
     "acc = accuracy_score(np.argmax(test_y, 1), np.argmax(pred, 1))\n",
     "loss = log_loss(test_y, pred)\n",
     "acc_list.append(acc)\n",
     "loss_list.append(loss)\n",
     "kfold_list.append(loss)\n",
     "print(‘test acc: %f, test loss: %f’ % (acc, loss))\n",
     "# predict\n",
     "prediction += model.predict_proba(x_test)\n",
     "print(‘this fold mean loss:’, np.mean(kfold_list))\n",
     "print(‘‘50)\n",
     "print(‘mean acc: %f, mean loss: %f’ % (np.mean(acc_list), np.mean(loss_list)))\n",
     "prediction = prediction / 50.\n",
     "return prediction\n",
     "def submit_result(prediction):\n",
     "sub = test_data[[‘Group’]]\n",
     "prob_cols = [i for i in submit.columns if i not in [‘Group’]]\n",
     "for i, f in enumerate(prob_cols):\n",
     "sub[f] = prediction[:, i]\n",
     "for i in prob_cols:\n",
     "sub[i] = sub.groupby(‘Group’)[i].transform(‘mean’)\n",
     "sub = sub.drop_duplicates()\n",
     "sub.to_csv(, index=False)\n",
     "time1 = time.clock()\n",
     "prediction = kfold_train(‘cat’)\n",
     "time2 = time.clock()\n",
     "print(‘running time: ‘, str((time2 - time1)/60))\n",
     "submit_result(prediction)"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}